実験ID,手法 (Method),0.45ノイズ精度,0.48ノイズ精度,評価・分析
初期,Cubic Contrast (3乗則),74.9%,N/A,コントラストを強めすぎ、微弱な信号(相関0.04)もノイズと共に消し去っていた。
#1,Lateral Inhibition,40.3% ⬇,N/A,抑制が強すぎて、ノイズに埋もれた正解発火も抑制してしまった。
#2,Z-Score Gain,31.7% ⬇,N/A,ノイズ分散で正規化したため、ノイズ自体が増幅され勾配が爆発した。
#3,Soft-WTA (Softmax),75.6% ⬆,N/A,確率的な勾配伝播により、微小な差を学習できるようになった。（最初のブレイクスルー）
#4,Delta Rule (誤差訂正),71.0%,29.3%,ノイズ自体を「誤差」として学習してしまい、重みが振動した。
#5,Bipolar (-1/+1),65.3%,27.0%,物理モデルは正しいが、誤差訂正則との相性が悪かった。
#6,Prototype Aggregation,87.1% ⬆,37.2%,決定的手法。誤差を修正するのではなく、入力を「平均化」することでノイズを統計的に消去した。
#7,EMA & Decorrelation,86.9%,37.3%,平均化の効果を確認。直交化は安定性に寄与するが、精度限界は変わらず。
#8,Contrastive (対照学習),85.2%,37.6%,「不正解から遠ざける」操作が、ノイズパターンを学習することになり逆効果。
#9,Power Law (x9),87.0%,37.5%,"S/N比改善を狙ったが、線形アプローチ(#6, #7)と大差なし。信号が微弱すぎるため。"
#10,Linear High-Gain,84.7%,36.0%,線形増幅で信号を保存したが、単純平均(#6)のロバストさには一歩及ばず。