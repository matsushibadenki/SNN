---------------------
まず、プロジェクト全体の構造を把握してください。
doc/ROADMAP.mdを参考にコードを実装してください。
すでに実装済みの部分もあるので、プロジェクトをよく調べてから作業を開始してください。
作成したコードは省略のない完全コードで教えてください。


まず、プロジェクト全体の構造を把握してください。
実用化に向けて精度向上、堅牢性向上、実用性向上、不足機能の追加を目指したいと思います。
私はテストコードのログを返しますので、結果に合わせて、doc/Objective.mdを念頭に、コードの調整をお願いします。
ログを出すためのコマンドは設定して教えてください。
また、修正したコードは省略のない完全コードで教えてください。

精度と速度を上げたいです。
まず、プロジェクト全体の構造を把握してください。
doc/Objective.mdを念頭に、下記のログをもとにブラッシュアップしてください。
修正したコードは省略のない完全コードで教えてください。
---------------------

# MNISTの結果（精度97.2%、レイテンシ3.5ms）を検証する場合
python scripts/tests/verify_performance.py --task mnist --accuracy 0.972 --latency 3.5
---------------------
# または、学習スクリプトが出力したJSONを指定する場合
python scripts/training/train_mnist_snn.py
python scripts/tests/verify_performance.py --metrics_json results/best_mnist_metrics.json
---------------------
python scripts/training/train_bio_pc_cifar10.py

---------------------
python scripts/tests/run_all_tests.py
python scripts/experiments/run_logic_gated_learning.py

python scripts/training/run_improved_scal_training.py --ensemble

python scripts/demos/run_forward_forward_demo.py

python scripts/visualization/visualize_spike_patterns.py \
--model-config configs/models/micro.yaml \
--timesteps 8 \
--output_path "runs/dynamics_viz/micro_dynamics.png"


--------------
スパイク自動チューン（準備学習）
python scripts/training/train.py \
--config configs/templates/base_config.yaml \
--model_config configs/models/small.yaml \
--data_path data/smoke_test_data.jsonl \
--override_config "training.epochs=10" \
--override_config "training.batch_size=4" \
--override_config "training.gradient_based.type=standard"

スパイク自動チューン（自動調整）
python scripts/optimization/auto_tune_efficiency.py \
--model-config configs/models/small.yaml \
--n-trials 20



--------------
1. 念のため古いデータを削除（クリーンな状態で再作成）

rm -rf precomputed_data/smoke_distill

2. 蒸留データの再生成

python scripts/data/prepare_distillation_data.py  \
--input_file data/smoke_test_data.jsonl \
--output_dir precomputed_data/smoke_distill \
--teacher_model gpt2

3.
python scripts/training/train.py \
--model_config configs/models/bit_rwkv_micro.yaml \
--data_path precomputed_data/smoke_distill/distillation_data.jsonl \
--paradigm gradient_based \
--override_config "training.gradient_based.type=distillation" \
--override_config "training.gradient_based.distillation.teacher_model=gpt2" \
--override_config "training.epochs=2"