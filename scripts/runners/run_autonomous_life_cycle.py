# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/runners/run_autonomous_life_cycle.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Autonomous Life Cycle Runner
# ç›®çš„ãƒ»å†…å®¹:
#   AutonomousLearningLoopã‚’ç”¨ã„ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã€Œä¸€ç”Ÿï¼ˆãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ï¼‰ã€ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
#   ãƒ€ãƒŸãƒ¼ã®è¦–è¦šãƒ»è¨€èªå…¥åŠ›ã‚’ç”¨ã„ã¦ã€è¦šé†’ã¨ç¡çœ ã®ã‚µã‚¤ã‚¯ãƒ«ãŒæ­£ã—ãå›ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
#   [Fix] ãƒ­ã‚°è¨­å®šã®å¼·åˆ¶(force=True)ã¨ã€mainé–¢æ•°å‘¼ã³å‡ºã—ã®ç¢ºå®ŸåŒ–ã€VLMåˆæœŸåŒ–é †åºã®ä¿®æ­£ã€‚

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ã«ãƒ—ãƒªãƒ³ãƒˆã—ã¦å‹•ä½œç¢ºèª
import logging
import torch.optim as optim
import torch
import sys
import os
from snn_research.systems.autonomous_learning_loop import AutonomousLearningLoop
from snn_research.systems.embodied_vlm_agent import EmbodiedVLMAgent
from snn_research.models.transformer.spiking_vlm import SpikingVLM
print("--- [DEBUG] Script loading... ---")


# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

# ãƒ­ã‚°è¨­å®š (force=Trueã§æ—¢å­˜ã®è¨­å®šã‚’ä¸Šæ›¸ãã—ã€ç¢ºå®Ÿã«è¡¨ç¤ºã•ã›ã‚‹)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True
)
logger = logging.getLogger(__name__)


def main():
    print("--- [DEBUG] Entering main() ---")
    logger.info("ğŸš€ Starting Autonomous Life Cycle Simulation...")

    # 1. Setup Environment & Agent
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"Using device: {device}")

    # ãƒ€ãƒŸãƒ¼ã®èªå½™ã‚µã‚¤ã‚º
    vocab_size = 1000

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­å®š (VLMã¨Motor)
    # SpikingVLMã®è¨­å®š
    vision_config = {
        "type": "cnn",
        "hidden_dim": 512,
        "img_size": 64,  # ãƒ€ãƒŸãƒ¼ç”»åƒã®ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
        "time_steps": 16
    }
    text_config = {
        "d_model": 512,
        "num_layers": 2
    }

    # MotorDecoderã®è¨­å®š
    motor_config = {
        "action_dim": 64,
        "hidden_dim": 512,
        "action_type": "continuous"
    }

    try:
        # ã¾ãšVLMã‚’æ§‹ç¯‰
        logger.info("Building SpikingVLM...")
        vlm_model = SpikingVLM(
            vocab_size=vocab_size,
            vision_config=vision_config,
            text_config=text_config,
            projection_dim=512
        ).to(device)

        # EmbodiedVLMAgentã‚’åˆæœŸåŒ– (VLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ¸¡ã™)
        logger.info("Building EmbodiedVLMAgent...")
        agent = EmbodiedVLMAgent(
            vlm_model=vlm_model,
            motor_config=motor_config
        ).to(device)
        logger.info("âœ… Agent built successfully.")

    except Exception as e:
        logger.error(f"Failed to init real agent: {e}", exc_info=True)
        logger.warning("Using Mock for demonstration.")
        # ãƒ¢ãƒƒã‚¯ä½¿ç”¨æ™‚ã¯æ§‹æˆè¾æ›¸ã‚’ãƒ•ãƒ©ãƒƒãƒˆãªå½¢å¼ã«å¤‰æ›ã—ã¦æ¸¡ã™
        mock_config = {
            "vision_dim": 3,
            "text_dim": 512,
            "hidden_dim": 512,
            "action_dim": 64
        }
        agent = MockAgent(mock_config).to(device)

    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
    optimizer = optim.AdamW(agent.parameters(), lr=1e-4)

    # 2. Initialize Autonomous Loop
    # ç–²åŠ´é–¾å€¤ã‚’ä½ãè¨­å®šã—ã¦ã€ã™ãã«ç¡çœ ã‚µã‚¤ã‚¯ãƒ«ãŒè¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    logger.info("Initializing AutonomousLearningLoop...")
    life_cycle = AutonomousLearningLoop(
        agent=agent,
        optimizer=optimizer,
        device=device,
        energy_capacity=100.0,
        fatigue_threshold=20.0
    )

    # 3. Simulation Loop (Days)
    num_steps = 100

    logger.info(f"â³ Running simulation for {num_steps} steps...")

    for step in range(num_steps):
        # Mock Sensory Input (ç’°å¢ƒã‹ã‚‰ã®å…¥åŠ›)
        # ç”»åƒå…¥åŠ› [Batch, Channels, Height, Width]
        current_image = torch.randn(1, 3, 64, 64).to(device)

        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› [Batch, Seq_Len] (SpikingVLMã¯ãƒˆãƒ¼ã‚¯ãƒ³IDã‚’æœŸå¾…ã™ã‚‹)
        current_text = torch.randint(0, vocab_size, (1, 10)).to(device)

        # æ¬¡ã®ç¬é–“ã®ç”»åƒ
        next_image = torch.randn(1, 3, 64, 64).to(device)

        # Step Execution
        # AutonomousLearningLoopå†…ã§ agent(image, text) ãŒå‘¼ã°ã‚Œã‚‹
        status = life_cycle.step(current_image, current_text, next_image)

        mode = status["mode"]

        if mode == "wake":
            logger.info(
                f"Step {step:03d} [Wake]: Surprise={status.get('surprise', 0.0):.4f}, "
                f"Reward={status.get('intrinsic_reward', 0.0):.4f}, "
                f"Fatigue={status.get('fatigue', 0.0):.1f}/{life_cycle.fatigue_threshold}"
            )
        elif mode == "sleep":
            logger.info(
                f"Step {step:03d} [SLEEP]: ğŸ’¤ Memory Consolidation Loss={status.get('sleep_loss', 0.0):.4f}")

    logger.info("âœ… Simulation Complete.")

# --- Mock Classes for Independent Execution ---


class MockAgent(torch.nn.Module):
    def __init__(self, config):
        super().__init__()
        self.fusion_dim = config["hidden_dim"]
        self.action_dim = config["action_dim"]
        # å…¥åŠ›æ¬¡å…ƒãªã©ã¯ç„¡è¦–ã—ã¦ã€å†…éƒ¨ã§é©å½“ãªã‚µã‚¤ã‚ºã®å±¤ã‚’æŒã¤
        self.mock_layer = torch.nn.Linear(10, self.fusion_dim)

        # Dummy VLM sub-module interface
        self.vlm = self._vlm_mock

        # Mockç”¨ã«Projectorã‚‚ã©ãã‚’æŒãŸã›ã¦ãŠã
        self.vlm.projector = type(
            'obj', (object,), {'embed_dim': self.fusion_dim})

    def forward(self, img, txt):
        B = img.shape[0]
        return {
            "fused_context": torch.randn(B, self.fusion_dim, device=img.device),
            "action_pred": torch.randn(B, self.action_dim, device=img.device),
            "alignment_loss": torch.tensor(0.1, device=img.device, requires_grad=True),
            # Dummy logits
            "logits": torch.randn(B, 10, 1000, device=img.device)
        }

    def _vlm_mock(self, img, txt):
        B = img.shape[0]
        return {
            "fused_representation": torch.randn(B, self.fusion_dim, device=img.device)
        }


if __name__ == "__main__":
    main()
