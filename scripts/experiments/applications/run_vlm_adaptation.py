# „Éï„Ç°„Ç§„É´„Éë„Çπ: scripts/run_vlm_adaptation.py
# (Phase 4: Autonomous Adaptation - Demo)
# Title: VLM Test-Time Adaptation Demo
# Description:
#   Â≠¶ÁøíÊ∏à„ÅøSpikingVLM„ÇíÁî®„ÅÑ„ÄÅÊé®Ë´ñÊôÇ„ÅÆ„Ç™„É≥„ÉÅ„ÉÉ„ÉóÈÅ©ÂøúÔºàTest-Time AdaptationÔºâ„ÇíÂÆüË®º„Åô„Çã„ÄÇ
#   ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÈ´ò„ÅÑÂÖ•Âäõ„Å´ÂØæ„Åó„Å¶„ÄÅOnChipSelfCorrector„Åå„Éã„É•„Éº„É≠„É≥„ÅÆÈñæÂÄ§„ÇíÂãïÁöÑ„Å´Ë™øÊï¥„Åô„ÇãÊßòÂ≠ê„ÇíË¶≥ÂØü„Åô„Çã„ÄÇ

from snn_research.data.datasets import ImageTextDataset
from snn_research.core.neurons import AdaptiveLIFNeuron
from snn_research.adaptive.on_chip_self_corrector import OnChipSelfCorrector
from snn_research.models.transformer.spiking_vlm import SpikingVLM
import sys
import os
import torch
import logging
from tqdm import tqdm
from transformers import AutoTokenizer

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„ÇíPython„Éë„Çπ„Å´ËøΩÂä†
sys.path.append(os.path.abspath(
    os.path.join(os.path.dirname(__file__), '../..')))


# „É≠„Ç¨„ÉºË®≠ÂÆö
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(message)s")
logger = logging.getLogger(__name__)


def load_trained_model(checkpoint_path, device, vocab_size=30522, d_model=256, vision_dim=128):
    """Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÅÆÊßãÁØâ„Å®Èáç„Åø„É≠„Éº„Éâ"""
    logger.info(f"üìÇ Loading checkpoint: {checkpoint_path}")

    vision_config = {
        "architecture_type": "spiking_cnn",
        "input_channels": 3,
        "features": vision_dim,
        "time_steps": 4,
        "layers": [64, 128, vision_dim]
    }
    language_config = {
        "architecture_type": "spiking_transformer",
        "vocab_size": vocab_size,
        "d_model": d_model,
        "num_layers": 4,
        "num_heads": 4,
        "time_steps": 4,
        "max_len": 64
    }
    projector_config = {"visual_dim": vision_dim,
                        "use_bitnet": True}  # BitNetÊúâÂäπÂåñ

    model = SpikingVLM(
        vocab_size=vocab_size,
        vision_config=vision_config,
        language_config=language_config,
        projector_config=projector_config
    ).to(device)

    try:
        model.load_state_dict(torch.load(checkpoint_path, map_location=device))
        logger.info("‚úÖ Model weights loaded successfully.")
    except FileNotFoundError:
        logger.warning(
            "‚ö†Ô∏è Checkpoint not found. Using random weights for demonstration.")

    return model


def collect_monitor_neurons(model):
    """„É¢„Éá„É´ÂÜÖ„ÅÆAdaptiveLIFNeuron„ÇíÂèéÈõÜ„Åô„Çã"""
    neurons = []
    for name, module in model.named_modules():
        if isinstance(module, AdaptiveLIFNeuron):
            neurons.append(module)
    logger.info(f"üîç Found {len(neurons)} adaptive neurons to monitor.")
    return neurons


def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    checkpoint_path = "workspace/checkpoints/vlm/spiking_vlm_epoch_2.pt"  # ÂâçÂõû„ÅÆÂ≠¶ÁøíÁµêÊûú
    data_path = "data/vlm_dummy/train_data.jsonl"

    # 1. „É¢„Éá„É´Ê∫ñÂÇô
    model = load_trained_model(checkpoint_path, device)
    model.eval()  # Êé®Ë´ñ„É¢„Éº„Éâ („Åó„Åã„ÅóÈÅ©Âøú„ÅØÂãï„Åè)

    # 2. „Ç™„É≥„ÉÅ„ÉÉ„ÉóËá™Â∑±‰øÆÊ≠£Âô®„ÅÆÂàùÊúüÂåñ
    monitor_neurons = collect_monitor_neurons(model)
    corrector = OnChipSelfCorrector(
        monitor_layers=monitor_neurons,
        adaptation_rate=0.05,  # „Éá„É¢Áî®„Å´È´ò„ÇÅ„Å´Ë®≠ÂÆö (Â§âÂåñ„Çí„Çè„Åã„Çä„ÇÑ„Åô„Åè„Åô„Çã„Åü„ÇÅ)
        entropy_threshold=0.5,  # ÈñæÂÄ§„Çí‰Ωé„ÇÅ„Å´Ë®≠ÂÆö„Åó„Å¶ÈÅ©Âøú„ÇíË™òÁô∫
        homeostasis_target=0.1  # ÁõÆÊ®ôÁô∫ÁÅ´Áéá
    )

    # 3. „Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº (1„Éê„ÉÉ„ÉÅ„Åö„Å§Âá¶ÁêÜ)
    try:
        tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
    except Exception:
        # „ÉÄ„Éü„Éº„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº
        class DummyTokenizer:
            pad_token_id = 0

            def __call__(self, text, **kwargs):
                ids = [hash(w) % 30522 for w in text.split()]
                return {"input_ids": torch.tensor([ids[:64]], dtype=torch.long)}
        tokenizer = DummyTokenizer()

    dataset = ImageTextDataset(data_path, tokenizer, max_seq_len=64)

    # 4. ÈÅ©ÂøúÊé®Ë´ñ„É´„Éº„Éó
    logger.info("üöÄ Starting Test-Time Adaptation Loop...")

    entropy_history = []
    threshold_history = []  # ÊúÄÂàù„ÅÆ„Éã„É•„Éº„É≠„É≥„ÅÆÈñæÂÄ§„ÇíË®òÈå≤

    # ÊúÄÂàù„ÅÆ„Éã„É•„Éº„É≠„É≥„ÅÆÈñæÂÄ§„Éë„É©„É°„Éº„Çø„Å∏„ÅÆÂèÇÁÖß
    target_neuron = monitor_neurons[0] if monitor_neurons else None

    for i in tqdm(range(min(20, len(dataset)))):  # 20„Çπ„ÉÜ„ÉÉ„Éó„Å†„ÅëÂÆüË°å
        item = dataset[i]

        # „Éá„Éº„ÇøÊ∫ñÂÇô (Batch dimËøΩÂä†)
        input_ids = item['input_ids'].unsqueeze(0).to(device)
        pixel_values = item['pixel_values'].unsqueeze(0).to(device)

        # --- Êé®Ë´ñ ---
        with torch.no_grad():
            logits, avg_spikes, _ = model(
                input_ids, pixel_values, return_spikes=True)

            # --- „Ç™„É≥„ÉÅ„ÉÉ„ÉóÈÅ©Âøú ---
            # hidden_states„ÅØÁèæÂú®Êú™‰ΩøÁî®„Å™„ÅÆ„ÅßÁ©∫„É™„Çπ„Éà„ÇíÊ∏°„Åô
            stats = corrector(logits, hidden_states=[])

        # Ë®òÈå≤
        entropy_history.append(stats.get("entropy", 0.0))
        if target_neuron is not None:
            # ÁèæÂú®„ÅÆÂÆüÂäπÈñæÂÄ§ (Base + Adaptive)
            current_th = target_neuron.base_threshold.mean().item()
            threshold_history.append(current_th)

    # ÁµêÊûúË°®Á§∫
    logger.info(f"üìä Final Entropy: {entropy_history[-1]:.4f}")
    logger.info(f"üìä Adaptation Count: {corrector.adaptation_count.item()}")

    if target_neuron:
        logger.info(
            f"üìà Threshold Change: {threshold_history[0]:.4f} -> {threshold_history[-1]:.4f}")
        if threshold_history[-1] != threshold_history[0]:
            logger.info(
                "‚úÖ SUCCESS: Neuron thresholds adapted dynamically during inference!")
        else:
            logger.info(
                "‚ÑπÔ∏è No significant threshold change (Entropy might be low).")


if __name__ == "__main__":
    main()
