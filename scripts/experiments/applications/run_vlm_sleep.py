# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/run_vlm_sleep.py
# (Phase 4: Sleep Consolidation Demo - Fixed)
# Title: VLM Sleep & Dreaming Demo
# Description: ãƒ­ã‚°å‡ºåŠ›ã‚’æ¨™æº–å‡ºåŠ›ã«å¼·åˆ¶ã—ã€å®Ÿè¡ŒçŠ¶æ³ã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚

import sys
import os
import torch
import logging
import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from snn_research.models.transformer.spiking_vlm import SpikingVLM
from snn_research.cognitive_architecture.sleep_consolidation import SleepConsolidator

# ãƒ­ã‚¬ãƒ¼è¨­å®š: æ¨™æº–å‡ºåŠ›ã«å¼·åˆ¶çš„ã«å‡ºã™
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

def load_trained_model(checkpoint_path, device):
    print(f"ğŸ“‚ Loading VLM from: {checkpoint_path}") # å¼·åˆ¶å‡ºåŠ›
    logger.info(f"ğŸ“‚ Loading VLM from: {checkpoint_path}")
    
    vision_config = {"architecture_type": "spiking_cnn", "input_channels": 3, "features": 128, "time_steps": 4, "layers": [64, 128, 128]}
    language_config = {"architecture_type": "spiking_transformer", "vocab_size": 30522, "d_model": 256, "num_layers": 4, "num_heads": 4, "time_steps": 4, "max_len": 64}
    projector_config = {"visual_dim": 128, "use_bitnet": True}
    
    model = SpikingVLM(
        vocab_size=30522,
        vision_config=vision_config,
        language_config=language_config,
        projector_config=projector_config
    ).to(device)
    
    if os.path.exists(checkpoint_path):
        model.load_state_dict(torch.load(checkpoint_path, map_location=device))
        logger.info("âœ… Weights loaded.")
    else:
        logger.warning("âš ï¸ Checkpoint not found. Initializing with random weights.")
        
    return model

def main():
    print("ğŸš€ Starting Sleep Simulation...") # å¼·åˆ¶å‡ºåŠ›
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    checkpoint_path = "workspace/checkpoints/vlm/spiking_vlm_epoch_2.pt"
    
    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    brain = load_trained_model(checkpoint_path, device)
    
    # 2. ç¡çœ ã‚³ãƒ³ã‚½ãƒªãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–
    sleeper = SleepConsolidator(memory_system={}, target_brain_model=brain, dream_rate=0.05)
    
    # 3. æ—¥ä¸­ã®æ´»å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    logger.info("â˜€ï¸ DAYTIME: Accumulating experiences...")
    for i in range(5):
        sleeper.experience_buffer.append({"type": "visual_event", "content_id": i})
    
    # 4. å¤œé–“ï¼šç¡çœ ã‚µã‚¤ã‚¯ãƒ«
    logger.info("ğŸŒ™ NIGHTTIME: Entering REM sleep (Dreaming)...")
    
    # 50ã‚µã‚¤ã‚¯ãƒ«ã®å¤¢ã‚’è¦‹ã‚‹
    results = sleeper.perform_sleep_cycle(duration_cycles=50)
    
    # 5. çµæœåˆ†æ
    clarity_history = results["loss_history"]
    avg_clarity = np.mean(clarity_history) if clarity_history else 0.0
    
    logger.info("ğŸ’¤ Sleep Cycle Completed.")
    logger.info(f"   - Dreams Replayed: {results['dreams_replayed']}")
    logger.info(f"   - Average Dream Clarity: {avg_clarity:.4f}")
    
    if avg_clarity > 0.0:
        print("âœ… SUCCESS: The brain generated internal dreams.")
    else:
        print("âš ï¸ The brain activity was silent.")

# ã“ã“ãŒæ¬ è½ã—ã¦ã„ã‚‹ã¨å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“
if __name__ == "__main__":
    main()