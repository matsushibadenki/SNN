# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/experiments/systems/run_unified_mission.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Phase 8 å…¨æ©Ÿèƒ½çµ±åˆãƒ‡ãƒ¢ "Project: OMEGA" v1.1
# ç›®çš„: è¦–è¦šãƒ»æ€è€ƒãƒ»ç¤¾ä¼šæ€§ãƒ»ç¡çœ ãƒ»è‡ªå¾‹æ€§ã‚’çµ±åˆã—ãŸã€æœ€çµ‚çš„ãªAGIãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®å®Ÿè¨¼å®Ÿé¨“ã€‚
# ä¿®æ­£å±¥æ­´:
#   v1.1: Pre-trainingæ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º(32)ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€Gatingåˆ¤å®šã‚’ .mean().item() ã«ä¿®æ­£ã€‚

import sys
import os
import time
import logging
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, Any, List, Optional
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
project_root = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../../../"))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š (ãƒªãƒƒãƒãªå‡ºåŠ›)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(message)s',
    datefmt='%H:%M:%S',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)
logging.getLogger("spikingjelly").setLevel(logging.ERROR)

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from snn_research.core.snn_core import SNNCore
    from snn_research.models.experimental.bit_spike_mamba import BitSpikeMamba
    from snn_research.cognitive_architecture.sleep_consolidation import SleepConsolidator
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    sys.exit(1)


# --- 1. çµ±åˆè„³ãƒ¢ãƒ‡ãƒ« (Unified Brain) ---

class VisualTokenizer(nn.Module):
    """è¦–è¦šé‡: ç”»åƒã‚’è„³ãŒç†è§£ã§ãã‚‹ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã«å¤‰æ›"""
    def __init__(self, vocab_size: int = 128, patch_size: int = 4):
        super().__init__()
        self.patch_conv = nn.Conv2d(1, vocab_size, kernel_size=patch_size, stride=patch_size)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        if not x.is_contiguous(): x = x.contiguous()
        features = self.patch_conv(x) # (B, C, H, W)
        features = features.flatten(2).transpose(1, 2).contiguous() # (B, L, C)
        visual_tokens = torch.argmax(features, dim=-1) # é‡å­åŒ–
        return visual_tokens

class OmegaBrain(nn.Module):
    """
    Project OMEGAã®ãŸã‚ã®çµ±åˆè„³ã€‚
    System 1 (ç›´æ„Ÿ/SFormer) ã¨ System 2 (ç†Ÿè€ƒ/Mamba) ã‚’æ­è¼‰ã€‚
    """
    def __init__(self, device: str, vocab_size: int = 128):
        super().__init__()
        self.device = device
        
        # è¦–è¦šå…¥åŠ›
        self.visual_cortex = VisualTokenizer(vocab_size=vocab_size, patch_size=4).to(device)
        
        # System 1: SFormer (Fast, Low Energy)
        self.system1 = SNNCore(config={
            "architecture_type": "sformer",
            "d_model": 64,
            "num_layers": 2,
            "nhead": 2,
            "time_steps": 2,
            "neuron_config": {"type": "lif", "v_threshold": 1.0}
        }, vocab_size=vocab_size).to(device)
        
        # System 2: BitSpikeMamba (Slow, Deep, High Energy)
        self.system2 = BitSpikeMamba(
            vocab_size=vocab_size,
            d_model=64,
            d_state=16,
            d_conv=4,
            expand=2,
            num_layers=2,
            time_steps=4,
            neuron_config={"type": "lif", "base_threshold": 1.0}
        ).to(device)
        
        # ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹: System 1ã®å‡ºåŠ›ã®ã€Œæ›–æ˜§ã•ã€ã‚’ç›£è¦–
        self.gating_net = nn.Sequential(
            nn.Linear(vocab_size, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        ).to(device)
        
        # å‡ºåŠ›å±¤ (æ•°å­—åˆ†é¡ 0-9)
        self.classifier = nn.Linear(vocab_size, 10).to(device)

    def forward(self, image: torch.Tensor, force_system2: bool = False) -> Dict[str, Any]:
        # 1. è¦‹ã‚‹ (Visual Cortex)
        tokens = self.visual_cortex(image)
        
        # 2. ç›´æ„Ÿã§è€ƒãˆã‚‹ (System 1)
        out1 = self.system1(tokens)
        if isinstance(out1, tuple): out1 = out1[0]
        sys1_feats = out1.mean(dim=1) # (B, Vocab)
        
        # 3. åˆ¤æ–­ã™ã‚‹ (Gating)
        uncertainty_map = self.gating_net(sys1_feats)
        
        # [Fix] ãƒãƒƒãƒã‚µã‚¤ã‚º > 1 ã®å ´åˆã«å¯¾å¿œã™ã‚‹ãŸã‚ .mean() ã‚’ä½¿ç”¨
        uncertainty_scalar = uncertainty_map.mean().item()
        
        final_feats = sys1_feats
        system_used = "System 1"
        
        # é–¾å€¤ã‚’è¶…ãˆã‚‹ã‹ã€å¼·åˆ¶ãƒ•ãƒ©ã‚°ãŒã‚ã‚Œã°System 2èµ·å‹•
        if uncertainty_scalar > 0.6 or force_system2:
            system_used = "System 2"
            out2 = self.system2(tokens)
            if isinstance(out2, tuple): out2 = out2[0]
            sys2_feats = out2.mean(dim=1)
            
            # æ€è€ƒã®çµ±åˆ
            final_feats = (sys1_feats + sys2_feats) / 2.0
            
        # 4. ç­”ãˆã‚’å‡ºã™
        logits = self.classifier(final_feats)
        
        return {
            "logits": logits,
            "features": final_feats,
            "system": system_used,
            "uncertainty": uncertainty_scalar,
            "tokens": tokens # è¨˜æ†¶ç”¨
        }


# --- 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (The Operators) ---

class Operator:
    def __init__(self, name: str, role: str, device: str):
        self.name = name
        self.role = role # "Commander" (Teacher) or "Scout" (Student)
        self.device = device
        
        self.brain = OmegaBrain(device).to(device)
        self.sleep_system = SleepConsolidator(target_brain_model=self.brain.system2)
        
        # å­¦ç¿’è¨­å®š
        self.optimizer = torch.optim.AdamW(self.brain.parameters(), lr=0.002)
        self.criterion = nn.CrossEntropyLoss()
        self.distill_loss = nn.KLDivLoss(reduction="batchmean")
        
        self.fatigue = 0.0
        self.experience_buffer = []
        self.accuracy_history = []

    def process_data(self, image: torch.Tensor, is_anomaly: bool = False) -> Dict[str, Any]:
        """ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€æ€è€ƒã™ã‚‹"""
        self.brain.eval()
        start_time = time.time()
        
        # ç•°å¸¸æ¤œçŸ¥æ™‚ã¯æ…é‡ã«ãªã‚‹ (System 2å¼·åˆ¶)
        force_s2 = is_anomaly and (self.role == "Commander")
        
        with torch.no_grad():
            result = self.brain(image, force_system2=force_s2)
            
        latency = (time.time() - start_time) * 1000
        result["latency"] = latency
        return result

    def learn(self, image: torch.Tensor, label: Optional[torch.Tensor], peer_logits: Optional[torch.Tensor] = None):
        """å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º: çµŒé¨“ã¾ãŸã¯ä»–è€…ã‹ã‚‰å­¦ã¶"""
        self.brain.train()
        self.optimizer.zero_grad()
        
        result = self.brain(image)
        my_logits = result["logits"]
        
        loss = torch.tensor(0.0, device=self.device, requires_grad=True)
        
        # æ•™å¸«ã‚ã‚Šå­¦ç¿’ (Commanderã¯å¸¸ã«å¯èƒ½, Scoutã¯ç¨€)
        if label is not None:
            loss = loss + self.criterion(my_logits, label)
            
        # ç¤¾ä¼šçš„å­¦ç¿’ (ScoutãŒCommanderã‹ã‚‰å­¦ã¶)
        if peer_logits is not None and self.role == "Scout":
            T = 3.0
            teacher_probs = F.softmax(peer_logits / T, dim=-1)
            my_log_probs = F.log_softmax(my_logits / T, dim=-1)
            loss = loss + self.distill_loss(my_log_probs, teacher_probs) * (T**2) * 5.0
            
        loss.backward()
        self.optimizer.step()
        
        # ç–²åŠ´è“„ç©
        self.fatigue += 0.05
        if result["system"] == "System 2":
            self.fatigue += 0.15 # æ·±ãè€ƒãˆã‚‹ã¨ç–²ã‚Œã‚‹

    def add_memory(self, tokens: torch.Tensor, label: int, is_important: bool):
        """é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã‚’æµ·é¦¬ã¸"""
        if is_important:
            mem_tokens = tokens.cpu()
            mem_label = torch.tensor([label]).cpu()
            self.sleep_system.store_experience(mem_tokens, mem_label, 1.0)

    def sleep_if_tired(self):
        """ç–²åŠ´ã—ãŸã‚‰çœ ã‚‹"""
        if self.fatigue >= 1.0:
            print(f"   ğŸ’¤ {self.name} is entering Deep Sleep cycle...")
            summary = self.sleep_system.perform_sleep_cycle(duration_cycles=2)
            consolidated = summary.get('consolidated_to_cortex', 0)
            print(f"      -> {self.name} consolidated {consolidated} memories. Brain optimized.")
            self.fatigue = 0.0
            return True
        return False

    def update_stats(self, pred: int, label: int):
        self.accuracy_history.append(1 if pred == label else 0)
        if len(self.accuracy_history) > 50:
            self.accuracy_history.pop(0)

    @property
    def current_accuracy(self) -> float:
        if not self.accuracy_history: return 0.0
        return sum(self.accuracy_history) / len(self.accuracy_history) * 100


# --- 3. ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ (Environment) ---

class UnifiedMission:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
        print("="*60)
        print(f"ğŸŒŒ PROJECT OMEGA: AGI Prototype Initialization")
        print(f"ğŸ“ Device: {self.device}")
        print("="*60)
        
        self._load_data()
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”Ÿæˆ
        self.commander = Operator("Alpha (Cmdr)", "Commander", self.device)
        self.scout = Operator("Beta (Scout)", "Scout", self.device)
        
        print("\nğŸ¤– TEAM ROSTER:")
        print(f"   1. {self.commander.name}: High Spec, Full Access. Uses System 2.")
        print(f"   2. {self.scout.name}: Agile, Learning. Relies on Alpha.")

    def _load_data(self):
        print("ğŸ“¥ Loading Mission Data (MNIST)...")
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
        self.dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
        self.data_iter = iter(self.dataloader)

    def pre_mission_briefing(self):
        """å¸ä»¤å®˜(Alpha)ã«äº‹å‰çŸ¥è­˜ã‚’ä¸ãˆã‚‹"""
        print("\nğŸ“š [Phase 0] Pre-Mission Briefing for Alpha...")
        
        # çŸ­æœŸé›†ä¸­å­¦ç¿’
        briefing_steps = 100
        loader = DataLoader(self.dataloader.dataset, batch_size=32, shuffle=True)
        iter_brief = iter(loader)
        
        for _ in range(briefing_steps // 32):
            try:
                imgs, lbls = next(iter_brief)
            except: break
            imgs, lbls = imgs.to(self.device), lbls.to(self.device)
            self.commander.learn(imgs, lbls)
            
        print("   âœ… Alpha is ready. Mission Start.")

    def run_mission(self, steps: int = 30):
        self.pre_mission_briefing()
        
        print(f"\nğŸš€ [Phase 1] Mission Start: Exploring the Noise Field ({steps} steps)")
        print(f"{'Step':<4} | {'Target':<6} | {'Alpha':<18} | {'Beta':<18} | {'Event Log'}")
        print("-" * 85)
        
        for step in range(1, steps + 1):
            # 1. ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            try:
                image, label = next(self.data_iter)
            except StopIteration:
                self.data_iter = iter(self.dataloader)
                image, label = next(self.data_iter)
            
            label_val = label.item()
            image = image.to(self.device)
            label = label.to(self.device)
            
            # 2. ç•°å¸¸ç™ºç”Ÿ (ãƒã‚¤ã‚º)
            is_anomaly = (random.random() < 0.3)
            if is_anomaly:
                noise = torch.randn_like(image) * 0.8
                image = image + noise
                event_log = "âš ï¸ ANOMALY DETECTED"
            else:
                event_log = "   Normal Scan"
                
            # 3. Alpha (å¸ä»¤å®˜) ã®è¡Œå‹•
            res_alpha = self.commander.process_data(image, is_anomaly)
            pred_alpha = torch.argmax(res_alpha["logits"], dim=-1).item()
            
            # Alphaã¯å¸¸ã«æ­£è§£ã‚’è¦‹ã¦å­¦ç¿’ã—ã€çµŒé¨“ã‚’ç©ã‚€
            self.commander.learn(image, label)
            self.commander.update_stats(pred_alpha, label_val)
            
            # 4. Beta (ã‚¹ã‚«ã‚¦ãƒˆ) ã®è¡Œå‹•
            res_beta = self.scout.process_data(image, is_anomaly) # Betaã¯è‡ªåŠ›ã§è€ƒãˆã‚‹
            pred_beta = torch.argmax(res_beta["logits"], dim=-1).item()
            
            # Betaã®åˆ¤æ–­ãƒ­ã‚¸ãƒƒã‚¯
            beta_action = ""
            beta_learn_target = None
            beta_teacher_logits = None
            
            # BetaãŒé–“é•ã£ã¦ã„ã‚‹ã€ã¾ãŸã¯è‡ªä¿¡ãŒãªã„(System 2èµ·å‹•ãªã©)å ´åˆã€Alphaã«é€šä¿¡
            # (ã“ã“ã§ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€Anomalyæ™‚ã¯å¿…ãšé€šä¿¡)
            if is_anomaly or res_beta["system"] == "System 2":
                event_log += " -> ğŸ“¡ Beta requesting backup"
                beta_teacher_logits = res_alpha["logits"].detach()
                beta_action = "(Help)"
                # é‡è¦ãªçµŒé¨“ã¨ã—ã¦è¨˜æ†¶
                self.scout.add_memory(res_beta["tokens"], label_val, True)
            else:
                # å¹³æ™‚ã¯è‡ªåŠ›å­¦ç¿’ (æ­£è§£ãƒ©ãƒ™ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯ç¨€: 10%)
                if random.random() < 0.1:
                    beta_learn_target = label
                    beta_action = "(Self)"
            
            # Betaã®å­¦ç¿’å®Ÿè¡Œ
            self.scout.learn(image, beta_learn_target, beta_teacher_logits)
            self.scout.update_stats(pred_beta, label_val)
            
            # 5. çµæœè¡¨ç¤º
            alpha_str = f"{pred_alpha} [{res_alpha['system']:^8}]"
            beta_str = f"{pred_beta} [{res_beta['system']:^8}] {beta_action}"
            
            # æ­£è§£åˆ¤å®šãƒãƒ¼ã‚¯
            alpha_mark = "âœ…" if pred_alpha == label_val else "âŒ"
            beta_mark = "âœ…" if pred_beta == label_val else "âŒ"
            
            print(f"{step:<4} | {label_val:<6} | {alpha_mark} {alpha_str} | {beta_mark} {beta_str} | {event_log}")
            
            # 6. ç¡çœ ç®¡ç† (è‡ªå¾‹æ€§)
            self.commander.sleep_if_tired()
            self.scout.sleep_if_tired()
            
            time.sleep(0.1)

        print("-" * 85)
        print("ğŸ Mission Complete.")
        print(f"   ğŸ‘®â€â™‚ï¸ Alpha Accuracy: {self.commander.current_accuracy:.1f}%")
        print(f"   ğŸ•µï¸â€â™‚ï¸ Beta Accuracy:  {self.scout.current_accuracy:.1f}% (Learned via collaboration)")


if __name__ == "__main__":
    mission = UnifiedMission()
    mission.run_mission(steps=40)