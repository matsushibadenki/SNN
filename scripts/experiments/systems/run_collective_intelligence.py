# „Éï„Ç°„Ç§„É´„Éë„Çπ: scripts/experiments/systems/run_collective_intelligence.py
# Êó•Êú¨Ë™û„Çø„Ç§„Éà„É´: Collective Intelligence Simulation (LDP) - Type Fixed
# ‰øÆÊ≠£ÂÜÖÂÆπ: ArchitectureRegistry.build „ÅÆÊàª„ÇäÂÄ§„Çí SpikingWorldModel „Å´„Ç≠„É£„Çπ„Éà„ÄÇ

import os
import sys
import torch
import logging
from typing import cast, Tuple

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„Çí„Éë„Çπ„Å´ËøΩÂä†
sys.path.append(os.getcwd())

from snn_research.core.architecture_registry import ArchitectureRegistry
from snn_research.models.experimental.brain_v4 import SynestheticBrain
from snn_research.models.experimental.world_model_snn import SpikingWorldModel
from snn_research.agent.synesthetic_agent import SynestheticAgent
from snn_research.social.theory_of_mind import TheoryOfMindModule
from snn_research.collective.liquid_democracy import LiquidDemocracyProtocol

# „É≠„ÇÆ„É≥„Ç∞Ë®≠ÂÆö
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("CollectiveSim")

def create_agent(name: str, device: str, noise_level: float = 0.0) -> Tuple[SynestheticAgent, TheoryOfMindModule, float]:
    """
    „Ç®„Éº„Ç∏„Çß„É≥„Éà„Å®„ÄÅ„Åù„ÅÆToM„É¢„Ç∏„É•„Éº„É´„ÇíÁîüÊàê„Åô„Çã„Éï„Ç°„ÇØ„Éà„É™Èñ¢Êï∞„ÄÇ
    noise_level„ÅåÈ´ò„ÅÑ„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØÂà§Êñ≠„ÇíË™§„Çä„ÇÑ„Åô„ÅÑÔºàÔºùÁ¥†‰∫∫Ôºâ„ÄÇ
    """
    # 1. Brain & WM (Small config for simulation)
    brain = SynestheticBrain(
        vocab_size=100, d_model=32, num_layers=1, time_steps=4, device=device
    )
    wm_config = {
        'd_model': 32, 'd_state': 16, 'num_layers': 1, 'time_steps': 4, 
        'action_dim': 1, 'sensory_configs': {'vision': 32}
    }
    # mypy fix: Explicit cast to SpikingWorldModel
    wm_module = ArchitectureRegistry.build("spiking_world_model", wm_config, 0).to(device)
    wm = cast(SpikingWorldModel, wm_module)
    
    # 2. Agent Wrapper
    agent = SynestheticAgent(brain, wm, action_dim=1, device=device)
    
    # 3. Theory of Mind
    tom = TheoryOfMindModule(observation_dim=4, hidden_dim=16, history_len=5).to(device)
    
    return agent, tom, noise_level

def generate_task_data(batch_size: int, input_dim: int, device: str):
    """
    „Çø„Çπ„ÇØ: „É©„É≥„ÉÄ„É†„Å™„Éô„ÇØ„Éà„É´„ÇíÂÖ•Âäõ„Åó„ÄÅ„Åù„ÅÆ„ÄåÂπ≥ÂùáÂÄ§„ÅåÊ≠£„ÅãË≤†„Åã„Äç„ÇíÂΩì„Å¶„Çã„Éê„Ç§„Éä„É™ÂàÜÈ°û„ÄÇ
    """
    data = torch.randn(batch_size, input_dim, device=device)
    # Ê≠£Ëß£: Âπ≥Âùá„Åå0„Çà„ÇäÂ§ß„Åç„Åë„Çå„Å∞1, „Åù„Çå‰ª•Â§ñ„ÅØ0
    labels = (data.mean(dim=1) > 0).long()
    return data, labels

def main():
    logger.info("üêù Starting Collective Intelligence Simulation (Liquid Democracy)...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    num_rounds = 30
    input_dim = 32
    
    # --- 1. Agent Population Setup ---
    # 5‰Ωì„ÅÆ„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí‰ΩúÊàê„ÄÇËÉΩÂäõ(„Éé„Ç§„Ç∫ËÄêÊÄß)„Å´Â∑Æ„Çí„Å§„Åë„Çã„ÄÇ
    agent_configs = [
        ("Expert_A", 0.0),   # ÈùûÂ∏∏„Å´ÂÑ™ÁßÄ (Noise 0)
        ("Average_B", 0.5),  # ÊôÆÈÄö
        ("Average_C", 0.5),
        ("Novice_D", 1.0),   # Âà§Êñ≠„Åå„É©„É≥„ÉÄ„É†„Å´Ëøë„ÅÑ
        ("Novice_E", 1.0)
    ]
    
    agents = {}
    toms = {}
    noise_profiles = {}
    
    for name, noise in agent_configs:
        agent, tom, n_level = create_agent(name, device, noise)
        agents[name] = agent
        toms[name] = tom
        noise_profiles[name] = n_level
        logger.info(f"   - Created Agent: {name} (Noise Level: {n_level})")

    # --- 2. Initialize Protocol ---
    ldp = LiquidDemocracyProtocol(agents, toms)
    
    history_accuracy = []
    delegation_counts = []
    
    # --- 3. Simulation Loop ---
    for round_idx in range(num_rounds):
        # „Çø„Çπ„ÇØÁîüÊàê
        task_input, label = generate_task_data(1, input_dim, device)
        task_input = task_input[0] # (D,)
        ground_truth = label[0].item()
        
        result = ldp.conduct_vote(task_input, ground_truth)
        
        # „É≠„Ç∞
        acc = 1.0 if result['correct'] else 0.0
        history_accuracy.append(acc)
        delegation_counts.append(result['delegation_count'])
        
        logger.info(f"Round {round_idx+1}: Consensus={result['consensus_decision']} (Truth={ground_truth}) "
                    f"| Delegations={result['delegation_count']} | Correct={result['correct']}")

    # --- 4. Result Analysis ---
    avg_acc = sum(history_accuracy) / len(history_accuracy)
    avg_del = sum(delegation_counts) / len(delegation_counts)
    
    logger.info("\nüìä Simulation Result:")
    logger.info(f"   Average Accuracy: {avg_acc:.2%}")
    logger.info(f"   Avg Delegation Count: {avg_del:.1f} / {len(agents)}")
    
    if avg_acc > 0.6:
        logger.info("‚úÖ Collective Intelligence Emerged! The group performed better than random.")
    else:
        logger.info("‚ö†Ô∏è Performance Low. Agents need more training to trust experts.")

if __name__ == "__main__":
    main()