# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/experiments/brain/run_phase2_autonomous_agent.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Phase 2 è‡ªå¾‹çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Scaled & Multimodal) v1.4
# ç›®çš„: Phase 2ã®æˆæœçµ±åˆã€‚è¨˜æ†¶å½¢æˆã¨ç¡çœ å›ºå®šåŒ–ã®é€£æºã‚’ä¿®æ­£ã€‚
# ä¿®æ­£å±¥æ­´:
#   v1.4: act_and_adaptå†…ã§ sleep_system.store_experience ã‚’å‘¼ã³å‡ºã—ã€è¨˜æ†¶ã‚’ä¿å­˜ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã€‚

import sys
import os
import time
import logging
import torch
import numpy as np
from typing import Dict, Any, Optional, Union

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
project_root = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../../../"))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š (force=Trueã§å¼·åˆ¶é©ç”¨)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [Agent] %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)
logger = logging.getLogger("Phase2Agent")

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from snn_research.core.snn_core import SNNCore
    from snn_research.adaptive.intrinsic_motivator import IntrinsicMotivator
    from snn_research.cognitive_architecture.sleep_consolidation import SleepConsolidator
    from snn_research.io.universal_encoder import UniversalSpikeEncoder
except ImportError as e:
    logger.error(f"âŒ Import Error: {e}")
    print("Please ensure you are running this script from the project root or correct path.")
    sys.exit(1)


class Phase2AutonomousAgent:
    """
    Phase 2 ç›®æ¨™é”æˆã®ãŸã‚ã®çµ±åˆè‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
    ç‰¹å¾´:
    1. Scaled Brain: d_model=512 ã®å¤§è¦æ¨¡SFormerã‚’ä½¿ç”¨ã€‚
    2. Multimodal: è¦–è¦šã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ±åˆå‡¦ç†ã€‚
    3. Autonomous: å¥½å¥‡å¿ƒã¨ç¡çœ ã‚µã‚¤ã‚¯ãƒ«ã«ã‚ˆã‚‹è‡ªå¾‹åˆ¶å¾¡ã€‚
    """

    def __init__(self, device: Optional[str] = None):
        self.device = device if device else (
            "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
        logger.info(f"ğŸ§  Initializing Phase 2 Agent on {self.device}...")

        # 1. è„³ã®æ§‹ç¯‰ (Scaled SFormer)
        self.brain_config = {
            "architecture_type": "sformer",  # Spiking Transformer
            "d_model": 512,                  # Scale Up Goal
            "num_layers": 4,
            "nhead": 8,
            "time_steps": 8,
            "neuron_config": {"type": "lif", "v_threshold": 1.0},
            "vocab_size": 1000
        }
        self.brain = SNNCore(config=self.brain_config,
                             vocab_size=1000).to(self.device)
        logger.info(
            f"   -> Brain Model: SFormer (d_model={self.brain_config['d_model']}) initialized.")

        # 2. æ„Ÿè¦šå™¨ (Universal Encoder)
        self.encoder = UniversalSpikeEncoder()

        # 3. æœ¬èƒ½ (Curiosity & Motivation)
        self.motivator = IntrinsicMotivator(
            config={"curiosity_threshold": 0.3})

        # 4. æ’å¸¸æ€§ (Sleep System)
        self.sleep_system = SleepConsolidator(
            target_brain_model=self.brain
        )

        # çŠ¶æ…‹ç®¡ç†
        self.fatigue_level = 0.0
        self.knowledge_base = []
        self.step_count = 0

    def perceive(self, sensory_input: Dict[str, Any]) -> tuple[torch.Tensor, torch.Tensor]:
        """å¤šæ„Ÿè¦šçµ±åˆãƒ—ãƒ­ã‚»ã‚¹"""
        # è¦–è¦šæƒ…å ±ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        if "image" in sensory_input:
            visual_spikes = self.encoder.encode(
                sensory_input["image"], modality="image"
            ).to(self.device)
        else:
            visual_spikes = torch.zeros(1, 8, 512).to(self.device)

        # ãƒ†ã‚­ã‚¹ãƒˆ/æ¦‚å¿µæƒ…å ±ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        if "text_id" in sensory_input:
            concept_input = torch.tensor(
                [[sensory_input["text_id"]]]).to(self.device)
        else:
            concept_input = torch.zeros(1, 1).long().to(self.device)

        return visual_spikes, concept_input

    def think(self, visual_spikes: torch.Tensor, concept_input: torch.Tensor) -> torch.Tensor:
        """æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ (æ¨è«–)"""
        start_time = time.time()

        # è„³ã«ã‚ˆã‚‹å‡¦ç†
        raw_output = self.brain(concept_input)
        
        output_spikes: torch.Tensor
        if isinstance(raw_output, tuple):
            output_spikes = raw_output[0]
        elif isinstance(raw_output, dict):
             if 'logits' in raw_output:
                 output_spikes = raw_output['logits']
             elif 'spikes' in raw_output:
                 output_spikes = raw_output['spikes']
             else:
                 output_spikes = list(raw_output.values())[0] # type: ignore
        else:
            output_spikes = raw_output

        latency = (time.time() - start_time) * 1000
        logger.info(f"   âš¡ Thought Latency: {latency:.2f} ms")

        return output_spikes

    def act_and_adapt(self, output: torch.Tensor):
            """è¡Œå‹•ã¨é©å¿œï¼ˆå¥½å¥‡å¿ƒãƒ»ç–²åŠ´ãƒ»è¨˜æ†¶å½¢æˆï¼‰"""
            try:
                if output.numel() > 1:
                    novelty = torch.var(output.float()).item()
                else:
                    novelty = 0.0
            except Exception:
                novelty = 0.0

            # å¥½å¥‡å¿ƒåˆ¤å®š (ç°¡æ˜“é–¾å€¤)
            is_curious = novelty > 0.01

            if is_curious:
                logger.info("   ğŸ” Curiosity Triggered! Forming new memory...")
                self.knowledge_base.append("New Pattern Discovered")
            
                # [ä¿®æ­£ç®‡æ‰€]
                # output(logits/float) ã‚’ãã®ã¾ã¾ä¿å­˜ã›ãšã€äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³ID(long)ã«å¤‰æ›ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
                # ã“ã‚Œã«ã‚ˆã‚Šã€ç¡çœ å­¦ç¿’(SFormer)ã§ã®Embeddingå…¥åŠ›ã‚¨ãƒ©ãƒ¼ã‚’é˜²ãã¾ã™ã€‚
                with torch.no_grad():
                    # argmaxã§æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„IDã‚’å–å¾—ã—ã€CPUã¸è»¢é€
                    dummy_state = torch.argmax(output, dim=-1).long().cpu()
                
                    # ä¸‡ãŒä¸€å½¢çŠ¶ãŒã‚¹ã‚«ãƒ©ãƒ¼ã«ãªã£ã¦ã—ã¾ã£ãŸå ´åˆã®æ¬¡å…ƒèª¿æ•´
                    if dummy_state.dim() == 0:
                        dummy_state = dummy_state.unsqueeze(0)
                    if dummy_state.dim() == 1:
                        dummy_state = dummy_state.unsqueeze(0)  # (1, SeqLen)

                    dummy_text = torch.tensor([1]).cpu() # Dummy ID
                    reward_val = 1.0 # Positive reward for curiosity
                
                    self.sleep_system.store_experience(
                        image=dummy_state, # ã“ã“ã§å¤‰æ›æ¸ˆã¿ã®IDã‚’æ¸¡ã™
                        text=dummy_text,
                        reward=reward_val
                    )

            # ç–²åŠ´ã®è“„ç©
            self.fatigue_level += 0.1
            logger.info(f"   ğŸ”‹ Fatigue Level: {self.fatigue_level:.1f}/1.0")
            
    def run_life_cycle(self, max_steps: int = 15):
        """è‡ªå¾‹ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã®å®Ÿè¡Œ"""
        logger.info("ğŸš€ Starting Autonomous Life Cycle")

        for step in range(max_steps):
            self.step_count += 1
            print(f"\n--- Step {self.step_count} ---")

            # 0. ç¡çœ ãƒã‚§ãƒƒã‚¯
            if self.fatigue_level >= 0.8:
                logger.info("ğŸ’¤ Fatigue limit reached. Initiating Sleep...")
                
                # è¨˜æ†¶ãŒã‚ã‚‹çŠ¶æ…‹ã§ç¡çœ ã‚’å®Ÿè¡Œ
                summary = self.sleep_system.perform_sleep_cycle(
                    duration_cycles=3
                )
                
                # ç¡çœ çµæœã®è¡¨ç¤º
                if summary.get("status") == "success":
                    consolidated = summary.get("consolidated_to_cortex", 0)
                    logger.info(f"   -> Sleep Successful: Consolidated {consolidated} memories to Long-term Cortex.")
                else:
                    logger.info(f"   -> Sleep Finished: {summary}")
                
                self.fatigue_level = 0.0
                continue

            # 1. ç’°å¢ƒã‹ã‚‰ã®å…¥åŠ›
            dummy_input = {
                "image": torch.randn(1, 3, 32, 32),
                "text_id": np.random.randint(0, 1000)
            }

            # 2. çŸ¥è¦š
            vis, txt = self.perceive(dummy_input)

            # 3. æ€è€ƒ
            output = self.think(vis, txt)

            # 4. è¡Œå‹•ã¨é©å¿œ
            self.act_and_adapt(output)

            time.sleep(0.1)

        logger.info("ğŸ Life cycle simulation completed.")


if __name__ == "__main__":
    try:
        agent = Phase2AutonomousAgent()
        agent.run_life_cycle(max_steps=15)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Simulation stopped by user.")
    except Exception as e:
        logger.error(f"âŒ Fatal Error: {e}")
        import traceback
        traceback.print_exc()