# scripts/experiments/brain/run_emotion_curriculum_v2.py
# æ—¥æœ¬èªžã‚¿ã‚¤ãƒˆãƒ«: æ„Ÿæƒ…é§†å‹•åž‹ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’ v2 (æ¤œè¨¼ä»˜ã)
# ç›®çš„: 1. é«˜ã„åŸºç¤Žèƒ½åŠ›(Vision)ã‚’ç²å¾—ã•ã›ã‚‹ã€‚
#       2. æ­£ã—ã„ä¾¡å€¤è¦³(Amygdala)ã‚’å½¢æˆã™ã‚‹ã€‚
#       3. ãƒ©ãƒ™ãƒ«ãªã—è‡ªå¾‹å­¦ç¿’(Value Pursuit)ã‚’è¡Œã„ã€ãã®åŠ¹æžœã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã™ã‚‹ã€‚

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms

sys.path.append(os.path.join(os.path.dirname(__file__), "../../.."))

from snn_research.models.hybrid.emotional_concept_brain import EmotionalConceptBrain

def evaluate_accuracy(model, loader, device):
    """ãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ã®æ­£è§£çŽ‡ã‚’è¨ˆæ¸¬ã™ã‚‹ï¼ˆå­¦ç¿’ã¯ã—ãªã„ï¼‰"""
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            logits, _ = model(imgs)
            preds = logits.argmax(dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return correct / total

def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if torch.backends.mps.is_available(): device = "mps"
    print(f"Running Emotion Curriculum Learning v2 on {device}...")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (MNIST Full)
    transform = transforms.Compose([
        transforms.Resize((28, 28)),
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    full_data = datasets.MNIST('./data', train=True, download=True, transform=transform)
    test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)
    
    # ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã—ã¦åŸºç¤Žã‚’å›ºã‚ã‚‹ (10000æžš)
    train_subset = Subset(full_data, range(10000))
    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)

    # è„³ãƒ¢ãƒ‡ãƒ«
    brain = EmotionalConceptBrain(num_classes=10).to(device)
    
    # ==========================================
    # Stage 1: Vision Pre-training (Cortex Only)
    # ==========================================
    print("\n>>> Stage 1: Vision Pre-training (Acquiring Sight) <<<")
    # å­¦ç¿’çŽ‡èª¿æ•´
    optimizer_cortex = torch.optim.Adam(brain.cortex.parameters(), lr=0.001)
    
    # 80%ã‚’è¶…ãˆã‚‹ã¾ã§ã€ã‚ã‚‹ã„ã¯æœ€å¤§20ã‚¨ãƒãƒƒã‚¯ã‚„ã‚‹
    for epoch in range(20):
        brain.cortex.train()
        total_loss = 0
        
        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            logits, _ = brain(imgs)
            loss = nn.CrossEntropyLoss()(logits, labels)
            
            optimizer_cortex.zero_grad()
            loss.backward()
            optimizer_cortex.step()
            total_loss += loss.item()
            
        # ç²¾åº¦ãƒã‚§ãƒƒã‚¯
        val_acc = evaluate_accuracy(brain, test_loader, device)
        print(f"Epoch {epoch+1}: Test Acc = {val_acc:.2%} | Loss = {total_loss/len(train_loader):.4f}")
        
        if val_acc > 0.85: # 85%è¶…ãˆãŸã‚‰ååˆ†
            print("-> Vision acquired! Moving to next stage.")
            break

    # ==========================================
    # Stage 2: Value Alignment (Amygdala Only)
    # ==========================================
    print("\n>>> Stage 2: Value Alignment (Forming Values) <<<")
    # Cortexå›ºå®š
    for param in brain.cortex.parameters():
        param.requires_grad = False
    
    optimizer_amygdala = torch.optim.Adam(brain.amygdala.parameters(), lr=0.002)
    
    for epoch in range(5):
        brain.amygdala.train()
        total_val_loss = 0
        
        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            
            # é †ä¼æ’­
            logits, emotion = brain(imgs)
            
            # æ­£è§£åˆ¤å®š
            preds = logits.argmax(dim=1)
            is_correct = (preds == labels).float().unsqueeze(1)
            
            # æ­£è§£ãªã‚‰+1.0, ä¸æ­£è§£ãªã‚‰-1.0
            target_value = is_correct * 2.0 - 1.0
            
            loss = nn.MSELoss()(emotion, target_value)
            
            optimizer_amygdala.zero_grad()
            loss.backward()
            optimizer_amygdala.step()
            total_val_loss += loss.item()
            
        print(f"Epoch {epoch+1}: Amygdala Loss = {total_val_loss/len(train_loader):.4f}")

    # ==========================================
    # Stage 3: Value Pursuit (Autonomous Learning)
    # ==========================================
    print("\n>>> Stage 3: Autonomous Value Pursuit (NO LABELS!) <<<")
    print("Hypothesis: Improving 'Emotion' autonomously will improve 'Test Accuracy'.")
    
    # Amygdalaå›ºå®šã€Cortexå­¦ç¿’å†é–‹
    for param in brain.amygdala.parameters():
        param.requires_grad = False
    for param in brain.cortex.parameters():
        param.requires_grad = True
        
    optimizer_pursuit = torch.optim.Adam(brain.cortex.parameters(), lr=0.0001) # æ…Žé‡ã«æ›´æ–°
    
    initial_acc = evaluate_accuracy(brain, test_loader, device)
    print(f"Initial Test Acc: {initial_acc:.2%}")
    
    brain.train()
    brain.amygdala.eval()
    
    for epoch in range(10):
        emotion_stats = []
        
        for imgs, _ in train_loader: # ãƒ©ãƒ™ãƒ«ã¯è¦‹ãªã„ï¼
            imgs = imgs.to(device)
            
            logits, emotion = brain(imgs)
            emotion_stats.extend(emotion.detach().cpu().numpy().flatten())
            
            # ä¾¡å€¤æœ€å¤§åŒ– (Maximize Emotion)
            # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ã§ã€Œè‡ªä¿¡ã‚’æŒã£ãŸåˆ¤æ–­ã€ã‚’ä¿ƒã™
            probs = F.softmax(logits, dim=1)
            entropy = -(probs * torch.log(probs + 1e-9)).sum(dim=1).mean()
            
            # Loss = -Emotion + entropy_penalty
            loss = -emotion.mean() + 0.1 * entropy
            
            optimizer_pursuit.zero_grad()
            loss.backward()
            optimizer_pursuit.step()
            
        # è©•ä¾¡
        avg_emo = np.mean(emotion_stats)
        current_acc = evaluate_accuracy(brain, test_loader, device)
        
        print(f"Epoch {epoch+1}: Emotion Avg = {avg_emo:.4f} | Test Acc = {current_acc:.2%} (Delta: {current_acc - initial_acc:+.2%})")
        
        if current_acc > initial_acc:
            print("   -> ðŸŒŸ EUREKA! Autonomous improvement confirmed!")

    print("Experiment Complete.")

if __name__ == "__main__":
    main()