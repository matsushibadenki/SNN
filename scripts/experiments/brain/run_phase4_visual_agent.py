# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/experiments/brain/run_phase4_visual_agent.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Phase 4 è¦–è¦šé‡æ­è¼‰ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Visual Cortex & MNIST)
# ç›®çš„: å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿(MNIST)ã‚’å…¥åŠ›ã¨ã—ã€è¦–è¦šãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’é€šã˜ã¦System 1/2ã§èªè­˜ãƒ»å­¦ç¿’ã‚’è¡Œã†ã€‚

import sys
import os
import time
import logging
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Tuple
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
project_root = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../../../"))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [VisualAgent] %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)
logger = logging.getLogger("VisualAgent")

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from snn_research.core.snn_core import SNNCore
    from snn_research.models.experimental.bit_spike_mamba import BitSpikeMamba
    from snn_research.cognitive_architecture.sleep_consolidation import SleepConsolidator
except ImportError as e:
    logger.error(f"âŒ Import Error: {e}")
    sys.exit(1)


class VisualTokenizer(nn.Module):
    """
    è¦–è¦šé‡ (Visual Cortex) ã®åˆæœŸæ®µéšã€‚
    ç”»åƒãƒ‘ãƒƒãƒã‚’å‡¦ç†ã—ã€è„³ãŒç†è§£ã§ãã‚‹ã€Œè¦–è¦šå˜èªï¼ˆVisual Tokensï¼‰ã€ã«é‡å­åŒ–ã™ã‚‹ã€‚
    """
    def __init__(self, vocab_size: int = 1000, patch_size: int = 4):
        super().__init__()
        # MNIST(28x28) -> 4x4ãƒ‘ãƒƒãƒ -> 7x7=49ãƒˆãƒ¼ã‚¯ãƒ³
        self.patch_conv = nn.Conv2d(1, vocab_size, kernel_size=patch_size, stride=patch_size)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x: (B, 1, 28, 28)
        # MPSå¯¾ç­–: ãƒ¡ãƒ¢ãƒªæ•´åˆ—
        if not x.is_contiguous():
            x = x.contiguous()
            
        # ç‰¹å¾´æŠ½å‡º: (B, Vocab, 7, 7)
        features = self.patch_conv(x)
        
        # ãƒ•ãƒ©ãƒƒãƒˆåŒ–: (B, Vocab, 49) -> (B, 49, Vocab)
        B, C, H, W = features.shape
        features = features.flatten(2).transpose(1, 2).contiguous()
        
        # é‡å­åŒ–: å„ãƒ‘ãƒƒãƒã§æœ€ã‚‚åå¿œã®å¼·ã„ãƒãƒ£ãƒãƒ«ã‚’ãƒˆãƒ¼ã‚¯ãƒ³IDã¨ã™ã‚‹
        # ã“ã‚Œã«ã‚ˆã‚Šã€SFormerç­‰ã®Embeddingå±¤ã«å…¥åŠ›å¯èƒ½ãªå½¢å¼(LongTensor)ã«ãªã‚‹
        visual_tokens = torch.argmax(features, dim=-1) # (B, 49)
        
        return visual_tokens


class VisualHybridBrain(nn.Module):
    """
    è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡¦ç†ã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è„³ã€‚
    """
    def __init__(self, device: str, vocab_size: int = 1000):
        super().__init__()
        self.device = device
        
        # 1. è¦–è¦šé‡ (Visual Cortex)
        logger.info("   ğŸ‘ï¸ Initializing Visual Cortex (Tokenizer)...")
        self.visual_cortex = VisualTokenizer(vocab_size=vocab_size, patch_size=4).to(device)
        
        # 2. System 1: SFormer (é«˜é€Ÿè¦–è¦šå‡¦ç†)
        logger.info("   ğŸ§  Initializing System 1: SFormer (Visual Reflex)...")
        sformer_config = {
            "architecture_type": "sformer",
            "d_model": 256,
            "num_layers": 2,
            "nhead": 4,
            "time_steps": 4,
            "neuron_config": {"type": "lif", "v_threshold": 1.0}
        }
        # å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã¯ 7x7=49
        self.system1 = SNNCore(config=sformer_config, vocab_size=vocab_size).to(device)
        
        # 3. System 2: BitSpikeMamba (è©³ç´°åˆ†æ)
        logger.info("   ğŸ§  Initializing System 2: BitSpikeMamba (Visual Reasoning)...")
        self.system2 = BitSpikeMamba(
            vocab_size=vocab_size,
            d_model=256,
            d_state=16,
            d_conv=4,
            expand=2,
            num_layers=4,
            time_steps=8,
            neuron_config={"type": "lif", "base_threshold": 1.0}
        ).to(device)
        
        # 4. å‡ºåŠ›å±¤ (æ•°å­—0-9ã®åˆ†é¡)
        self.classifier = nn.Linear(256, 10).to(device)
        
        # 5. ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ (ä¸ç¢ºå®Ÿæ€§ã«åŸºã¥ãåˆ‡ã‚Šæ›¿ãˆ)
        # System 1 ã®å‡ºåŠ›(Vocabæ¬¡å…ƒ)ã‹ã‚‰åˆ¤æ–­
        self.gating_network = nn.Sequential(
            nn.Linear(vocab_size, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        ).to(device)

    def forward(self, image: torch.Tensor, noise_level: float = 0.0) -> Dict[str, Any]:
        # è¦–è¦šé‡ã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        visual_tokens = self.visual_cortex(image) # (B, 49)
        
        # System 1 å®Ÿè¡Œ
        sys1_feats = self.system1(visual_tokens) # (B, Seq, Vocab)
        if isinstance(sys1_feats, tuple): sys1_feats = sys1_feats[0]
        
        # ç‰¹å¾´é‡ã®å¹³å‡åŒ– (Classificationç”¨)
        # ã“ã“ã§ã¯å˜ç´”åŒ–ã®ãŸã‚ã€Vocabæ¬¡å…ƒã‚’ç‰¹å¾´é‡ã¨ã—ã¦æ‰±ã†
        sys1_pooled = sys1_feats.mean(dim=1) # (B, Vocab)
        
        # ã‚²ãƒ¼ãƒˆåˆ¤æ–­
        gate_score = self.gating_network(sys1_pooled).mean().item()
        
        # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ãŒé«˜ã„å ´åˆã‚„ã€System 1ãŒè‡ªä¿¡ãŒãªã„å ´åˆã¯System 2ã‚’èµ·å‹•
        # (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã€noise_levelã‚‚åˆ¤æ–­ã«åŠ ãˆã‚‹)
        use_system2 = gate_score > 0.6 or noise_level > 0.3
        
        used_system = "System 1"
        final_feats = sys1_pooled
        
        if use_system2:
            used_system = "System 2 (Activated)"
            sys2_feats = self.system2(visual_tokens)
            if isinstance(sys2_feats, tuple): sys2_feats = sys2_feats[0]
            
            # System 2ã®ç‰¹å¾´é‡ã¨System 1ã®ç‰¹å¾´é‡ã‚’çµ±åˆï¼ˆã“ã“ã§ã¯å˜ç´”ç½®æ›ï¼‰
            # æ¬¡å…ƒåˆã‚ã›: Mambaå‡ºåŠ›ã¯(B, Seq, D_model=256)æƒ³å®šã ãŒã€å®Ÿè£…ã«ã‚ˆã‚Šç•°ãªã‚‹ãŸã‚èª¿æ•´
            # BitSpikeMambaã®å‡ºåŠ›ã¯ (B, L, Vocab)
            
            final_feats = sys2_feats.mean(dim=1) # (B, Vocab)
        
        # æœ€çµ‚åˆ†é¡ (Vocabæ¬¡å…ƒ -> 256ã¸å°„å½±ãŒå¿…è¦ã ãŒã€ç°¡æ˜“çš„ã«Vocabæ¬¡å…ƒã®ä¸€éƒ¨ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€å†å°„å½±)
        # ã“ã“ã§ã¯ classifier ã®å…¥åŠ›æ¬¡å…ƒ(256)ã«åˆã‚ã›ã‚‹ãŸã‚ã€Vocab(1000) -> 256 ã®å°„å½±å±¤ã‚’é€šã™ã‹ã€ã‚¹ãƒ©ã‚¤ã‚¹ã™ã‚‹
        # ç°¡æ˜“å®Ÿè£…: Vocabæ¬¡å…ƒã®å…ˆé ­256ã‚’ä½¿ç”¨
        logits = self.classifier(final_feats[:, :256])
        
        return {
            "logits": logits,
            "system": used_system,
            "gate_score": gate_score,
            "visual_tokens": visual_tokens # è¨˜æ†¶ç”¨
        }


class Phase4VisualAgent:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
        logger.info(f"ğŸš€ Initializing Phase 4 Visual Agent on {self.device}...")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ (MNIST)
        self._prepare_data()
        
        # è„³ã®æ§‹ç¯‰
        self.brain = VisualHybridBrain(self.device).to(self.device)
        
        # ç¡çœ ã‚·ã‚¹ãƒ†ãƒ  (é•·æœŸè¨˜æ†¶)
        self.sleep_system = SleepConsolidator(
            target_brain_model=self.brain.system2
        )
        
        self.fatigue = 0.0
        self.steps = 0

    def _prepare_data(self):
        """MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰"""
        logger.info("   ğŸ“¥ Loading MNIST dataset...")
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒãªã„å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        try:
            dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
            self.dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
            self.data_iter = iter(self.dataloader)
        except Exception as e:
            logger.warning(f"   âš ï¸ Could not load MNIST: {e}. Using dummy noise data.")
            self.dataloader = None

    def get_visual_input(self) -> Tuple[torch.Tensor, int, float]:
        """ç’°å¢ƒã‹ã‚‰è¦–è¦šå…¥åŠ›ã‚’å–å¾—"""
        noise_level = 0.0
        
        if self.dataloader:
            try:
                image, label = next(self.data_iter)
            except StopIteration:
                self.data_iter = iter(self.dataloader)
                image, label = next(self.data_iter)
                
            # æ™‚ã€…ç”»åƒã«ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ï¼ˆé›£æ˜“åº¦ã‚¢ãƒƒãƒ— -> System 2 èµ·å‹•ç”¨ï¼‰
            if np.random.random() < 0.2:
                noise_level = 0.5
                noise = torch.randn_like(image) * noise_level
                image = image + noise
                logger.info("   ğŸŒªï¸ Input image is distorted/noisy!")
        else:
            # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            image = torch.randn(1, 1, 28, 28)
            label = torch.tensor([0])
            
        return image.to(self.device), label.item(), noise_level

    def run_life_cycle(self, max_steps: int = 15):
        logger.info("ğŸ¬ Starting Visual Life Cycle...")
        
        try:
            for _ in range(max_steps):
                self.steps += 1
                print(f"\n--- Step {self.steps} ---")
                
                # 1. çŸ¥è¦š (Perception)
                image, label, noise = self.get_visual_input()
                
                # 2. æ€è€ƒ (Thinking)
                start_time = time.time()
                result = self.brain(image, noise_level=noise)
                latency = (time.time() - start_time) * 1000
                
                prediction = torch.argmax(result["logits"], dim=-1).item()
                system_used = result["system"]
                
                # 3. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                is_correct = (prediction == label)
                result_str = "âœ… Correct" if is_correct else f"âŒ Wrong (Ans:{label})"
                
                logger.info(f"   ğŸ‘ï¸ Saw Digit: {label} | Prediction: {prediction} ({result_str})")
                logger.info(f"   ğŸ§  Processed by: {system_used}")
                logger.info(f"   âš¡ Latency: {latency:.2f} ms")
                
                # 4. å­¦ç¿’ã¨è¨˜æ†¶ (Learning & Memory)
                # é–“é•ãˆãŸå ´åˆã‚„ã€System 2ã‚’ä½¿ã£ãŸå ´åˆã¯å°è±¡ã«æ®‹ã‚‹ãŸã‚è¨˜æ†¶ã™ã‚‹
                if not is_correct or "System 2" in system_used:
                    logger.info("   ğŸ“ Notable event. Consolidating to Hippocampus...")
                    
                    # è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨˜æ†¶ã¨ã—ã¦ä¿å­˜ (MPSå¯¾ç­–ã§CPUã¸)
                    visual_memory = result["visual_tokens"].cpu() # (1, 49)
                    text_memory = torch.tensor([label]).cpu()     # æ­£è§£ãƒ©ãƒ™ãƒ«
                    reward = -1.0 if not is_correct else 1.0
                    
                    self.sleep_system.store_experience(
                        image=visual_memory,
                        text=text_memory,
                        reward=reward
                    )
                    self.fatigue += 0.25
                else:
                    self.fatigue += 0.05
                    
                logger.info(f"   ğŸ”‹ Fatigue: {self.fatigue:.2f}/1.0")
                
                # 5. ç¡çœ ãƒã‚§ãƒƒã‚¯
                if self.fatigue >= 1.0:
                    logger.info("ğŸ’¤ Visual Cortex exhausted. Sleeping...")
                    summary = self.sleep_system.perform_sleep_cycle(duration_cycles=2)
                    logger.info(f"   -> Sleep Summary: {summary}")
                    self.fatigue = 0.0
                    
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ Stopped by user.")
        except Exception as e:
            logger.error(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    agent = Phase4VisualAgent()
    agent.run_life_cycle(max_steps=20)