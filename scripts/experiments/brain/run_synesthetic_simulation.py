# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/experiments/brain/run_synesthetic_simulation.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Run Synesthetic Brain Simulation
# ç›®çš„: Brain v4 (äº”æ„Ÿçµ±åˆãƒ¢ãƒ‡ãƒ«) ã®å‹•ä½œæ¤œè¨¼ã€‚
#       è¦–è¦šã€è´è¦šã€è§¦è¦šã€å—…è¦šã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€çµ±åˆå‡¦ç†ã¨å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

from snn_research.utils.efficiency_profiler import EfficiencyProfiler
from snn_research.models.experimental.brain_v4 import SynestheticBrain
import os
import sys
import torch
import torch.nn as nn
import logging
from typing import Dict

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.getcwd())


# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SynesthesiaSim")


def generate_dummy_sensory_data(batch_size: int, seq_len: int, config: Dict) -> Dict[str, torch.Tensor]:
    """å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    data = {}
    device = config['device']

    # Vision: (B, T, C, H, W) or (B, C, H, W) based on encoder
    # ã“ã“ã§ã¯ç°¡æ˜“åŒ–ã®ãŸã‚ç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹ (B, seq_len, input_dim) ã¨ã™ã‚‹
    if 'vision' in config['sensory']:
        dim = config['sensory']['vision']
        data['vision'] = torch.randn(batch_size, seq_len, dim, device=device)

    # Audio
    if 'audio' in config['sensory']:
        dim = config['sensory']['audio']
        data['audio'] = torch.randn(batch_size, seq_len, dim, device=device)

    # Tactile (è§¦è¦š)
    if 'tactile' in config['sensory']:
        dim = config['sensory']['tactile']
        # è§¦è¦šã¯ã‚¹ãƒ‘ãƒ¼ã‚¹ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ãŒã€ã“ã“ã§ã¯ãƒ©ãƒ³ãƒ€ãƒ 
        data['tactile'] = torch.randn(batch_size, seq_len, dim, device=device)

    # Olfactory (å—…è¦š)
    if 'olfactory' in config['sensory']:
        dim = config['sensory']['olfactory']
        data['olfactory'] = torch.abs(torch.randn(
            batch_size, seq_len, dim, device=device))  # æ¿ƒåº¦ãªã®ã§æ­£ã®å€¤

    return data


def main():
    logger.info("ğŸš€ Starting Synesthetic Brain Simulation...")

    # --- Configuration ---
    device = "cuda" if torch.cuda.is_available() else "cpu"
    config = {
        'device': device,
        'vocab_size': 1000,
        'd_model': 128,
        'time_steps': 8,
        'sensory': {
            'vision': 784,
            'audio': 64,
            'tactile': 32,   # æ–°è¦è¿½åŠ 
            'olfactory': 16  # æ–°è¦è¿½åŠ 
        }
    }

    # --- Model Initialization ---
    logger.info(f"ğŸ§  Initializing Brain v4 on {device}...")
    model = SynestheticBrain(
        vocab_size=config['vocab_size'],
        d_model=config['d_model'],
        num_layers=2,  # ãƒ‡ãƒ¢ç”¨ã«è»½é‡åŒ–
        time_steps=config['time_steps'],
        tactile_dim=config['sensory']['tactile'],
        olfactory_dim=config['sensory']['olfactory'],
        device=device
    )

    # æœ€é©åŒ–è¨­å®š
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
    criterion = nn.CrossEntropyLoss()
    profiler = EfficiencyProfiler()

    # --- Simulation Loop ---
    num_steps = 5
    batch_size = 4
    seq_len = 1  # Brain v4ã®Encoderã¯å…¥åŠ›ã‚’å³æ™‚å‡¦ç†ã™ã‚‹æƒ³å®š(å†…éƒ¨ã§TimeStepså±•é–‹)

    model.train()

    for step in range(num_steps):
        logger.info(f"âš¡ Step {step+1}/{num_steps}")

        # 1. Generate Inputs (äº”æ„Ÿå…¥åŠ› + ãƒ†ã‚­ã‚¹ãƒˆæ€è€ƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ)
        sensory_data = generate_dummy_sensory_data(batch_size, seq_len, config)

        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ€è€ƒã®ç¨®ï¼‰
        text_input = torch.randint(
            0, config['vocab_size'], (batch_size, 16)).to(device)

        # æ­£è§£ãƒ©ãƒ™ãƒ«ï¼ˆæ¬¡ã®å˜èªäºˆæ¸¬ã‚¿ã‚¹ã‚¯ã¨ä»®å®šï¼‰
        targets = torch.randint(0, config['vocab_size'], (batch_size, 16)).to(
            device)  # é•·ã•ã¯text_input + sensory_contextåˆ†ãšã‚Œã‚‹ãŒç°¡æ˜“åŒ–

        # 2. Forward Pass
        profiler.start_measurement()

        # Brain v4 forward: äº”æ„Ÿã‚’å…¨ã¦æ¸¡ã™
        logits = model(
            text_input=text_input,
            image_input=sensory_data['vision'],
            audio_input=sensory_data['audio'],
            tactile_input=sensory_data['tactile'],
            olfactory_input=sensory_data['olfactory']
        )

        # Logits shape: [B, Total_Seq_Len, Vocab]
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã‚µã‚¤ã‚ºã‚’åˆã‚ã›ã‚‹ãŸã‚ã®ç°¡æ˜“ã‚¹ãƒ©ã‚¤ã‚¹ï¼ˆå®Ÿéš›ã¯ã‚·ãƒ•ãƒˆãŒå¿…è¦ï¼‰
        output_len = logits.size(1)
        target_len = targets.size(1)
        min_len = min(output_len, target_len)

        loss = criterion(logits[:, :min_len, :].reshape(-1, config['vocab_size']),
                         targets[:, :min_len].reshape(-1))

        # 3. Backward Pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        profiler.end_measurement()

        logger.info(f"   Loss: {loss.item():.4f}")
        logger.info(f"   Context Length: {output_len} (Sensory + Text)")

    # --- Generative Demo ---
    logger.info("ğŸ¨ Testing Generative Capability (Cross-Modal)...")
    model.eval()

    # ã€Œç”»åƒã€ã‚’è¦‹ã¦ã€Œè¨€è‘‰ã€ã‚’ç™ºã™ã‚‹ãƒ‡ãƒ¢
    test_image = torch.randn(1, 1, config['sensory']['vision'], device=device)
    start_token = 101  # BOS

    generated_ids = model.generate(
        image_input=test_image,
        start_token_id=start_token,
        max_new_tokens=10
    )

    logger.info(f"   Generated Tokens from Visual Input: {generated_ids}")
    logger.info("âœ… Simulation completed successfully.")


if __name__ == "__main__":
    main()
