# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/experiments/brain/run_synesthetic_life_cycle.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Synesthetic Life Cycle Simulation (Day & Night)
# ç›®çš„: è¦šé†’(æ¢ç´¢ãƒ»è¡Œå‹•)ã¨ç¡çœ (å¤¢ãƒ»è¨˜æ†¶å®šç€)ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å›ã—ã€
#       å˜ä¸€å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ãŒè‡ªå¾‹çš„ã«æˆé•·ã™ã‚‹éç¨‹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€‚

from snn_research.cognitive_architecture.synesthetic_sleep import SynestheticSleepManager
from snn_research.agent.synesthetic_agent import SynestheticAgent
from snn_research.models.experimental.brain_v4 import SynestheticBrain
from snn_research.core.architecture_registry import ArchitectureRegistry
import os
import sys
import torch
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.getcwd())


# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("LifeCycleSim")

# --- ç°¡æ˜“ç’°å¢ƒã‚¯ãƒ©ã‚¹ (å‰å›ã®æ‹¡å¼µ) ---


class DayNightEnvironment:
    def __init__(self, config):
        self.device = config['device']
        self.sensory_dims = config['sensory_configs']
        self.pos = torch.zeros(1, 2, device=self.device)
        self.target = torch.randn(1, 2, device=self.device)  # ç›®æ¨™åœ°ç‚¹
        self.step_count = 0

    def reset(self):
        self.pos = torch.zeros(1, 2, device=self.device)
        self.target = torch.randn(1, 2, device=self.device)
        return self._observe()

    def step(self, action: torch.Tensor):
        # è¡Œå‹•ã«ã‚ˆã‚‹ç§»å‹• (action: B, 2)
        move = torch.clamp(action, -1.0, 1.0) * 0.2
        self.pos += move

        # å ±é…¬: ç›®æ¨™ã«è¿‘ã„ã»ã©é«˜ã„
        dist = torch.dist(self.pos, self.target)
        reward = -dist  # è·é›¢ãŒè¿‘ã„ã»ã©0ã«è¿‘ã¥ãï¼ˆæœ€å¤§åŒ–ï¼‰

        done = dist < 0.1
        if done:
            self.target = torch.randn(1, 2, device=self.device)  # æ–°ã—ã„ç›®æ¨™

        return self._observe(), reward, done

    def _observe(self):
        # ç›®æ¨™ã¨ã®ç›¸å¯¾ä½ç½®ã‚’è¦–è¦šãƒ»è§¦è¦šã¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        rel_pos = self.target - self.pos

        obs = {}
        # Vision: ç›¸å¯¾ä½ç½®ã‚’è¦–è¦šãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–
        if 'vision' in self.sensory_dims:
            dim = self.sensory_dims['vision']
            obs['vision'] = torch.sin(
                rel_pos[0, 0] * torch.linspace(0, 10, dim, device=self.device)).view(1, 1, dim)

        # Tactile: å£(åº§æ¨™é™ç•Œ)ã«è¿‘ã„ã¨åå¿œ
        if 'tactile' in self.sensory_dims:
            dim = self.sensory_dims['tactile']
            wall_dist = 2.0 - torch.abs(self.pos).max()
            contact = (wall_dist < 0.2).float()
            obs['tactile'] = (torch.ones(
                1, 1, dim, device=self.device) * contact)

        return obs


def main():
    logger.info("ğŸŒ… Starting Synesthetic Life Cycle Simulation...")

    # 1. Configuration
    device = "cuda" if torch.cuda.is_available() else "cpu"
    config = {
        'device': device,
        'action_dim': 2,
        'vocab_size': 1000,
        'brain_d_model': 128,
        'wm_d_model': 128,
        'sensory_configs': {'vision': 64, 'tactile': 16}
    }

    # 2. Build Agent System
    logger.info("ğŸ§  Building Brain & World Model...")

    brain = SynestheticBrain(
        vocab_size=config['vocab_size'],
        d_model=config['brain_d_model'],
        num_layers=2,
        time_steps=8,
        tactile_dim=config['sensory_configs']['tactile'],
        device=device
    )

    wm_config = {
        'd_model': config['wm_d_model'],
        'd_state': 32,
        'num_layers': 2,
        'time_steps': 8,
        'action_dim': config['action_dim'],
        'sensory_configs': config['sensory_configs'],
        'neuron': {'type': 'lif'},
        'use_bitnet': False
    }
    world_model = ArchitectureRegistry.build(
        "spiking_world_model", wm_config, 0).to(device)

    agent = SynestheticAgent(brain, world_model, config['action_dim'], device)

    # Sleep Manager
    sleep_manager = SynestheticSleepManager(agent)

    # Environment
    env = DayNightEnvironment(config)

    # 3. Simulation Loop (Days)
    num_days = 3
    steps_per_day = 20

    for day in range(1, num_days + 1):
        logger.info(f"\n=== ğŸ“… DAY {day} START ===")

        # --- Day Phase: Activity & Experience Gathering ---
        obs = env.reset()
        daily_memories = []  # çŸ­æœŸè¨˜æ†¶ãƒãƒƒãƒ•ã‚¡
        total_reward = 0.0

        # World Modelå­¦ç¿’ç”¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ (æ—¥ä¸­ã¯WMã‚’å­¦ç¿’)
        wm_optimizer = torch.optim.AdamW(world_model.parameters(), lr=1e-3)

        for step in range(steps_per_day):
            # è¡Œå‹•æ±ºå®š
            action = agent.step(obs)

            # ç’°å¢ƒå¿œç­”
            next_obs, reward, done = env.step(action)
            total_reward += reward.item()

            # è¨˜æ†¶ã®ä¿å­˜ (é‡è¦ãªç¬é–“ã®ã¿ä¿å­˜ã™ã‚‹ãªã©ã®é¸åˆ¥ã‚‚å¯èƒ½)
            if step % 5 == 0:  # é–“å¼•ãä¿å­˜
                daily_memories.append(obs)

            # World Model Online Learning (æ—¥ã€…ã®å­¦ç¿’)
            world_model.train()
            wm_optimizer.zero_grad()

            # å…¥åŠ›æ•´å½¢ (Timeæ¬¡å…ƒã‚ã‚ã›)
            # Obs: Dict[str, (1, 1, D)]
            inputs = obs
            act_in = action.view(1, 1, -1)

            _, recons, _ = world_model(inputs, act_in)

            # Loss (å†æ§‹æˆèª¤å·®)
            wm_loss = torch.tensor(0.0, device=device)
            for k, v in recons.items():
                if k in next_obs:
                    wm_loss += torch.nn.functional.mse_loss(v, next_obs[k])

            wm_loss.backward()
            wm_optimizer.step()

            obs = next_obs

        logger.info(
            f"ğŸŒ Day {day} Summary: Total Reward = {total_reward:.2f}, Memories Stored = {len(daily_memories)}")

        # --- Night Phase: Sleep & Consolidation ---
        if daily_memories:
            logger.info(f"=== ğŸŒ™ NIGHT {day} START ===")

            # ç¡çœ ã«ã‚ˆã‚‹è¨˜æ†¶ã®å®šç€
            # æ—¥ä¸­ã«å­¦ç¿’ã—ãŸWorld Modelã‚’ä½¿ã£ã¦å¤¢ã‚’è¦‹ã€Brainã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹
            _ = sleep_manager.enter_sleep_cycle(
                initial_memories=daily_memories,
                num_cycles=3
            )

            logger.info(f"âœ¨ Night {day} Complete. Brain Plasticity Updated.")
        else:
            logger.warning("No memories to consolidate today.")

    logger.info("\nâœ… Life Cycle Simulation Completed. The agent has grown.")


if __name__ == "__main__":
    main()
