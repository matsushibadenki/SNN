# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/benchmarks/run_benchmark_suite.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: SNN Benchmark Suite v2.6 (MPS Memory Support)
# ç›®çš„: Apple Silicon (MPS) ç’°å¢ƒã§ã®æ­£ç¢ºãªãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¨ã€Phase 2ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆã®å¼·åŒ–ã€‚

import sys
import os
import torch
import torch.nn as nn
import logging
import time
import datetime
import gc
import psutil
from typing import Dict, Any, cast, Optional, List, Tuple
from omegaconf import OmegaConf

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
project_root = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../../"))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stdout
)
logger = logging.getLogger("Benchmark")

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ã‚°æŠ‘åˆ¶ï¼ˆCuPyè­¦å‘Šãªã©ï¼‰
logging.getLogger("spikingjelly").setLevel(logging.ERROR)

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©¦è¡Œ
try:
    from snn_research.core.snn_core import SNNCore
except ImportError:
    SNNCore = None  # type: ignore

try:
    from snn_research.models.experimental.bit_spike_mamba import BitSpikeMamba
except ImportError:
    BitSpikeMamba = None  # type: ignore


class BenchmarkSuite:
    def __init__(self, output_dir: str = "workspace/results/benchmarks"):
        print("âš™ï¸ Initializing Benchmark Suite v2.6 (MPS Supported)...")
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

        self.device = self._detect_device()
        print(f"   -> Device selected: {self.device}")

        self.results: Dict[str, Any] = {
            "timestamp": str(datetime.datetime.now()),
            "hardware": self.device,
            "tests": {}
        }
        
        # ãƒ—ãƒ­ã‚»ã‚¹IDå–å¾—ï¼ˆCPUãƒ¡ãƒ¢ãƒªè¨ˆæ¸¬ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        self.process = psutil.Process(os.getpid())

    def _detect_device(self) -> str:
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"

    def _get_dummy_config(self, architecture: str, d_model: int = 64) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼è¨­å®šã‚’ç”Ÿæˆ"""
        base_config = {
            "vocab_size": 100,
            "d_model": d_model,
            "num_layers": 2,
            "time_steps": 8,  # é«˜é€ŸåŒ–ã®ãŸã‚ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’èª¿æ•´
            "neuron_config": {"type": "lif", "base_threshold": 1.0}
        }
        
        if architecture == "bit_spike_mamba":
            base_config.update({
                "architecture_type": "bit_spike_mamba",
                "d_state": 16,
                "d_conv": 4,
                "expand": 2
            })
        else:
            # Transformerç³»
            base_config.update({
                "architecture_type": architecture,
                "nhead": max(2, d_model // 32),
                "dim_feedforward": d_model * 4
            })
        return base_config

    def _build_model(self, model_name: str, config_path: Optional[str] = None, d_model: int = 64) -> nn.Module:
        """ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€"""
        if config_path and os.path.exists(config_path):
            conf = OmegaConf.load(config_path)
            model_config = OmegaConf.to_container(
                conf.model if 'model' in conf else conf, resolve=True)
        else:
            if "Mamba" in model_name:
                arch = "bit_spike_mamba"
            elif "DSA" in model_name:
                arch = "dsa_transformer"
            else:
                arch = "sformer"
            model_config = self._get_dummy_config(arch, d_model)

        model_config = cast(Dict[str, Any], model_config)
        vocab_size = int(model_config.get("vocab_size", 100))

        if model_config.get("architecture_type") == "bit_spike_mamba" and BitSpikeMamba is not None:
            return BitSpikeMamba(
                vocab_size=vocab_size,
                d_model=model_config["d_model"],
                d_state=model_config["d_state"],
                d_conv=model_config["d_conv"],
                expand=model_config["expand"],
                num_layers=model_config["num_layers"],
                time_steps=model_config.get("time_steps", 8),
                neuron_config=model_config["neuron_config"]
            ).to(self.device)

        if SNNCore is not None:
            return SNNCore(config=model_config, vocab_size=vocab_size).to(self.device)

        raise ImportError("No suitable model class found (SNNCore or BitSpikeMamba missing).")

    def _measure_model_size(self, model: nn.Module) -> float:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚º(MB)ã‚’è¨ˆæ¸¬"""
        param_size = 0
        for param in model.parameters():
            param_size += param.nelement() * param.element_size()
        buffer_size = 0
        for buffer in model.buffers():
            buffer_size += buffer.nelement() * buffer.element_size()
        return (param_size + buffer_size) / 1024**2

    def _get_current_memory(self) -> float:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡(MB)ã‚’å–å¾—ï¼ˆãƒ‡ãƒã‚¤ã‚¹ä¾å­˜ï¼‰"""
        if self.device == "cuda":
            return torch.cuda.memory_allocated() / 1024**2
        elif self.device == "mps":
            # MPSã®ãƒ¡ãƒ¢ãƒªè¨ˆæ¸¬ (PyTorch 2.0ä»¥é™æ¨å¥¨)
            try:
                return torch.mps.current_allocated_memory() / 1024**2
            except AttributeError:
                # APIãŒãªã„å ´åˆã¯RSSãƒ¡ãƒ¢ãƒªã®å¤‰åŒ–ã§è¿‘ä¼¼
                return self.process.memory_info().rss / 1024**2
        else:
            return self.process.memory_info().rss / 1024**2

    def _measure_peak_memory_during_execution(self, func, *args) -> float:
        """é–¢æ•°ã®å®Ÿè¡Œä¸­ã®ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡(MB)ã‚’ç°¡æ˜“è¨ˆæ¸¬"""
        gc.collect()
        if self.device == "cuda":
            torch.cuda.reset_peak_memory_stats()
            torch.cuda.empty_cache()
            
        mem_before = self._get_current_memory()
        
        # å®Ÿè¡Œ
        func(*args)
        
        if self.device == "cuda":
            peak = torch.cuda.max_memory_allocated() / 1024**2
        elif self.device == "mps":
            try:
                # MPSãƒ‰ãƒ©ã‚¤ãƒã®æ¨å¥¨è¨ˆæ¸¬æ–¹æ³•
                peak = torch.mps.driver_allocated_memory() / 1024**2
            except AttributeError:
                 # APIãŒãªã„å ´åˆã¯ç¾åœ¨ã®ä½¿ç”¨é‡ã¨ã®å·®åˆ†ï¼ˆä¸æ­£ç¢ºã ãŒç›®å®‰ã«ãªã‚‹ï¼‰
                mem_after = self._get_current_memory()
                peak = mem_after # ç°¡æ˜“çš„ã«ç¾åœ¨å€¤ã‚’ãƒ”ãƒ¼ã‚¯ã¨ã™ã‚‹
        else:
            mem_after = self._get_current_memory()
            peak = mem_after

        # å·®åˆ†ã§ã¯ãªãçµ¶å¯¾å€¤ã€ã‚‚ã—ãã¯å¢—åŠ åˆ†ã‚’è¿”ã™è¨­è¨ˆã«ã™ã‚‹
        # ã“ã“ã§ã¯ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¾Œã®å®Ÿè¡Œæ™‚ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã‚’çŸ¥ã‚ŠãŸã„ã®ã§ã€
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ç›´å¾Œã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®å·®åˆ†ãŒæœ›ã¾ã—ã„ãŒã€
        # ç°¡æ˜“çš„ã«ã€Œå®Ÿè¡Œç›´å¾Œã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã€ã‚’è¿”ã™ã€‚
        return peak

    def run_smoke_test(self, model_name: str, config_path: Optional[str] = None):
        """åŸºæœ¬å‹•ä½œç¢ºèª"""
        print(f"\nğŸ§ª [Smoke Test] {model_name} ... ", end="", flush=True)

        try:
            model = self._build_model(model_name, config_path)
            model.eval()
            size_mb = self._measure_model_size(model)

            safe_model = cast(Any, model)
            vocab_size = 100
            if hasattr(safe_model, 'vocab_size'):
                vocab_size = safe_model.vocab_size
            elif hasattr(safe_model, 'config') and isinstance(safe_model.config, dict):
                vocab_size = safe_model.config.get('vocab_size', 100)

            input_ids = torch.randint(0, vocab_size, (1, 16)).to(self.device)

            with torch.no_grad():
                _ = model(input_ids)

            print(f"âœ… PASSED (Params: {size_mb:.2f} MB)")
            self.results["tests"][f"smoke_{model_name}"] = {
                "status": "PASSED",
                "param_size_mb": size_mb
            }

        except Exception as e:
            print(f"âŒ FAILED: {e}")
            self.results["tests"][f"smoke_{model_name}"] = {
                "status": "FAILED", "error": str(e)}

    def run_efficiency_benchmark(self, model_name: str):
        """æ¨è«–åŠ¹ç‡ï¼ˆLatency & Memoryï¼‰ã®è¨ˆæ¸¬"""
        print(f"âš¡ [Latency Test] {model_name} (Batch=1) ... ", end="", flush=True)
        try:
            # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            model = self._build_model(model_name)
            safe_model = cast(Any, model)
            
            # è¨­å®šã®ä¸Šæ›¸ã (Latencyé‡è¦–è¨­å®š)
            if hasattr(safe_model, 'time_steps'):
                safe_model.time_steps = 4 # å°‘ã—ã‚¹ãƒ†ãƒƒãƒ—ã‚’æŒãŸã›ã‚‹
            if hasattr(safe_model, 'config') and isinstance(safe_model.config, dict):
                safe_model.config['time_steps'] = 4

            model.eval()
            vocab_size = 100
            input_ids = torch.randint(0, vocab_size, (1, 1)).to(self.device)

            # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
            for _ in range(5):
                _ = model(input_ids)

            num_runs = 50
            if self.device == "cuda":
                torch.cuda.synchronize()

            # è¨ˆæ¸¬é–¢æ•°
            def run_inference():
                with torch.no_grad():
                    for _ in range(num_runs):
                        if hasattr(safe_model, 'reset_net'):
                            safe_model.reset_net()
                        elif hasattr(safe_model, 'model') and hasattr(safe_model.model, 'reset_net'):
                            safe_model.model.reset_net()
                        _ = model(input_ids)
            
            # ãƒ¡ãƒ¢ãƒªè¨ˆæ¸¬ã—ãªãŒã‚‰å®Ÿè¡Œ
            if self.device == "cuda":
                torch.cuda.reset_peak_memory_stats()
            
            start_time = time.time()
            mem_usage = self._measure_peak_memory_during_execution(run_inference)
            
            if self.device == "cuda":
                torch.cuda.synchronize()

            end_time = time.time()
            avg_latency = ((end_time - start_time) / num_runs) * 1000

            print(f"âœ… {avg_latency:.2f} ms | Est.Mem: {mem_usage:.1f} MB")

            self.results["tests"][f"efficiency_{model_name}"] = {
                "status": "PASSED",
                "latency_ms": avg_latency,
                "memory_mb": mem_usage
            }
        except Exception as e:
            print(f"âŒ FAILED: {e}")

    def run_scaling_benchmark(self, model_name: str, scales: List[int] = [64, 128, 256, 512]):
        """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ (Phase 2å¯¾å¿œ)"""
        print(f"\nğŸ“ˆ [Scaling Test] {model_name} checking scales {scales}...")
        
        scaling_results = {}
        
        for d_model in scales:
            print(f"   - d_model={d_model:3d}: ", end="", flush=True)
            
            try:
                # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¼·åˆ¶ã—ã¦ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢
                gc.collect()
                if self.device == "cuda":
                    torch.cuda.empty_cache()
                elif self.device == "mps":
                    torch.mps.empty_cache()

                model = self._build_model(model_name, d_model=d_model)
                model.eval()
                
                input_ids = torch.randint(0, 100, (1, 16)).to(self.device)
                
                # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
                for _ in range(3):
                    with torch.no_grad():
                        _ = model(input_ids)
                    
                if self.device == "cuda":
                    torch.cuda.synchronize()
                    
                start_time = time.time()
                with torch.no_grad():
                    for _ in range(10): # é«˜è² è·æ™‚ã¯å›æ•°ã‚’æ¸›ã‚‰ã™
                        _ = model(input_ids)
                        
                if self.device == "cuda":
                    torch.cuda.synchronize()
                    
                elapsed = (time.time() - start_time) / 10 * 1000
                
                # ãƒ¡ãƒ¢ãƒªã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º + å®Ÿè¡Œæ™‚ãƒãƒƒãƒ•ã‚¡
                mem = self._get_current_memory()
                
                print(f"{elapsed:.2f} ms | {mem:.1f} MB")
                scaling_results[f"d{d_model}"] = {"latency": elapsed, "memory": mem}
                
                # æ˜ç¤ºçš„ã«å‰Šé™¤
                del model
                
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    print("âŒ OOM")
                    scaling_results[f"d{d_model}"] = "OOM"
                else:
                    print(f"âŒ Error: {e}")
                    scaling_results[f"d{d_model}"] = "Error"
            except Exception as e:
                print(f"âŒ Unexpected: {e}")
                scaling_results[f"d{d_model}"] = str(e)

        self.results["tests"][f"scaling_{model_name}"] = scaling_results

    def save_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜"""
        report_path = os.path.join(self.output_dir, "benchmark_report.yaml")
        OmegaConf.save(OmegaConf.create(self.results), report_path)
        print(f"\nğŸ“ Report saved to: {report_path}")


def main():
    suite = BenchmarkSuite()
    
    # Phase 2 é‡ç‚¹è©•ä¾¡å¯¾è±¡
    models = ["SFormer", "BitSpikeMamba"]
    
    for name in models:
        suite.run_smoke_test(name)
        suite.run_efficiency_benchmark(name)
        # MPS/CPUç’°å¢ƒã§ã¯512ã¯é‡ã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€try-catchå†…ã§å®Ÿè¡Œ
        suite.run_scaling_benchmark(name, scales=[64, 128, 256, 512]) 
        
    suite.save_report()


if __name__ == "__main__":
    main()