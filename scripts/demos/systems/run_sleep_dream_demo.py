# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/demos/systems/run_sleep_dream_demo.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Sleep & Dream Demo (Memory Consolidation) v1.1
# ç›®çš„ãƒ»å†…å®¹:
#   1. [Awake] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçµŒé¨“ã‚’ç©ã¿ã€çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜ã™ã‚‹ã€‚
#   2. [Sleep] é‡è¦ãªçµŒé¨“ã‚’ãƒªãƒ—ãƒ¬ã‚¤ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã™ã‚‹ã€‚
#   3. [Wake] è¨˜æ†¶ãŒå®šç€ã—ã¦ã„ã‚‹ã‹ï¼ˆLossãŒä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼‰ã‚’ç¢ºèªã™ã‚‹ã€‚
#   [Fix] æ¤œè¨¼æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã—ã€Contrastive LossãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚

import os
import sys
import torch
import logging

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.join(os.path.dirname(__file__), "../../../"))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True
)
logger = logging.getLogger(__name__)

from snn_research.core.architecture_registry import ArchitectureRegistry  # noqa: E402
from snn_research.systems.embodied_vlm_agent import EmbodiedVLMAgent  # noqa: E402
from snn_research.cognitive_architecture.sleep_consolidation import SleepConsolidator  # noqa: E402


def run_sleep_demo():
    logger.info("ğŸ›Œ Starting Sleep & Dream Consolidation Demo...")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    vocab_size = 1000
    img_size = 32

    # 1. Build Agent
    full_config = {
        "vision_config": {"type": "cnn", "hidden_dim": 64, "img_size": img_size, "time_steps": 4, "neuron": {"type": "lif"}},
        "language_config": {"d_model": 64, "vocab_size": vocab_size, "num_layers": 2, "time_steps": 4},
        "projector_config": {"projection_dim": 64},
        "sensory_inputs": {"vision": 64},
        "use_bitnet": False
    }
    motor_config = {"action_dim": 2, "hidden_dim": 32}

    try:
        vlm_model = ArchitectureRegistry.build(
            "spiking_vlm", full_config, vocab_size)
    except Exception:
        from snn_research.models.transformer.spiking_vlm import SpikingVLM
        vlm_model = SpikingVLM(
            vocab_size, full_config["vision_config"], full_config["language_config"], projection_dim=64)

    agent = EmbodiedVLMAgent(vlm_model, motor_config).to(device)
    optimizer = torch.optim.AdamW(agent.parameters(), lr=1e-3)

    # 2. Initialize Sleep System
    sleeper = SleepConsolidator(
        agent, optimizer, buffer_size=50, batch_size=4, device=device)

    # 3. Phase 1: Awake & Experience (Short-term Memory Accumulation)
    logger.info("â˜€ï¸ [Phase 1] Awake: Exploring and accumulating memories...")

    # é‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ (High Reward)
    key_image = torch.randn(1, 3, img_size, img_size).to(device)
    key_text = torch.tensor([[101, 777, 777, 102]], device=device)

    # æ¯”è¼ƒç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ (Distractors) - æ¤œè¨¼ç”¨
    distractor_images = torch.randn(3, 3, img_size, img_size).to(device)
    distractor_texts = torch.randint(0, vocab_size, (3, 4)).to(device)

    # ãƒãƒƒãƒæ§‹ç¯‰é–¢æ•° (Contrastive Lossã«ã¯è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ãŒå¿…è¦)
    def get_eval_batch():
        # Key Pattern + Distractors
        eval_images = torch.cat([key_image, distractor_images], dim=0)
        eval_texts = torch.cat([key_text, distractor_texts], dim=0)
        return eval_images, eval_texts

    # ã„ãã¤ã‹ã®ãƒ©ãƒ³ãƒ€ãƒ ãªçµŒé¨“ã¨ã€å°‘æ•°ã®é‡è¦ãªçµŒé¨“ã‚’æ··ãœã‚‹
    for i in range(20):
        if i % 5 == 0:
            # Important experience (High Reward)
            # ãƒã‚¤ã‚ºã‚’åŠ ãˆã¦ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŒãŸã›ã‚‹
            img = key_image + torch.randn_like(key_image) * 0.1
            txt = key_text
            reward = 1.0
            type_str = "ğŸŒŸ Important"
        else:
            # Random experience (Low Reward)
            img = torch.randn(1, 3, img_size, img_size).to(device)
            txt = torch.randint(0, vocab_size, (1, 4)).to(device)
            reward = 0.1
            type_str = "sample"

        sleeper.store_experience(img, txt, reward)
        if i % 5 == 0:
            logger.info(f"   Stored {type_str} memory (Reward: {reward})")

    # 4. Check initial loss on Evaluation Batch (Before Sleep)
    agent.eval()
    with torch.no_grad():
        eval_imgs, eval_txts = get_eval_batch()
        out_before = agent.vlm(eval_imgs, eval_txts)
        loss_before = out_before["alignment_loss"].item()
    logger.info(f"ğŸ“‰ Loss on Key Batch BEFORE sleep: {loss_before:.4f}")

    # 5. Phase 2: Sleep & Dream (Consolidation)
    logger.info("ğŸŒ™ [Phase 2] Sleeping: Replaying high-reward memories...")
    sleep_stats = sleeper.sleep(cycles=10)
    logger.info(f"   Sleep stats: {sleep_stats}")

    # 6. Phase 3: Wake & Verify (Long-term Memory Check)
    logger.info("ğŸŒ… [Phase 3] Waking up: Verifying memory retention...")
    agent.eval()
    with torch.no_grad():
        eval_imgs, eval_txts = get_eval_batch()
        out_after = agent.vlm(eval_imgs, eval_txts)
        loss_after = out_after["alignment_loss"].item()

    logger.info(f"ğŸ“‰ Loss on Key Batch AFTER sleep:  {loss_after:.4f}")

    improvement = loss_before - loss_after
    if improvement > 0.001:  # å¾®å°ãªèª¤å·®ä»¥ä¸Šã®æ”¹å–„
        logger.info(
            f"âœ… Memory Consolidated! Loss improved by {improvement:.4f}")
    else:
        logger.warning(
            f"âš ï¸ Memory consolidation result inconclusive (Diff: {improvement:.4f}).")

    logger.info("ğŸ‰ Sleep & Dream Demo Completed.")


if __name__ == "__main__":
    run_sleep_demo()
