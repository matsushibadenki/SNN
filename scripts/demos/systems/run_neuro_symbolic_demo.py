# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/runners/run_neuro_symbolic_demo.py
# Title: Neuro-Symbolic & Sleep Distillation Demo
# Description:
#   v16.1ã®å…¨æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
#   1. RAGçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ï¼ˆãƒ•ã‚§ã‚¤ã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰
#   2. ReasoningEngineã«ã‚ˆã‚‹ã€Œæ¤œç´¢ã‚’ä¼´ã†æ€è€ƒã€ã®å®Ÿè¡Œ
#   3. æ€è€ƒçµæœã®SleepConsolidatorã¸ã®è“„ç©ã¨è’¸ç•™ï¼ˆå­¦ç¿’ï¼‰

from snn_research.io.spike_encoder import SpikeEncoder  # ãƒ€ãƒŸãƒ¼ç”¨
from snn_research.cognitive_architecture.sleep_consolidation import SleepConsolidator
from snn_research.cognitive_architecture.reasoning_engine import ReasoningEngine
from snn_research.cognitive_architecture.rag_snn import RAGSystem
from snn_research.cognitive_architecture.astrocyte_network import AstrocyteNetwork  # E402 fixed
from snn_research.models.transformer.sformer import SFormer
import sys
import os
import torch
import logging
from transformers import GPT2Tokenizer

# ãƒ‘ã‚¹è¨­å®š
project_root = os.path.abspath(os.path.join(
    os.path.dirname(__file__), "../../../"))
sys.path.insert(0, project_root)


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("NeuroSymDemo")


def main():
    print("ğŸ§  --- Neuro-Symbolic SNN & Sleep Distillation Demo ---")

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # 1. Setup Components
    # SFormer
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    tokenizer.pad_token = tokenizer.eos_token
    sformer = SFormer(vocab_size=50257, d_model=128,
                      nhead=4, num_layers=4).to(device)

    # RAG System (Mocking Data)
    rag = RAGSystem(vector_store_path="workspace/runs/demo_store")
    # çŸ¥è­˜æ³¨å…¥: SNNã«ã¤ã„ã¦ã®çŸ¥è­˜ã‚’æŒãŸã›ã‚‹
    rag.add_document(
        "SNN (Spiking Neural Network) is energy efficient.", metadata={"subj": "SNN"})
    rag.add_triple("SNN", "uses", "spikes")
    rag.add_triple("SNN", "mimics", "brain")

    # Astrocyte & Reasoning
    astrocyte = AstrocyteNetwork()
    reasoning = ReasoningEngine(
        generative_model=sformer,
        astrocyte=astrocyte,
        rag_system=rag,
        enable_rag_verification=True,
        device=device
    )

    # Sleep Consolidator
    spike_encoder = SpikeEncoder()  # ãƒ€ãƒŸãƒ¼
    sleep_manager = SleepConsolidator(rag, sformer, spike_encoder)

    # 2. Run Reasoning Task (Thinking with RAG)
    print("\nğŸ”¹ Phase 1: Reasoning with RAG")
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: "Tell me about SNN efficiency. <query>SNN efficiency</query>"
    # â€»æœ¬æ¥ã¯LLMãŒ<query>ã‚’è‡ªå¾‹ç”Ÿæˆã™ã‚‹ãŒã€ã“ã“ã§ã¯ãƒ‡ãƒ¢ã®ãŸã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸ‹ã‚è¾¼ã‚€
    input_text = "Question: What is SNN? <query>SNN</query>"
    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)

    result = reasoning.think_and_solve(input_ids, tokenizer=tokenizer)

    print("   [Trace]")
    for t in result["thought_trace"]:
        print(f"   - {t}")

    # ç”Ÿæˆã•ã‚ŒãŸæ€è€ƒçµæœã‚’ç¡çœ ãƒãƒãƒ¼ã‚¸ãƒ£ã«ç™»éŒ²
    sleep_manager.add_thought_trace(result)

    # 3. Run Sleep Cycle (Distillation)
    print("\nğŸ”¹ Phase 2: Sleep & Distillation")
    print("   Going to sleep to consolidate the reasoning experience...")

    stats = sleep_manager.perform_sleep_cycle()

    print(f"   Replayed Dreams: {stats['dreams_replayed']}")
    print(f"   Synaptic Change (Loss): {stats['synaptic_change']:.4f}")

    print("\nğŸ‰ Demo Completed: The brain reasoned, learned from tools, and consolidated memory.")


if __name__ == "__main__":
    main()
