# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/demos/brain/run_conscious_broadcast_demo.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Conscious Broadcast Demo (Global Workspace Theory)
# ç›®çš„ãƒ»å†…å®¹:
#   è„³å†…ã®ç•°ãªã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆè¦–è¦šã€æ€è€ƒã€æ’å¸¸æ€§ï¼‰ãŒæ„è­˜ã®åº§ã‚’å·¡ã£ã¦ç«¶åˆã™ã‚‹æ§˜å­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€‚
#   é€šå¸¸ã¯ã€Œè¦–è¦šã€ãŒå„ªä½ã ãŒã€ç·Šæ€¥æ™‚ï¼ˆç©ºè…¹ã‚„ç—›ã¿ï¼‰ã«ã¯ã€Œæ’å¸¸æ€§ã€ãŒå‰²ã‚Šè¾¼ã‚“ã§æ„è­˜ã‚’ã‚¸ãƒ£ãƒƒã‚¯ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

from snn_research.cognitive_architecture.global_workspace import GlobalWorkspace
import os
import sys
import torch
import logging
import time

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.join(os.path.dirname(__file__), "../../../"))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    datefmt='%H:%M:%S',
    force=True
)
logger = logging.getLogger(__name__)


def run_consciousness_demo():
    print("""
    ============================================================
       ğŸ‘ï¸ CONSCIOUS BROADCAST DEMO (Global Workspace) ğŸ‘ï¸
    ============================================================
    """)

    device = "cpu"
    dim = 64

    # 1. Initialize Global Workspace
    gwt = GlobalWorkspace(dim=dim).to(device)

    # 2. Simulate Modules
    # å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä¿¡å·(Tensor)ã‚’å‡ºåŠ›ã™ã‚‹
    logger.info("ğŸ§  Initializing Brain Modules: [Vision], [Thought], [Body]...")

    # ã‚·ãƒŠãƒªã‚ª:
    # å¹³ç©ãªçŠ¶æ…‹ -> ä½•ã‹ã‚’è¦‹ã‚‹ -> è€ƒãˆäº‹ã‚’ã™ã‚‹ -> çªç„¶ã®è…¹ç—›(ç·Šæ€¥)

    for step in range(15):
        inputs = {}

        # --- Module 1: Vision (è¦–è¦š) ---
        # å¸¸ã«ç’°å¢ƒæƒ…å ±ã‚’é€ã£ã¦ãã‚‹
        vision_signal = torch.randn(1, dim).to(device) * 1.0  # é€šå¸¸å¼·åº¦
        if 2 <= step <= 5:
            # èˆˆå‘³æ·±ã„ã‚‚ã®ã‚’è¦‹ãŸï¼
            vision_signal *= 3.0
            logger.debug(f"Step {step}: Vision is excited!")
        inputs["Vision ğŸ“·"] = vision_signal

        # --- Module 2: Thought (æ€è€ƒ/è¨€èª) ---
        # ãƒ©ãƒ³ãƒ€ãƒ ãªæ€è€ƒ
        thought_signal = torch.randn(1, dim).to(device) * 0.8
        if 6 <= step <= 9:
            # æ·±ã„æ€è€ƒãƒ¢ãƒ¼ãƒ‰
            thought_signal *= 4.0
            logger.debug(f"Step {step}: Deep thought...")
        inputs["Thought ğŸ’­"] = thought_signal

        # --- Module 3: Body (èº«ä½“/æ’å¸¸æ€§) ---
        # é€šå¸¸ã¯é™ã‹ã ãŒ...
        body_signal = torch.randn(1, dim).to(device) * 0.2
        if step >= 11:
            # ç·Šæ€¥äº‹æ…‹ï¼ (ç—›ã¿ã‚„ç©ºè…¹)
            body_signal *= 10.0  # åœ§å€’çš„å¼·åº¦
            logger.debug(f"Step {step}: BODY EMERGENCY!")
        inputs["Body ğŸ’“"] = body_signal

        # --- GWT Step ---
        # æ„è­˜ã«ã‚ˆã‚‹é¸æŠã¨æ”¾é€
        result = gwt(inputs)

        winner = result["winner"]
        # broadcast_vec = result["broadcast"]
        # salience = result["salience"]

        # Visualize
        # ç°¡æ˜“ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§Attentionã‚’è¡¨ç¤º
        # attn_str = " | ".join(
        #     [f"{k}: {salience[i]:.2f}" for i, k in enumerate(inputs.keys())])

        icon = ""
        if "Vision" in winner:
            icon = "ğŸ‘€ Seeing"
        elif "Thought" in winner:
            icon = "ğŸ¤” Thinking"
        elif "Body" in winner:
            icon = "ğŸ˜« Feeling"

        logger.info(f"Step {step:02d}: Winner -> [{winner}] {icon}")
        # logger.info(f"   Attn: {attn_str}")

        time.sleep(0.1)  # èª­ã¿ã‚„ã™ãã™ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ

    logger.info("\nâœ… Demo Result Analysis:")
    logger.info("   1. Steps 0-1: Random fluctuations (Mind wandering)")
    logger.info(
        "   2. Steps 2-5: Vision dominates (Attention captured by scene)")
    logger.info(
        "   3. Steps 6-9: Thought dominates (Internal simulation/planning)")
    logger.info(
        "   4. Steps 11+: Body interrupts everything (Survival instinct)")

    logger.info("ğŸ‰ Global Workspace Demo Completed.")


if __name__ == "__main__":
    run_consciousness_demo()
