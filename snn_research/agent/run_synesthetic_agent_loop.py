# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/agents/run_synesthetic_agent_loop.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Synesthetic Agent Runtime Loop
# ç›®çš„: äº”æ„Ÿçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ(SynestheticAgent)ã‚’æ“¬ä¼¼ç’°å¢ƒã§å‹•ä½œã•ã›ã€
#       çŸ¥è¦š-è¡Œå‹•ãƒ«ãƒ¼ãƒ—ã¨ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬(Dream)ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

from snn_research.agent.synesthetic_agent import SynestheticAgent
from snn_research.models.experimental.brain_v4 import SynestheticBrain
from snn_research.core.architecture_registry import ArchitectureRegistry
import os
import sys
import torch
import torch.nn as nn
import logging
from typing import Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.getcwd())


# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("AgentLoop")


class DummyEnvironment:
    """
    äº”æ„Ÿãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹æ“¬ä¼¼ç’°å¢ƒã‚¯ãƒ©ã‚¹ã€‚
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã«å¿œã˜ã¦ç’°å¢ƒã®çŠ¶æ…‹ï¼ˆè¦–è¦šãƒ»è§¦è¦šãªã©ï¼‰ã‚’å¤‰åŒ–ã•ã›ã‚‹ã€‚
    """

    def __init__(self, config: Dict[str, Any]):
        self.device = config['device']
        self.sensory_dims = config['sensory_configs']
        self.step_count = 0
        self.state_pos = torch.zeros(1, 2, device=self.device)  # (x, y)

    def reset(self) -> Dict[str, torch.Tensor]:
        self.step_count = 0
        self.state_pos = torch.zeros(1, 2, device=self.device)
        return self._get_observation()

    def step(self, action: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è¡Œå‹•ã‚’å—ã‘å–ã‚Šã€çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¦æ–°ã—ã„è¦³æ¸¬ã‚’è¿”ã™ã€‚
        action: (B, 2) - ç§»å‹•ãƒ™ã‚¯ãƒˆãƒ«ã¨ä»®å®š
        """
        self.step_count += 1

        # çŠ¶æ…‹æ›´æ–° (ç§»å‹•)
        # actionã¯-1~1ã®ç¯„å›²ã¨æƒ³å®š
        self.state_pos += action * 0.1

        return self._get_observation()

    def _get_observation(self) -> Dict[str, torch.Tensor]:
        """ç¾åœ¨ã®çŠ¶æ…‹ã«åŸºã¥ã„ãŸäº”æ„Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        obs = {}
        batch_size = 1  # ãƒ‡ãƒ¢ç”¨å›ºå®š

        # 1. Vision: ä½ç½®ã«å¿œã˜ãŸãƒ‘ã‚¿ãƒ¼ãƒ³
        if 'vision' in self.sensory_dims:
            dim = self.sensory_dims['vision']
            # ä½ç½®æƒ…å ±ã‚’sinæ³¢ã§é«˜æ¬¡å…ƒåŒ–
            freq = torch.linspace(0.1, 5.0, dim, device=self.device)
            # (B, 1, D)
            obs['vision'] = torch.sin(
                self.state_pos.mean() * freq).unsqueeze(0).unsqueeze(0)

        # 2. Tactile: ç‰¹å®šã‚¨ãƒªã‚¢ã§åå¿œ
        if 'tactile' in self.sensory_dims:
            dim = self.sensory_dims['tactile']
            # åŸç‚¹ã‹ã‚‰é›¢ã‚Œã‚‹ã¨å£ã«è§¦ã‚Œã‚‹ã¨ä»®å®š
            dist = torch.norm(self.state_pos)
            contact = (dist > 1.0).float()
            obs['tactile'] = (torch.randn(batch_size, 1, dim,
                              device=self.device) * contact)

        return obs


def main():
    logger.info("ğŸ¤– Initializing Synesthetic Agent System...")

    # --- 1. Configuration ---
    device = "cuda" if torch.cuda.is_available() else "cpu"
    config = {
        'device': device,
        'action_dim': 2,
        'vocab_size': 1000,
        'brain_d_model': 128,
        'wm_d_model': 128,
        'sensory_configs': {
            'vision': 64,   # ãƒ‡ãƒ¢ç”¨ã«å°ã•ãè¨­å®š
            'tactile': 16,
            'audio': 16,
            'olfactory': 8
        }
    }

    # --- 2. Build Components ---

    # A. Brain (æ€è€ƒã‚¨ãƒ³ã‚¸ãƒ³)
    logger.info("   - Building Synesthetic Brain...")
    brain = SynestheticBrain(
        vocab_size=config['vocab_size'],
        d_model=config['brain_d_model'],
        num_layers=2,
        time_steps=8,
        tactile_dim=config['sensory_configs']['tactile'],
        olfactory_dim=config['sensory_configs']['olfactory'],
        device=device
    )

    # B. World Model (äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³)
    logger.info("   - Building Spiking World Model...")
    # ArchitectureRegistryã‚’ä½¿ã£ã¦ãƒ“ãƒ«ãƒ‰
    wm_config = {
        'd_model': config['wm_d_model'],
        'd_state': 32,
        'num_layers': 2,
        'time_steps': 8,
        'action_dim': config['action_dim'],
        'sensory_configs': config['sensory_configs'],
        'neuron': {'type': 'lif'},
        'use_bitnet': False
    }
    world_model = ArchitectureRegistry.build(
        "spiking_world_model", wm_config, 0).to(device)

    # C. Agent (çµ±åˆ)
    logger.info("   - assembling Agent...")
    agent = SynestheticAgent(
        brain=brain,
        world_model=world_model,
        action_dim=config['action_dim'],
        device=device
    )

    # D. Environment
    env = DummyEnvironment(config)

    # --- 3. Runtime Loop ---
    logger.info("ğŸš€ Starting Active Learning Loop...")

    # å­¦ç¿’ç”¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ (ç°¡æ˜“çš„ã«WorldModelã®ã¿å­¦ç¿’ã•ã›ã‚‹ä¾‹)
    wm_optimizer = torch.optim.AdamW(world_model.parameters(), lr=0.001)

    obs = env.reset()
    total_steps = 10

    for step in range(total_steps):
        logger.info(f"\n[Step {step+1}/{total_steps}]")

        # 1. Dream (Before Act) - è¡Œå‹•å‰ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        logger.info("   ğŸ’­ Dreaming future possibilities...")
        _ = agent.dream(obs, horizon=5)
        logger.info("      -> Imagined 5 steps into the future.")

        # 2. Act (Brain Decision)
        # å¤–éƒ¨ã‹ã‚‰ã®æŒ‡ç¤º (ä»»æ„)
        instruction = "Explore the environment safely."

        logger.info("   ğŸ§  Thinking and Acting...")
        action = agent.step(obs, instruction=instruction)
        logger.info(
            f"      -> Action decided: {action[0].detach().cpu().numpy()}")

        # 3. Environment Response
        next_obs = env.step(action)

        # 4. Learn (World Model Update) - å®Ÿä½“é¨“ã«åŸºã¥ãå­¦ç¿’
        # ã€Œäºˆæ¸¬ã—ã¦ã„ãŸçµæœã€ã¨ã€Œå®Ÿéš›ã®çµæœã€ã®èª¤å·®ã‚’å­¦ç¿’ã™ã‚‹
        logger.info("   ğŸ“š Learning from experience (World Model Update)...")

        world_model.train()
        wm_optimizer.zero_grad()

        # ç°¡æ˜“å­¦ç¿’: 1ã‚¹ãƒ†ãƒƒãƒ—å‰ã®è¦³æ¸¬+è¡Œå‹• -> ç¾åœ¨ã®è¦³æ¸¬ ã‚’äºˆæ¸¬ã§ããŸã‹ï¼Ÿ
        # (æœ¬æ¥ã¯ReplayBufferã‚’ä½¿ã†ãŒã€ã“ã“ã§ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã®ç°¡æ˜“å®Ÿè£…)

        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢ (Timeæ¬¡å…ƒã‚’è¿½åŠ )
        current_inputs = {k: v.unsqueeze(
            1) if v.dim() == 2 else v for k, v in obs.items()}
        # Actionã‚‚Timeæ¬¡å…ƒè¿½åŠ 
        current_action_seq = action.unsqueeze(1)

        # äºˆæ¸¬å®Ÿè¡Œ
        _, reconstructions, _ = world_model(current_inputs, current_action_seq)

        # æå¤±è¨ˆç®— (å„æ„Ÿè¦šã®å†æ§‹æˆèª¤å·®)
        loss = torch.tensor(0.0, device=device)
        for mod, pred in reconstructions.items():
            if mod in next_obs:
                target = next_obs[mod]
                if target.dim() == 2:
                    target = target.unsqueeze(1)

                # æ¬¡å…ƒåˆã‚ã›
                if pred.shape != target.shape:
                    # ç°¡æ˜“ãƒªã‚µã‚¤ã‚º (å®Ÿé‹ç”¨ã§ã¯å½¢çŠ¶ã‚’å³å¯†ã«ç®¡ç†)
                    continue

                loss += nn.MSELoss()(pred, target)

        loss.backward()
        wm_optimizer.step()
        logger.info(f"      -> World Model Loss: {loss.item():.4f}")

        # çŠ¶æ…‹æ›´æ–°
        obs = next_obs

        # çŸ­ã„ä¼‘æ†© (ãƒ­ã‚°ã‚’è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚)
        # time.sleep(0.5)

    logger.info("\nâœ… Synesthetic Agent Loop Completed Successfully.")


if __name__ == "__main__":
    main()
