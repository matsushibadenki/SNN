# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/hybrid_perception_cortex.py
# (Phase 3: Cortical Column Integrated - Fix: Added perceive method)
# Title: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çŸ¥è¦šé‡ (Cortical Column + SOM)
# Description:
# - å…¥åŠ›ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ã€Œçš®è³ªã‚«ãƒ©ãƒ  (Cortical Column)ã€ã§å‡¦ç†ã—ã€éšå±¤çš„ãªç‰¹å¾´å¤‰æ›ã‚’è¡Œã†ã€‚
# - ã‚«ãƒ©ãƒ ã®å‡ºåŠ›ã‚’ã€Œè‡ªå·±çµ„ç¹”åŒ–ãƒãƒƒãƒ— (SOM)ã€ã«å…¥åŠ›ã—ã€ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ãªåˆ†é¡ã‚’è¡Œã†ã€‚
# - ä¿®æ­£: perceive ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ ã—ã€ArtificialBrain ã¨ã®äº’æ›æ€§ã‚’ç¢ºä¿ã€‚

import torch
import torch.nn as nn
from typing import Dict, Any, Optional

from .som_feature_map import SomFeatureMap
from .global_workspace import GlobalWorkspace
from snn_research.core.cortical_column import CorticalColumn

class HybridPerceptionCortex(nn.Module):
    """
    çš®è³ªã‚«ãƒ©ãƒ ã«ã‚ˆã‚‹éšå±¤çš„å‡¦ç†ã¨ã€SOMã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’çµ±åˆã—ãŸçŸ¥è¦šé‡ã€‚
    """
    # ã‚¯ãƒ©ã‚¹ãƒ¬ãƒ™ãƒ«ã¾ãŸã¯__init__å†…ã§å‹ã‚’æ˜ç¤º
    column: CorticalColumn
    prev_column_state: Optional[Dict[str, torch.Tensor]]

    def __init__(
        self, 
        workspace: GlobalWorkspace, 
        num_neurons: int, 
        feature_dim: int = 64, 
        som_map_size=(8, 8), 
        stdp_params: Optional[Dict[str, Any]] = None,
        cortical_column: Optional[CorticalColumn] = None 
    ):
        super().__init__()
        self.workspace = workspace
        self.num_neurons = num_neurons
        self.feature_dim = feature_dim
        
        # 1. çš®è³ªã‚«ãƒ©ãƒ  (CorticalColumn)
        if cortical_column is None:
            print("âš ï¸ Warning: CorticalColumn not injected. Using fallback.")
            self.column = CorticalColumn(
                input_dim=num_neurons,
                column_dim=feature_dim,
                output_dim=feature_dim,
                neuron_config={'type': 'lif', 'tau_mem': 20.0, 'base_threshold': 1.0}
            )
        else:
            self.column = cortical_column
        
        # 2. ç‰¹å¾´å°„å½± (ã‚«ãƒ©ãƒ å‡ºåŠ›ã‚’SOMæ¬¡å…ƒã¸)
        self.input_projection = nn.Linear(feature_dim, feature_dim)
        
        if stdp_params is None:
            stdp_params = {'learning_rate': 0.005, 'a_plus': 1.0, 'a_minus': 1.0, 'tau_trace': 20.0}
        
        # 3. è‡ªå·±çµ„ç¹”åŒ–ãƒãƒƒãƒ— (SOM)
        self.som = SomFeatureMap(
            input_dim=feature_dim,
            map_size=som_map_size,
            stdp_params=stdp_params
        )
        
        # ã‚«ãƒ©ãƒ ã®çŠ¶æ…‹ä¿æŒç”¨
        self.prev_column_state = None
        
        print("ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çŸ¥è¦šé‡ (Cortical Column + SOM) ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚")

    def perceive(self, sensory_input: torch.Tensor) -> Dict[str, Any]:
        """
        ArtificialBrain ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚
        å…¥åŠ› -> ã‚«ãƒ©ãƒ å‡¦ç† -> SOMå­¦ç¿’ -> ç‰¹å¾´é‡è¿”å´
        
        Args:
            sensory_input: (Batch, Neurons) ã¾ãŸã¯ (Neurons,)
        """
        # ãƒ‡ãƒã‚¤ã‚¹åŒæœŸ
        if sensory_input.device != next(self.parameters()).device:
            sensory_input = sensory_input.to(next(self.parameters()).device)

        # å…¥åŠ›å½¢çŠ¶ã®æ­£è¦åŒ– (Batch=1 ã¾ãŸã¯ Timeå¹³å‡)
        if sensory_input.dim() == 2:
            # (Batch, Neurons) -> (1, Neurons) å¹³å‡åŒ–
            input_signal = sensory_input.float().mean(dim=0).unsqueeze(0)
        else:
            input_signal = sensory_input.float().unsqueeze(0)

        # 1. çš®è³ªã‚«ãƒ©ãƒ ã«ã‚ˆã‚‹å‡¦ç†
        out_ff, out_fb, current_states = self.column(input_signal, self.prev_column_state)
        
        # çŠ¶æ…‹æ›´æ–°
        self.prev_column_state = {k: v.detach() for k, v in current_states.items()}

        # 2. ç‰¹å¾´å°„å½±
        column_output = out_ff.squeeze(0)
        feature_vector = torch.relu(self.input_projection(column_output))

        # 3. SOMã«ã‚ˆã‚‹ç‰¹å¾´åˆ†é¡ã¨å­¦ç¿’ (ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’)
        for _ in range(3): 
            som_spikes = self.som(feature_vector)
            self.som.update_weights(feature_vector, som_spikes)
        
        final_som_activation = self.som(feature_vector)
        
        # æ´»æ€§åº¦è¨ˆç®—
        column_activity = sum(t.mean().item() for t in current_states.values()) / len(current_states)
        
        return {
            "features": final_som_activation, # (FeatureDim,)
            "column_activity": column_activity,
            "type": "perception",
            "details": f"Processed via Cortical Column (Activity: {column_activity:.2f})"
        }

    def perceive_and_upload(self, spike_pattern: torch.Tensor) -> None:
        """
        (æ—§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹) å‡¦ç†çµæœã‚’ç›´æ¥ Workspace ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
        perceive ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ©ãƒƒãƒ—ã™ã‚‹å½¢ã§å®Ÿè£…ã€‚
        """
        result = self.perceive(spike_pattern)
        
        input_strength = spike_pattern.float().mean().item()
        salience = min(1.0, (result["column_activity"] + input_strength) * 5.0)
        
        perception_data = {
            "type": "perception", 
            "features": result["features"],
            "details": result["details"]
        }

        self.workspace.upload_to_workspace(
            source="perception",
            data=perception_data,
            salience=salience
        )
        print(f"  - çŸ¥è¦šé‡: çš®è³ªã‚«ãƒ©ãƒ å‡¦ç†å®Œäº† (æ´»æ€§åº¦: {result['column_activity']:.2f}) -> Workspaceã¸é€ä¿¡")