# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/sleep_consolidation.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Sleep Consolidator (Hippocampal-Cortical Consolidation) v2.7 (MPS Fix)
# ä¿®æ­£ (v2.7): _train_stepã§ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã« .contiguous() ã‚’é©ç”¨ã—ã€MPSã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã€‚

import torch
import torch.nn as nn
import logging
import random
from typing import Dict, Any, Optional, List, Deque
from collections import deque

logger = logging.getLogger(__name__)


class Episode:
    """
    ãƒ¬ã‚¬ã‚·ãƒ¼/ãƒ†ã‚¹ãƒˆäº’æ›ç”¨ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚³ãƒ³ãƒ†ãƒŠã€‚
    """

    def __init__(self, state: torch.Tensor, text: torch.Tensor, reward: float):
        self.state = state.cpu().detach()
        self.text = text.cpu().detach()
        self.reward = reward


class SleepConsolidator:
    """
    ç¡çœ ã«ã‚ˆã‚‹è¨˜æ†¶å›ºå®šåŒ–ã‚·ã‚¹ãƒ†ãƒ  (System 2 Consolidation)ã€‚
    æµ·é¦¬ã®çŸ­æœŸè¨˜æ†¶ã‚’ãƒªãƒ—ãƒ¬ã‚¤ã—ã€å¤§è„³çš®è³ªã®é•·æœŸè¨˜æ†¶(RAG/Weights)ã¸è»¢é€ãƒ»çµ±åˆã™ã‚‹ã€‚
    """

    def __init__(
        self,
        memory_system: Optional[Any] = None,
        hippocampus: Optional[Any] = None,
        cortex: Optional[Any] = None,
        target_brain_model: Optional[nn.Module] = None,
        agent: Optional[nn.Module] = None,
        optimizer: Optional[torch.optim.Optimizer] = None,
        config: Dict[str, Any] = {}
    ):
        self.config = config
        self.hippocampus_buffer: Deque[Episode] = deque(maxlen=1000)
        
        # ä¾å­˜é–¢ä¿‚ã®è§£æ±º
        self.agent = target_brain_model if target_brain_model else agent
        self.cortex = cortex
        self.memory_system = memory_system
        
        self.batch_size = config.get("replay_batch_size", 32)
        self.learning_rate = config.get("sleep_learning_rate", 1e-4)
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®åˆæœŸåŒ–
        if optimizer:
            self.optimizer = optimizer
        elif self.agent:
            # å‡çµã•ã‚Œã¦ã„ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿å¯¾è±¡
            params = [p for p in self.agent.parameters() if p.requires_grad]
            if params:
                self.optimizer = torch.optim.AdamW(params, lr=self.learning_rate)
            else:
                self.optimizer = None
        else:
            self.optimizer = None

        logger.info(f"ğŸ’¤ Sleep Consolidator v2.7 initialized (Knowledge Graph Integration enabled).")

    def store_experience(self, image: torch.Tensor, text: torch.Tensor, reward: float):
        """è¦šé†’æ™‚ã®çµŒé¨“ã‚’æµ·é¦¬(ãƒãƒƒãƒ•ã‚¡)ã«ä¸€æ™‚ä¿å­˜"""
        episode = Episode(image, text, reward)
        self.hippocampus_buffer.append(episode)

    def perform_sleep_cycle(self, duration_cycles: int = 5, recent_memories: List[Any] = []) -> Dict[str, Any]:
        """ç¡çœ ã‚µã‚¤ã‚¯ãƒ«ã®å®Ÿè¡Œ (Replay & Consolidation)"""
        if not self.agent:
            return {"status": "skipped", "reason": "no_agent_model"}
        
        if len(self.hippocampus_buffer) < 2 and not recent_memories:
             return {"status": "skipped", "reason": "no_memories"}

        logger.info(f"ğŸŒ™ Starting Sleep Consolidation. Processing {len(self.hippocampus_buffer)} episodes over {duration_cycles} cycles.")
        
        self.agent.train()
        total_loss = 0.0
        consolidated_count = 0
        
        try:
            for cycle in range(duration_cycles):
                loss = self._train_step()
                total_loss += loss
                
                # å¤ã„è¨˜æ†¶ã®ä¸€éƒ¨ã‚’é•·æœŸè¨˜æ†¶ã¸è»¢é€
                if self.hippocampus_buffer and random.random() < 0.3:
                    mem = self.hippocampus_buffer[0] # å¤ã„ã‚‚ã®ã‹ã‚‰
                    self._transfer_to_cortex(mem)
                    consolidated_count += 1
            
            return {
                "status": "success",
                "cycles": duration_cycles,
                "processed_episodes": len(self.hippocampus_buffer),
                "consolidated_to_cortex": consolidated_count,
                "avg_replay_loss": total_loss / duration_cycles,
                "knowledge_graph": {} # Placeholder
            }
            
        except Exception as e:
            logger.error(f"Sleep cycle failed: {e}")
            return {"status": "failed", "error": str(e)}
        finally:
            self.agent.eval()

    def _train_step(self) -> float:
        """ãƒªãƒ—ãƒ¬ã‚¤ã«ã‚ˆã‚‹å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"""
        if not self.optimizer or len(self.hippocampus_buffer) == 0:
            return 0.0
            
        # ãƒãƒƒãƒä½œæˆ
        batch_size = min(len(self.hippocampus_buffer), self.batch_size)
        batch = random.sample(self.hippocampus_buffer, batch_size)
        
        # ãƒ†ãƒ³ã‚½ãƒ«ã®çµåˆ
        try:
            device = next(self.agent.parameters()).device
            
            # [MPS Fix] ã“ã“ã§ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã‹ã‚‰stackã—ãŸå¾Œã€.contiguous()ã‚’é©ç”¨
            states = torch.stack([e.state for e in batch]).to(device).squeeze(1).contiguous()
            
            # ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆã¯è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆæ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ãªã©ï¼‰ã‚’æƒ³å®š
            # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã€Œå…¥åŠ›ãã®ã‚‚ã®ã‚’å†æ§‹æˆã™ã‚‹ã€ã‚ã‚‹ã„ã¯ã€Œãƒ€ãƒŸãƒ¼æå¤±ã€
            
            self.optimizer.zero_grad()
            
            # Forward
            if hasattr(self.agent, "forward"):
                # SNNCoreã‚„SFormerã®å ´åˆ
                outputs = self.agent(states)
                
                # å‡ºåŠ›ãŒã‚¿ãƒ—ãƒ«ã®å ´åˆ (logits, spikes, mem)
                if isinstance(outputs, tuple):
                    logits = outputs[0]
                elif isinstance(outputs, dict):
                    logits = outputs.get('logits', list(outputs.values())[0])
                else:
                    logits = outputs
                
                # ç°¡æ˜“çš„ãªå†æ§‹æˆæå¤± (Autoencoderçš„) or è‡ªå·±å›å¸°æå¤±
                # ã“ã“ã§ã¯å…¥åŠ›IDã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã™ã‚‹CrossEntropy (SFormerãŒLLMçš„ãªã‚‰)
                if hasattr(self.agent, "vocab_size") and logits.shape[-1] == self.agent.vocab_size:
                    # logits: (B, L, V), states: (B, L)
                    # å½¢çŠ¶èª¿æ•´
                    B, L, V = logits.shape
                    
                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å½¢çŠ¶ç¢ºèª
                    targets = states
                    if targets.dim() > 2: # (B, 1, L) -> (B, L)
                        targets = targets.squeeze(1)
                    
                    # é•·ã•ãŒåˆã‚ãªã„å ´åˆã®ãƒˆãƒªãƒŸãƒ³ã‚°
                    if targets.shape[1] > L:
                        targets = targets[:, :L]
                    elif targets.shape[1] < L:
                        logits = logits[:, :targets.shape[1], :]
                        
                    loss_fct = nn.CrossEntropyLoss()
                    loss = loss_fct(logits.reshape(-1, V), targets.reshape(-1))
                else:
                    # ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«ç”¨ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
                    loss = logits.mean() 
                
                # Backward
                loss.backward()
                self.optimizer.step()
                
                return float(loss.item())
                
        except Exception as e:
            logger.error(f"Replay training step failed: {e}")
            return 0.0
            
        return 0.0

    def _transfer_to_cortex(self, memory: Any):
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’é•·æœŸè¨˜æ†¶(Cortex/RAG)ã¸è»¢é€ãƒ»ä¿å­˜ã™ã‚‹"""
        pass # (ä»¥ä¸‹çœç•¥ã€å¤‰æ›´ãªã—)