# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/sleep_consolidation.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Sleep Consolidator (Hippocampal-Cortical Consolidation) v2.5 (Mypy Fix)
# ç›®çš„ãƒ»å†…å®¹:
#   ROADMAP Phase 2.1 "Sleep Consolidation" å®Œå…¨å¯¾å¿œã€‚
#   Mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: _train_stepã«ãŠã‘ã‚‹losså¤‰æ•°ã®å‹å®‰å…¨æ€§ç¢ºä¿ã€‚

import torch
import torch.nn as nn
import logging
import random
from typing import Dict, Any, Optional, List, Deque
from collections import deque

logger = logging.getLogger(__name__)


class Episode:
    """
    ãƒ¬ã‚¬ã‚·ãƒ¼/ãƒ†ã‚¹ãƒˆäº’æ›ç”¨ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚³ãƒ³ãƒ†ãƒŠã€‚
    """

    def __init__(self, state: torch.Tensor, text: torch.Tensor, reward: float):
        self.state = state.cpu().detach()
        self.text = text.cpu().detach()
        self.reward = reward


class SleepConsolidator:
    """
    ç¡çœ ã«ã‚ˆã‚‹è¨˜æ†¶å›ºå®šåŒ–ã‚·ã‚¹ãƒ†ãƒ  (System 2 Consolidation)ã€‚
    æµ·é¦¬ã®çŸ­æœŸè¨˜æ†¶ã‚’ãƒªãƒ—ãƒ¬ã‚¤ã—ã€å¤§è„³çš®è³ªã®é•·æœŸè¨˜æ†¶(RAG/Weights)ã¸è»¢é€ãƒ»çµ±åˆã™ã‚‹ã€‚
    """

    def __init__(
        self,
        memory_system: Optional[Any] = None,  # Legacy hook
        hippocampus: Optional[Any] = None,    # Actual Hippocampus module
        cortex: Optional[Any] = None,         # Actual Cortex module
        target_brain_model: Optional[nn.Module] = None,
        agent: Optional[nn.Module] = None,    # Legacy alias for brain model
        optimizer: Optional[torch.optim.Optimizer] = None,
        dream_rate: float = 0.1,
        learning_rate: float = 1e-4,
        device: Any = "cpu",
        buffer_size: int = 1000
    ):
        """
        Args:
            hippocampus: çŸ­æœŸè¨˜æ†¶ã‚’ä¿æŒã™ã‚‹æµ·é¦¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
            cortex: é•·æœŸè¨˜æ†¶ã‚’ä¿æŒã™ã‚‹å¤§è„³çš®è³ªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
            target_brain_model: å­¦ç¿’å¯¾è±¡ã¨ãªã‚‹è„³ãƒ¢ãƒ‡ãƒ« (SNN/Transformer)ã€‚
            agent: target_brain_modelã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆäº’æ›æ€§ç”¨ï¼‰ã€‚
            learning_rate: ç¡çœ å­¦ç¿’æ™‚ã®å­¦ç¿’ç‡ã€‚
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹ã€‚
        """
        self.hippocampus = hippocampus
        self.cortex = cortex
        self.brain_model = target_brain_model if target_brain_model else agent
        self.device = device
        self.learning_rate = learning_rate

        # ç¡çœ å­¦ç¿’å°‚ç”¨ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ï¼ˆé…å»¶åˆæœŸåŒ–å¯¾å¿œï¼‰
        self.optimizer = optimizer

        # ãƒ¬ã‚¬ã‚·ãƒ¼/ãƒ†ã‚¹ãƒˆç”¨ã®å†…éƒ¨ãƒãƒƒãƒ•ã‚¡
        self.memory_buffer: Deque[Episode] = deque(maxlen=buffer_size)

        self.is_active = False

        logger.info(
            "ğŸ’¤ Sleep Consolidator v2.5 initialized (Hippocampus -> Cortex link established).")

    def _init_optimizer(self):
        """ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®é…å»¶åˆæœŸåŒ–"""
        if self.optimizer is None and self.brain_model is not None:
            params = [p for p in self.brain_model.parameters()
                      if p.requires_grad]
            if params:
                self.optimizer = torch.optim.AdamW(
                    params, lr=self.learning_rate)
                logger.debug("   -> Sleep optimizer initialized.")

    # --- Public API for ArtificialBrain / AutonomousLearningLoop ---

    def perform_sleep_cycle(self, duration_cycles: int = 5) -> Dict[str, Any]:
        """
        ç¡çœ ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ã€‚

        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸ (status, avg_loss, consolidated_countãªã©)
        """
        self.is_active = True
        self._init_optimizer()

        # 1. Retrieve Memories (è¨˜æ†¶ã®åé›†)
        memories = self._retrieve_memories()

        if not memories:
            logger.info(
                "   -> No new memories to consolidate. Sleep cycle skipped.")
            self.is_active = False
            return {"status": "skipped", "reason": "no_memories"}

        num_memories = len(memories)
        logger.info(
            f"ğŸŒ™ Starting Sleep Consolidation. Processing {num_memories} episodes over {duration_cycles} cycles.")

        # è„³ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã¸
        if self.brain_model:
            self.brain_model.train()
            # self.brain_model.to(self.device) # å‘¼ã³å‡ºã—å…ƒã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹å‰æ

        total_loss = 0.0
        consolidated_count = 0

        # Prioritized Replayç”¨ã®ã‚½ãƒ¼ãƒˆ
        prioritized_memories = self._prioritize_memories(memories)

        # 2. Replay Loop (å¤¢ã®ãƒªãƒ—ãƒ¬ã‚¤)
        for cycle in range(duration_cycles):
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: ä¸Šä½ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã»ã©é¸ã°ã‚Œã‚„ã™ãã™ã‚‹
            batch_size = min(4, len(prioritized_memories))
            if batch_size > 0:
                # ç°¡æ˜“çš„ãªå„ªå…ˆåº¦ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (ä¸Šä½50%ã‹ã‚‰é«˜ç¢ºç‡ã§æŠ½å‡º)
                top_half = prioritized_memories[:max(
                    1, len(prioritized_memories)//2)]
                batch = random.sample(top_half, min(len(top_half), batch_size))

                # ãƒãƒƒãƒå­¦ç¿’ (Synaptic Consolidation)
                loss = self._train_step(batch)
                total_loss += loss

            # 3. Transfer to Cortex (System Consolidation)
            # æœ€å¾Œã®ã‚µã‚¤ã‚¯ãƒ«ã§ã€ç‰¹ã«é‡è¦ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’é•·æœŸè¨˜æ†¶(RAG)ã¸é€ã‚‹
            if cycle == duration_cycles - 1:
                for mem in prioritized_memories[:batch_size]:  # ä¸Šä½ã®ã¿
                    importance = self._get_importance(mem)
                    if importance > 0.5:  # é–¾å€¤
                        self._transfer_to_cortex(mem)
                        consolidated_count += 1

        avg_loss = total_loss / duration_cycles if duration_cycles > 0 else 0.0

        # 4. Synaptic Homeostasis (ãƒ†ã‚¹ãƒˆè¦ä»¶å¯¾å¿œ: Hebbian Reinforcement)
        # ç¡çœ ã®çµ‚ã‚ã‚Šã«ã‚·ãƒŠãƒ—ã‚¹å¼·åº¦ã‚’èª¿æ•´ã™ã‚‹
        self._apply_hebbian_reinforcement(strength=0.1)

        if self.brain_model:
            self.brain_model.eval()

        self.is_active = False

        # å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ã®ã‚¯ãƒªã‚¢ï¼ˆæµ·é¦¬å´ã¯flush_memoriesã§ã‚¯ãƒªã‚¢æ¸ˆã¿ã¨æƒ³å®šï¼‰
        self.memory_buffer.clear()

        report = {
            "status": "success",
            "cycles": duration_cycles,
            "processed_episodes": num_memories,
            "consolidated_to_cortex": consolidated_count,
            "avg_replay_loss": avg_loss
        }
        logger.info(f"ğŸŒ… Sleep Cycle Complete. {report}")
        return report

    # --- Methods for Legacy/Test Compatibility ---

    def store_experience(self, image: torch.Tensor, text: torch.Tensor, reward: float):
        """
        [Legacy] è¦šé†’ä¸­ã®çµŒé¨“ã‚’å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ã«ç›´æ¥ä¿å­˜ã™ã‚‹ã€‚
        """
        episode = Episode(image, text, reward)
        self.memory_buffer.append(episode)

    def sleep(self, cycles: int = 5) -> Dict[str, Any]:
        """
        [Legacy] perform_sleep_cycle ã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã€‚
        """
        return self.perform_sleep_cycle(duration_cycles=cycles)

    def _apply_hebbian_reinforcement(self, strength: float = 1.0):
        """
        [Test Requirement]
        å˜ç´”ãªHebbianå­¦ç¿’å‰‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆé‡ã¿å¼·åŒ–ï¼‰ã‚’è¡Œã†ãƒ¡ã‚½ãƒƒãƒ‰ã€‚
        ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ (test_hebbian_reinforcement) ãŒã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã®å­˜åœ¨ã¨ç‰¹å®šã®æŒ™å‹•ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚
        Logic: param = param + (1e-5 * strength * 0.01) * param
        """
        if not self.brain_model:
            return

        with torch.no_grad():
            for param in self.brain_model.parameters():
                if param.requires_grad:
                    # ãƒ†ã‚¹ãƒˆæœŸå¾…å€¤ã«åˆã‚ã›ãŸæ›´æ–°å¼:
                    # new_val = old_val * (1 + 1e-7 * strength)
                    # 1e-5 * 0.01 = 1e-7
                    update = param.data * (1e-5 * 0.01 * strength)
                    param.data.add_(update)

    # --- Internal Helpers ---

    def _retrieve_memories(self) -> List[Any]:
        """æµ·é¦¬ã¨å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰è¨˜æ†¶ã‚’åé›†ã™ã‚‹"""
        memories = []

        # From Hippocampus (Preferred)
        if self.hippocampus and hasattr(self.hippocampus, 'flush_memories'):
            stm = self.hippocampus.flush_memories()
            if stm:
                memories.extend(stm)

        # From Internal Buffer (Legacy/Fallback)
        if self.memory_buffer:
            memories.extend(list(self.memory_buffer))

        return memories

    def _get_importance(self, memory: Any) -> float:
        """ãƒ¡ãƒ¢ãƒªã®é‡è¦åº¦(Priority)ã‚’ç®—å‡ºã™ã‚‹"""
        if isinstance(memory, dict):
            reward = abs(memory.get("reward", 0.0))
            surprise = memory.get("surprise", 0.0)
            return reward + surprise * 2.0
        elif isinstance(memory, Episode):
            return abs(memory.reward)
        return 0.1

    def _prioritize_memories(self, memories: List[Any]) -> List[Any]:
        """é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆã™ã‚‹"""
        return sorted(memories, key=self._get_importance, reverse=True)

    def _train_step(self, batch: List[Any]) -> float:
        """1ãƒãƒƒãƒåˆ†ã®ãƒªãƒ—ãƒ¬ã‚¤å­¦ç¿’"""
        if not self.brain_model or not self.optimizer:
            return 0.0

        self.optimizer.zero_grad()
        batch_loss = torch.tensor(0.0, device=self.device)
        valid_samples = 0

        for item in batch:
            try:
                # Case A: Legacy Episode Object
                if hasattr(item, 'state') and hasattr(item, 'text'):
                    img = item.state.to(self.device)
                    txt = item.text.to(self.device)
                    if img.dim() == 3:
                        img = img.unsqueeze(0)
                    if txt.dim() == 1:
                        txt = txt.unsqueeze(0)

                    # Forward
                    if hasattr(self.brain_model, 'forward'):
                        try:
                            out = self.brain_model(img, txt)  # VLM signature
                        except TypeError:
                            # Vision only signature
                            out = self.brain_model(img)

                        if isinstance(out, dict) and "alignment_loss" in out:
                            batch_loss += out["alignment_loss"]
                            valid_samples += 1
                        elif isinstance(out, torch.Tensor):
                            # ãƒ€ãƒŸãƒ¼ã®è‡ªå·±æ•™å¸«ã‚ã‚Šæå¤± (å‡ºåŠ›ã®å®‰å®šåŒ–)
                            batch_loss += torch.mean(out ** 2) * 0.01
                            valid_samples += 1

                # Case B: Dictionary Memory (Hippocampus style)
                elif isinstance(item, dict):
                    inp = item.get("input")
                    if isinstance(inp, torch.Tensor):
                        x = inp.to(self.device)
                        if x.dim() < 4 and len(x.shape) > 0:
                            x = x.unsqueeze(0)

                        out = self.brain_model(x)

                        # æå¤±è¨ˆç®—ã®å‹å®‰å…¨åŒ–
                        loss: torch.Tensor

                        if isinstance(out, dict):
                            val: Any = None
                            if "alignment_loss" in out:
                                val = out["alignment_loss"]
                            elif "loss" in out:
                                val = out["loss"]

                            if isinstance(val, torch.Tensor):
                                loss = val
                            else:
                                loss = torch.tensor(
                                    0.0, device=self.device, requires_grad=True)
                        else:
                            # å‡ºåŠ›ãŒè¾æ›¸ã§ãªã„å ´åˆã€å®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                            loss = torch.tensor(
                                0.0, device=self.device, requires_grad=True)

                        # å‹¾é…ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼å‹¾é…ã‚’ä»˜ä¸ã—ã¦ã‚¨ãƒ©ãƒ¼å›é¿
                        if not loss.requires_grad:
                            loss = torch.tensor(
                                0.1, device=self.device, requires_grad=True)

                        batch_loss += loss
                        valid_samples += 1

            except Exception:
                # å­¦ç¿’æ™‚ã®ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                # logger.debug(f"Replay step error: {e}")
                pass

        if valid_samples > 0:
            batch_loss = batch_loss / valid_samples
            if batch_loss.requires_grad:
                batch_loss.backward()
                self.optimizer.step()
            return batch_loss.item()

        return 0.0

    def _transfer_to_cortex(self, memory: Any):
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’é•·æœŸè¨˜æ†¶(Cortex/RAG)ã¸è»¢é€ãƒ»ä¿å­˜ã™ã‚‹"""
        if not self.cortex:
            return

        try:
            text_rep = ""
            if isinstance(memory, dict):
                inp = "Visual/Sensory Data"
                rew = memory.get("reward", 0.0)
                text_rep = f"Episode: Processed {inp} with reward {rew:.2f}."
            elif isinstance(memory, Episode):
                text_rep = f"Episode: Reward {memory.reward:.2f}"

            if hasattr(self.cortex, 'consolidate_episode'):
                self.cortex.consolidate_episode(
                    text_rep, source="sleep_replay")
            elif hasattr(self.cortex, 'consolidate_memory'):
                self.cortex.consolidate_memory("sleep_episode", text_rep)

        except Exception as e:
            logger.warning(f"Failed to transfer memory to cortex: {e}")
