# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/thalamus.py
# Title: Thalamus (è¦–åºŠ) Module
# Description:
# - æ„Ÿè¦šæƒ…å ±ã®çš®è³ªã¸ã®ãƒªãƒ¬ãƒ¼ã¨ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã€‚
# - çš®è³ªã‹ã‚‰ã®ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³æ³¨æ„ä¿¡å·ã«åŸºã¥ãã€å…¥åŠ›ã®é¸åˆ¥ã‚’è¡Œã†ã€‚
# - Phase 6: å…¨è„³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é‡è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€‚

import torch
import torch.nn as nn
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)

class Thalamus(nn.Module):
    """
    è¦–åºŠãƒ¢ãƒ‡ãƒ«ã€‚
    æ„Ÿè¦šå™¨ã‹ã‚‰ã®ãƒœãƒˆãƒ ã‚¢ãƒƒãƒ—ä¿¡å·ã¨ã€å¤§è„³çš®è³ª/å‰é ­å‰é‡ã‹ã‚‰ã®ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³ä¿¡å·ã‚’çµ±åˆã™ã‚‹ã€‚
    """
    def __init__(self, input_dim: int = 784, output_dim: int = 256, device: str = 'cpu'):
        super().__init__()
        self.device = device
        self.input_dim = input_dim
        self.output_dim = output_dim
        
        # æ„Ÿè¦šä¸­ç¶™æ ¸ (Relay Nuclei): å˜ç´”ãªç·šå½¢å¤‰æ›ã§ã¯ãªãã€ã‚²ãƒ¼ãƒˆä»˜ããƒªãƒ¬ãƒ¼
        self.relay_weights = nn.Linear(input_dim, output_dim, bias=False)
        
        # ç¶²æ§˜ä½“æ ¸ (TRN: Thalamic Reticular Nucleus): æŠ‘åˆ¶æ€§åˆ¶å¾¡
        # ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³æ³¨æ„ä¿¡å·ã‚’å—ã‘å–ã‚Šã€ãƒªãƒ¬ãƒ¼ç´°èƒã‚’æŠ‘åˆ¶/è„±æŠ‘åˆ¶ã™ã‚‹
        self.attention_gate = nn.Linear(output_dim, output_dim)
        self.sigmoid = nn.Sigmoid()
        
        # çŠ¶æ…‹ä¿æŒ
        self.current_state = "OPEN" # OPEN, GATED, SLEEP
        self.to(device)
        logger.info(f"ğŸ§  Thalamus initialized (In: {input_dim}, Out: {output_dim})")

    def forward(self, sensory_input: torch.Tensor, top_down_attention: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        Args:
            sensory_input: æ„Ÿè¦šå™¨ã‹ã‚‰ã®ç”Ÿã‚¹ãƒ‘ã‚¤ã‚¯ã¾ãŸã¯ãƒ¬ãƒ¼ãƒˆä¿¡å·
            top_down_attention: çš®è³ªã‹ã‚‰ã®æ³¨æ„åˆ¶å¾¡ä¿¡å· (Optional)
        Returns:
            Dict containing 'relayed_output' and 'gate_status'
        """
        # 1. åŸºæœ¬çš„ãªãƒªãƒ¬ãƒ¼å‡¦ç†
        relayed = self.relay_weights(sensory_input)
        
        # 2. ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (Attention Control)
        gate_value = torch.ones_like(relayed)
        
        if top_down_attention is not None:
            # æ³¨æ„ä¿¡å·ãŒã‚ã‚‹å ´åˆã€TRNã‚’ä»‹ã—ã¦ã‚²ãƒ¼ãƒˆã‚’èª¿æ•´
            # æ³¨æ„ä¿¡å·ãŒé«˜ã„ã»ã©ã€ã‚²ãƒ¼ãƒˆãŒé–‹ã (è„±æŠ‘åˆ¶)
            gate_control = self.attention_gate(top_down_attention)
            gate_value = self.sigmoid(gate_control)
            relayed = relayed * gate_value
        
        # 3. ç¡çœ æ™‚ã®é®æ–­ (Burst mode vs Tonic mode simulation)
        if self.current_state == "SLEEP":
            # ç¡çœ ç´¡éŒ˜æ³¢ (Sleep Spindles) ã®ã‚ˆã†ãªãƒã‚¤ã‚ºã®ã¿ã‚’é€šã™ã‹ã€å®Œå…¨ã«é®æ–­
            relayed = relayed * 0.1 # å¤§å¹…ã«æ¸›è¡°
            
        return {
            "relayed_output": relayed,
            "gate_value": gate_value
        }

    def set_state(self, state: str):
        """
        è„³ã®çŠ¶æ…‹ã«åˆã‚ã›ã¦è¦–åºŠã®ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ (AWAKE / SLEEP)
        """
        if state in ["AWAKE", "SLEEP"]:
            self.current_state = state
            logger.info(f"Thalamus state switched to: {state}")
        else:
            logger.warning(f"Invalid thalamus state: {state}")