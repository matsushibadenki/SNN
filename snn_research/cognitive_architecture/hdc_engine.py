# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/hdc_engine.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: HDC Engine v2.1 (Full Suite)
# æ©Ÿèƒ½èª¬æ˜: 
#   HDCæ¼”ç®—ã‚¨ãƒ³ã‚¸ãƒ³ã€Neuro-Symbolic Bridgeã€ãŠã‚ˆã³ HDCReasoningAgent ã‚’çµ±åˆã€‚
#   ã‚·ãƒ³ãƒœãƒ«æ¥åœ°ã¨æ¨è«–æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã€‚

import torch
import torch.nn as nn
import logging
from typing import Dict, Optional, List, Tuple

logger = logging.getLogger(__name__)

class HDCEngine:
    """
    Hyperdimensional Computing (HDC) ã‚¨ãƒ³ã‚¸ãƒ³ã€‚
    MAP (Multiply, Add, Permute) ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚
    """
    
    def __init__(self, dim: int = 10000, device: Optional[str] = None):
        self.dim = dim
        self.device = torch.device(device if device else "cpu")
        self.item_memory: Dict[str, torch.Tensor] = {}
        logger.info(f"ğŸŒŒ HDC Engine initialized (Dim: {dim}, Device: {self.device})")

    def create_hypervector(self, name: Optional[str] = None) -> torch.Tensor:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªãƒã‚¤ãƒŠãƒªãƒã‚¤ãƒ‘ãƒ¼ãƒ™ã‚¯ãƒˆãƒ« (-1, +1) ã‚’ç”Ÿæˆ"""
        hv = torch.randint(0, 2, (self.dim,), device=self.device, dtype=torch.float32)
        hv = torch.where(hv == 0, -1.0, 1.0)
        if name:
            self.item_memory[name] = hv
        return hv

    def get_hypervector(self, name: str) -> torch.Tensor:
        """ãƒ¡ãƒ¢ãƒªã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ã€ãªã‘ã‚Œã°æ–°è¦ä½œæˆ"""
        if name not in self.item_memory:
            return self.create_hypervector(name)
        return self.item_memory[name]

    # --- Operations ---

    def bind(self, hv1: torch.Tensor, hv2: torch.Tensor) -> torch.Tensor:
        """Binding (XOR equivalent in bipolar)"""
        return hv1 * hv2

    def bundle(self, hvs: List[torch.Tensor]) -> torch.Tensor:
        """Bundling (Superposition with normalization)"""
        if not hvs:
            return torch.zeros(self.dim, device=self.device)
        stacked = torch.stack(hvs)
        summed = torch.sum(stacked, dim=0)
        bundled = torch.sign(summed)
        bundled[bundled == 0] = 1.0 
        return bundled

    def permute(self, hv: torch.Tensor, shifts: int = 1) -> torch.Tensor:
        """Permutation (Cyclic shift)"""
        return torch.roll(hv, shifts=shifts, dims=0)

    def similarity(self, hv1: torch.Tensor, hv2: torch.Tensor) -> float:
        """Cosine Similarity"""
        return torch.nn.functional.cosine_similarity(hv1.unsqueeze(0), hv2.unsqueeze(0)).item()

    def query_memory(self, query_hv: torch.Tensor, top_k: int = 1) -> List[Tuple[str, float]]:
        """é€£æƒ³ãƒ¡ãƒ¢ãƒªæ¤œç´¢"""
        results = []
        for name, mem_hv in self.item_memory.items():
            sim = self.similarity(query_hv, mem_hv)
            results.append((name, sim))
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]

class NeuroSymbolicBridge(nn.Module):
    """
    SNN(ã‚µãƒ–ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯)ã¨HDC(ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯)ã®æ¶ã‘æ©‹ã€‚
    ãƒ©ãƒ³ãƒ€ãƒ å°„å½±ã‚’ç”¨ã„ã¦ã€ä½æ¬¡å…ƒã®ã‚¹ãƒ‘ã‚¤ã‚¯æ´»å‹•ã‚’é«˜æ¬¡å…ƒã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã¸ã€
    ã‚ã‚‹ã„ã¯ãã®é€†ã¸ã¨å¤‰æ›ã™ã‚‹ã€‚
    """
    def __init__(self, snn_features: int, hdc_dim: int = 10000, device: Optional[str] = None):
        super().__init__()
        self.snn_features = snn_features
        self.hdc_dim = hdc_dim
        self.device = torch.device(device if device else "cpu")
        
        # å›ºå®šãƒ©ãƒ³ãƒ€ãƒ å°„å½±è¡Œåˆ— (å­¦ç¿’ä¸è¦ã€ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§ãŒé«˜ã„)
        # SNN -> HDC (Encoder)
        self.projection_matrix = torch.randn(hdc_dim, snn_features, device=self.device)
        # HDC -> SNN (Decoder) - æ“¬ä¼¼é€†è¡Œåˆ—ã«è¿‘ã„å½¹å‰²ã ãŒã€ã“ã“ã§ã¯è»¢ç½®ã‚’ä½¿ç”¨(åŒæ–¹å‘æ€§)
        
        # 2å€¤åŒ–ã®ãŸã‚ã®é–¾å€¤
        self.threshold = 0.0

    def spikes_to_hypervector(self, spikes: torch.Tensor) -> torch.Tensor:
        """
        SNNã®ã‚¹ãƒ‘ã‚¤ã‚¯æ´»å‹• (Batch, Features) or (Features,) ã‚’ ãƒã‚¤ãƒ‘ãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã€‚
        Symbol Grounding: ã€ŒçŸ¥è¦šã€ã‚’ã€Œæ¦‚å¿µã€ã«å¤‰æ›ã€‚
        """
        if spikes.dim() > 1:
            # æ™‚é–“å¹³å‡ã¾ãŸã¯ãƒãƒƒãƒå¹³å‡ã‚’ã¨ã‚‹ï¼ˆç°¡æ˜“åŒ–ï¼‰
            spikes = spikes.mean(dim=0)
            
        # å°„å½±: HV = sign(W @ spikes)
        projected = torch.matmul(self.projection_matrix, spikes)
        hv = torch.sign(projected)
        hv[hv == 0] = 1.0
        return hv

    def hypervector_to_spikes(self, hv: torch.Tensor, steps: int = 10) -> torch.Tensor:
        """
        ãƒã‚¤ãƒ‘ãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’SNNã®å…¥åŠ›é›»æµ/ã‚¹ãƒ‘ã‚¤ã‚¯ã«å¤‰æ›ã€‚
        Top-down Attention / Imagination: ã€Œæ¦‚å¿µã€ã‹ã‚‰ã€ŒçŸ¥è¦šã‚¤ãƒ¡ãƒ¼ã‚¸ã€ã‚’ç”Ÿæˆã€‚
        """
        # é€†å°„å½±: Input = W.T @ HV
        currents = torch.matmul(self.projection_matrix.t(), hv)
        
        # ãƒ¬ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¸ã®å¤‰æ› (ç°¡æ˜“çš„ãªãƒã‚¢ã‚½ãƒ³ç”Ÿæˆ)
        # é›»æµå€¤ã‚’ç™ºç«ç¢ºç‡ã¨ã¿ãªã™ï¼ˆæ­£è¦åŒ–å¿…è¦ï¼‰
        probs = torch.sigmoid(currents) # 0.0 ~ 1.0
        
        # æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—åˆ†ç”Ÿæˆ
        spike_train = (torch.rand(steps, self.snn_features, device=self.device) < probs).float()
        return spike_train

class HDCReasoningAgent:
    """
    HDCã‚’ç”¨ã„ãŸç°¡æ˜“æ¨è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
    """
    def __init__(self, engine: HDCEngine):
        self.hdc = engine
        
    def learn_concept(self, subject: str, relation: str, obj: str):
        """
        çŸ¥è­˜ã‚’çµåˆã—ã¦è¨˜æ†¶ã™ã‚‹ã€‚
        Memory = Memory + (Subject * Relation * Object)
        """
        # ä¾‹: (Japan * Capital * Tokyo)
        h_sub = self.hdc.get_hypervector(subject)
        h_rel = self.hdc.get_hypervector(relation)
        h_obj = self.hdc.get_hypervector(obj)
        
        fact = self.hdc.bind(self.hdc.bind(h_sub, h_rel), h_obj)
        
        # "Global Knowledge" ã¨ã„ã†æ¦‚å¿µã«æŸã­ã¦ã„ãï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        global_mem = self.hdc.get_hypervector("GLOBAL_KNOWLEDGE")
        new_mem = self.hdc.bundle([global_mem, fact])
        self.hdc.item_memory["GLOBAL_KNOWLEDGE"] = new_mem
        
    def query(self, subject: str, relation: str) -> List[Tuple[str, float]]:
        """
        æ¨è«–ã‚’è¡Œã†ã€‚
        Query: Japan * Capital * ? = Tokyo
        """
        global_mem = self.hdc.get_hypervector("GLOBAL_KNOWLEDGE")
        h_sub = self.hdc.get_hypervector(subject)
        h_rel = self.hdc.get_hypervector(relation)
        
        # Query = Memory * Subject * Relation
        query_res = self.hdc.bind(self.hdc.bind(global_mem, h_sub), h_rel)
        
        # ãƒã‚¤ã‚ºã®ä¸­ã‹ã‚‰æœ€ã‚‚è¿‘ã„æ¦‚å¿µã‚’æ¢ã™
        return self.hdc.query_memory(query_res, top_k=3)