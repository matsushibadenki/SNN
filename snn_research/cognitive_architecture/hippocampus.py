# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/hippocampus.py
# Title: Hippocampal Formation v3.2 (Phase 2: Sleep Support)
# Description: é•·æœŸè¨˜æ†¶è»¢é€(Consolidation)ã®ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å¼·åŒ–ã€‚

import logging
import torch
import torch.nn.functional as F
from typing import List, Any, Optional
from collections import deque
from snn_research.cognitive_architecture.rag_snn import RAGSystem

logger = logging.getLogger(__name__)


class BipolarAssociativeMemory:
    """
    SCALã«åŸºã¥ãé€£æƒ³è¨˜æ†¶ãƒãƒˆãƒªã‚¯ã‚¹ã€‚
    ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒã‚¤ãƒãƒ¼ãƒ©é‡å¿ƒå­¦ç¿’ã§è¨˜æ†¶ã—ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æƒ³èµ·ã™ã‚‹ã€‚
    """

    def __init__(self, dim: int, capacity: int = 100):
        self.dim = dim
        self.capacity = capacity
        # è¨˜æ†¶ãƒãƒˆãƒªã‚¯ã‚¹: [Capacity, Dim]
        # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿æŒ
        self.memory = torch.zeros(capacity, dim)
        self.usage = torch.zeros(capacity)  # ä½¿ç”¨é »åº¦
        self.pointer = 0
        self.is_full = False

    def store(self, vector: torch.Tensor):
        """
        ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨˜æ†¶ã™ã‚‹ã€‚Centroid Updateã‚’è¡Œã†ã€‚
        """
        if vector.dim() == 1:
            vector = vector.unsqueeze(0)

        # Bipolar Transform & Normalize
        # 0.5ä¸­å¿ƒã«[-1, 1]ã¸å¤‰æ›ã—ã¦æ­£è¦åŒ–
        vec_bipolar = (vector - 0.5) * 2.0
        vec_norm = F.normalize(vec_bipolar, p=2, dim=1)

        # æœ€ã‚‚ä¼¼ã¦ã„ã‚‹ã‚¹ãƒ­ãƒƒãƒˆã‚’æ¢ã™
        sim = torch.matmul(vec_norm, self.memory.t()).squeeze(0)

        # ãƒã‚¹ã‚¯: ã¾ã åŸ‹ã¾ã£ã¦ã„ãªã„ã‚¹ãƒ­ãƒƒãƒˆã¨ã®é¡ä¼¼åº¦ã¯ç„¡è¦–ï¼ˆåˆæœŸå€¤0ã¨ã®ãƒãƒƒãƒãƒ³ã‚°é˜²æ­¢ï¼‰
        if not self.is_full:
            # ç¾åœ¨ã®pointerä»¥é™ã¯ç„¡åŠ¹ã¨ã™ã‚‹ï¼ˆç°¡æ˜“çš„ãªãƒã‚¹ã‚¯ï¼‰
            # å³å¯†ã«ã¯ä¸€åº¦ã‚‚æ›¸ãè¾¼ã¾ã‚Œã¦ã„ãªã„å ´æ‰€ã‚’ç®¡ç†ã™ã¹ãã ãŒã€ä»Šå›ã¯zerosåˆæœŸåŒ–ã‚’åˆ©ç”¨
            pass

        max_sim, idx = sim.max(dim=0)
        learning_rate = 0.1

        # é¡ä¼¼åº¦é–¾å€¤ (0.85) ä»¥ä¸Šãªã‚‰åŒä¸€è¨˜æ†¶ã¨ã¿ãªã—ã¦æ›´æ–°
        if max_sim > 0.85 and (self.is_full or idx < self.pointer):
            current_mem = self.memory[idx]
            # EMA Update: mem = mem + lr * (input - mem)
            new_mem = current_mem + learning_rate * \
                (vec_norm.squeeze(0) - current_mem)
            self.memory[idx] = F.normalize(new_mem, p=2, dim=0)
            self.usage[idx] += 1
        else:
            # æ–°è¦æ›¸ãè¾¼ã¿ (Ring Buffer)
            target_idx = self.pointer
            self.memory[target_idx] = vec_norm.squeeze(0)
            self.usage[target_idx] = 1

            self.pointer = (self.pointer + 1) % self.capacity
            if self.pointer == 0:
                self.is_full = True

    def retrieve(self, query_vector: torch.Tensor, k: int = 1) -> List[int]:
        """
        é¡ä¼¼ãƒ¡ãƒ¢ãƒªã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™ã€‚
        """
        if query_vector.dim() == 1:
            query_vector = query_vector.unsqueeze(0)

        q_bipolar = (query_vector - 0.5) * 2.0
        q_norm = F.normalize(q_bipolar, p=2, dim=1)

        sim = torch.matmul(q_norm, self.memory.t())

        # æœªä½¿ç”¨é ˜åŸŸã®ã‚¹ã‚³ã‚¢ã‚’ä¸‹ã’ã‚‹
        if not self.is_full:
            sim[:, self.pointer:] = -2.0  # Cosine sim range is [-1, 1]

        top_v, top_i = sim.topk(k, dim=1)
        return top_i.squeeze(0).tolist()


class Hippocampus:
    """
    çŸ­æœŸè¨˜æ†¶ï¼ˆSTMï¼‰ã¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã®ä¸€æ™‚ä¿ç®¡ã‚’æ‹…å½“ã€‚
    ç¡çœ ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã„ã¦ã€ã“ã“ã«ã‚ã‚‹è¨˜æ†¶ãŒCortexï¼ˆé•·æœŸè¨˜æ†¶ï¼‰ã¸è»¢é€ã•ã‚Œã‚‹ã€‚
    """

    def __init__(
        self,
        rag_system: Optional[RAGSystem] = None,
        short_term_capacity: int = 50,
        working_memory_dim: int = 256
    ):
        self.rag = rag_system if rag_system else RAGSystem()
        # çŸ­æœŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒãƒƒãƒ•ã‚¡ (FIFO)
        self.episodic_buffer: deque = deque(maxlen=short_term_capacity)

        # SCAL Associative Memory (ãƒ™ã‚¯ãƒˆãƒ«ç”¨çŸ­æœŸè¨˜æ†¶)
        self.associative_memory = BipolarAssociativeMemory(
            working_memory_dim, capacity=short_term_capacity)

        # ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ¡ãƒ¢ãƒª (ç¾åœ¨ã®æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«)
        self.working_memory = torch.zeros(working_memory_dim)

        logger.info(
            "ğŸ§  Hippocampus initialized (SCAL Memory & Sleep Support Enabled).")

    def process(self, input_data: Any) -> Any:
        """
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã¨è¨˜æ†¶ã€‚
        """
        # ã‚¯ã‚¨ãƒªå‡¦ç†
        if isinstance(input_data, str) and input_data.startswith("QUERY:"):
            query = input_data.replace("QUERY:", "").strip()
            return self.recall(query)

        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¨ã—ã¦ä¿å­˜
        self.store_episode(input_data)

        # ãƒ™ã‚¯ãƒˆãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°é€£æƒ³è¨˜æ†¶ã¸ä¿å­˜
        if isinstance(input_data, dict) and 'embedding' in input_data:
            emb = input_data['embedding']
            if isinstance(emb, torch.Tensor):
                self.associative_memory.store(emb)
                self.working_memory = emb  # WMæ›´æ–°

        return None

    def store_episode(self, data: Any):
        """çŸ­æœŸè¨˜æ†¶ãƒãƒƒãƒ•ã‚¡ã¸è¿½åŠ """
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã©ã‚’ä»˜ä¸ã™ã‚‹ã¨å°šè‰¯ã—ã ãŒã€ã“ã“ã§ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä¿æŒ
        self.episodic_buffer.append(data)

    def recall(self, query: str, k: int = 3) -> List[str]:
        """
        çŸ­æœŸè¨˜æ†¶ãŠã‚ˆã³RAGã‹ã‚‰æƒ…å ±ã‚’æ¤œç´¢
        """
        results = []

        # 1. STM Search (ç›´è¿‘ã®ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢)
        stm_hits = 0
        for item in reversed(self.episodic_buffer):
            item_text = str(item)
            if query in item_text:
                results.append(f"[STM] {item_text[:200]}...")
                stm_hits += 1
                if stm_hits >= 2:
                    break

        # 2. RAG Search (é•·æœŸè¨˜æ†¶)
        if self.rag:
            try:
                rag_results = self.rag.search(query, k=k)
                if rag_results:
                    results.extend(rag_results)
            except Exception:
                pass

        return results

    def flush_memories(self) -> List[Any]:
        """
        [Sleep Cycleç”¨]
        ãƒãƒƒãƒ•ã‚¡å†…ã®å…¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å–ã‚Šå‡ºã—ã€ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã€‚
        ã“ã‚Œã¯ç¡çœ æ™‚ã®è¨˜æ†¶å›ºå®šåŒ–(Consolidation)ãƒ—ãƒ­ã‚»ã‚¹ã§å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’æƒ³å®šã€‚
        """
        memories = list(self.episodic_buffer)
        self.episodic_buffer.clear()
        logger.info(
            f"ğŸ§  Hippocampus flushed {len(memories)} memories for sleep consolidation.")
        return memories

    def consolidate_memory(self):
        """
        [Legacy/Manual] æ‰‹å‹•ã§ã®å›ºå®šåŒ–å‘¼ã³å‡ºã—ç”¨ã€‚
        é€šå¸¸ã¯ SleepConsolidator çµŒç”±ã§è¡Œã†ã“ã¨ã‚’æ¨å¥¨ã€‚
        """
        if not self.episodic_buffer:
            return

        items_to_store = self.flush_memories()

        if items_to_store and self.rag:
            # æ–‡å­—åˆ—åŒ–ã—ã¦çµåˆä¿å­˜ (ç°¡æ˜“çš„)
            texts = [str(item) for item in items_to_store]
            combined_text = "\n".join(texts)
            try:
                self.rag.add_knowledge(combined_text)
                logger.info(f"âœ… Manually consolidated {len(texts)} episodes.")
            except Exception:
                pass
