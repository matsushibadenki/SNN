# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/agency_engine.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Agency Engine (Free Will / Veto Mechanism) v1.0
# ç›®çš„ãƒ»å†…å®¹:
#   ROADMAP Phase 4.3 "Free Will & Agency" å¯¾å¿œã€‚
#   ãƒœãƒˆãƒ ã‚¢ãƒƒãƒ—ãªè¡å‹•ï¼ˆImpulseï¼‰ã«å¯¾ã—ã¦ã€ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãªæ„å¿—ï¼ˆIntentionï¼‰ãŒ
#   ä»‹å…¥ã—ã€è¡Œå‹•ã‚’è¨±å¯ã¾ãŸã¯æ‹’å¦ï¼ˆVetoï¼‰ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€‚
#   ã€Œè‡ªåˆ†ã®è¡Œå‹•ã‚’é¸ã‚“ã§ã„ã‚‹ã€ã¨ã„ã†æ„Ÿè¦šï¼ˆSense of Agencyï¼‰ã®åŸºç¤ã¨ãªã‚‹ã€‚

import torch
import torch.nn as nn
import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)

class AgencyEngine(nn.Module):
    """
    è‡ªç”±æ„å¿—ã‚¨ãƒ³ã‚¸ãƒ³ã€‚
    ç„¡æ„è­˜ã®è¡å‹•(Impulse)ã¨ã€æ„è­˜çš„ãªæ„å›³(Intention)ã‚’ç…§åˆã—ã€
    æœ€çµ‚çš„ãªè¡Œå‹•å®Ÿè¡ŒæŒ‡ä»¤(Motor Command)ã‚’ç™ºè¡Œã™ã‚‹ã€‚
    """
    
    def __init__(self, action_dim: int = 4, hidden_dim: int = 32):
        super().__init__()
        
        # 1. Evaluator (è¡Œå‹•ã®æ˜¯éã‚’å•ã†)
        # å…¥åŠ›: [Action_Impulse, Long_Term_Goal]
        # å‡ºåŠ›: Veto Probability (æ‹’å¦ç¢ºç‡)
        self.evaluator = nn.Sequential(
            nn.Linear(action_dim + hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )
        
        # å†…éƒ¨çŠ¶æ…‹: Sense of Agency (è‡ªåˆ†ãŒã‚„ã£ãŸæ„Ÿ)
        self.register_buffer("sense_of_agency", torch.tensor(0.5))
        
        logger.info("ğŸ•Šï¸ Agency Engine (Free Will / Veto Power) initialized.")

    def forward(
        self, 
        impulse: torch.Tensor, # ç„¡æ„è­˜ã‹ã‚‰ã®è¡Œå‹•ææ¡ˆ (Action Vector)
        goal_context: torch.Tensor # é•·æœŸçš„ãªç›®æ¨™/ä¾¡å€¤è¦³ (Context Vector)
    ) -> Dict[str, Any]:
        """
        è¡Œå‹•ææ¡ˆã‚’å¯©æŸ»ã™ã‚‹ã€‚
        """
        # è©•ä¾¡å…¥åŠ›ã®ä½œæˆ
        combined = torch.cat([impulse, goal_context], dim=-1)
        
        # æ‹’å¦æ¨©ã®ç™ºå‹•ç¢ºç‡ (Veto Probability)
        # é«˜ã„ã»ã©ã€Œãã‚Œã¯ãƒ€ãƒ¡ã ã€ã¨åˆ¤æ–­ã—ã¦ã„ã‚‹
        veto_prob = self.evaluator(combined)
        
        # æ±ºå®š (Thresholding)
        # ç¢ºç‡çš„ãªæºã‚‰ãã‚’æŒãŸã›ã‚‹ã“ã¨ã§ã€Œè¿·ã„ã€ã‚’è¡¨ç¾
        decision_threshold = 0.5
        is_vetoed = veto_prob > decision_threshold
        
        # æœ€çµ‚è¡Œå‹•
        if is_vetoed:
            final_action = torch.zeros_like(impulse) # è¡Œå‹•æŠ‘åˆ¶
            status = "VETOED"
        else:
            final_action = impulse # è¡Œå‹•è¨±å¯
            status = "EXECUTED"
            
        # Sense of Agencyã®æ›´æ–°
        # è‡ªåˆ†ã®æ„å›³(Goal)ã¨å®Ÿéš›ã®è¡Œå‹•(Final)ãŒä¸€è‡´ã—ã¦ã„ã‚Œã°ã€Œè‡ªå·±åŠ¹åŠ›æ„Ÿã€ãŒä¸ŠãŒã‚‹
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã€ŒVetoãŒæˆåŠŸã—ãŸã€ã¾ãŸã¯ã€Œæ„å›³é€šã‚Šå‹•ã„ãŸã€å ´åˆã«ä¸Šæ˜‡
        # è¡å‹•çš„ã«å‹•ã„ã¦ã—ã¾ã£ãŸ(Vetoå¤±æ•—)å ´åˆã¯ä¸‹ãŒã‚‹ãƒ­ã‚¸ãƒƒã‚¯ç­‰ã‚’å…¥ã‚Œã‚‰ã‚Œã‚‹ãŒä»Šå›ã¯å‰²æ„›
        
        return {
            "final_action": final_action,
            "veto_prob": veto_prob.item(),
            "status": status,
            "impulse_strength": impulse.norm().item()
        }