# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/basal_ganglia.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Basal Ganglia Action Selector v2.1
# ç›®çš„ãƒ»å†…å®¹:
#   è¡Œå‹•é¸æŠã®ä¸­æ¢ã€‚è¤‡æ•°ã®å€™è£œï¼ˆå¤–éƒ¨ææ¡ˆ + å†…éƒ¨ç”Ÿæˆï¼‰ã‹ã‚‰ã€
#   æƒ…å‹•ã‚„å ±é…¬äºˆæ¸¬ã«åŸºã¥ã„ã¦æœ€é©ãªè¡Œå‹•ã‚’ä¸€ã¤é¸æŠã™ã‚‹ã€‚

from typing import List, Dict, Any, Optional
import torch
from .global_workspace import GlobalWorkspace


class BasalGanglia:
    workspace: GlobalWorkspace

    def __init__(self, workspace: GlobalWorkspace, selection_threshold: float = 0.5, inhibition_strength: float = 0.3):
        self.workspace = workspace
        self.base_threshold = selection_threshold
        self.inhibition_strength = inhibition_strength
        self.selected_action: Optional[Dict[str, Any]] = None

        # Workspaceã‹ã‚‰ã®ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚‚ç›£è¦–ã™ã‚‹ãŒã€
        # ãƒ¡ã‚¤ãƒ³ã®è¡Œå‹•é¸æŠã¯ ArtificialBrain ã‹ã‚‰ select_action ãŒå‘¼ã°ã‚ŒãŸã¨ãã«è¡Œã†
        self.workspace.subscribe(self.handle_conscious_broadcast)
        print("ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚")

    def handle_conscious_broadcast(self, source: str, conscious_data: Dict[str, Any]):
        # ã“ã“ã§ã¯ç›´æ¥è¡Œå‹•æ±ºå®šã›ãšã€å†…éƒ¨çŠ¶æ…‹ã®æ›´æ–°ãªã©ã«ç•™ã‚ã‚‹ã®ãŒä¸€èˆ¬çš„ã ãŒã€
        # ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦ãƒ­ã‚°å‡ºåŠ›ã®ã¿è¡Œã†
        # print(f"ğŸ“¬ å¤§è„³åŸºåº•æ ¸: '{source}' ã‹ã‚‰ã®æ„è­˜çš„æƒ…å ±ã‚’å—ä¿¡ã€‚")
        pass

    def _generate_internal_candidates(self) -> List[Dict[str, Any]]:
        """å†…éƒ¨çš„ãªæœ¬èƒ½çš„è¡Œå‹•å€™è£œã‚’ç”Ÿæˆã™ã‚‹"""
        return [
            {'action': 'investigate_perception', 'value': 0.3},  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ¢ç´¢è¡Œå‹•
            {'action': 'reflect_on_emotion', 'value': 0.2},
            {'action': 'ignore', 'value': 0.1},  # ä½•ã‚‚ã—ãªã„
        ]

    def _modulate_threshold(self, emotion_context: Optional[Dict[str, float]]) -> float:
        if emotion_context is None:
            return self.base_threshold

        arousal = emotion_context.get("arousal", 0.0)
        # è¦šé†’åº¦ãŒé«˜ã„ã¨ãã¯é–¾å€¤ã‚’ä¸‹ã’ã¦è¡Œå‹•ã—ã‚„ã™ãã™ã‚‹ï¼ˆè¡å‹•çš„ï¼‰
        # ä¸å¿«(Negative Valence)ãŒå¼·ã„ã¨ãã¯ã€å›é¿è¡Œå‹•ãªã©ã‚’å–ã‚Šã‚„ã™ãã™ã‚‹èª¿æ•´ã‚‚å¯èƒ½
        return max(0.1, min(0.9, self.base_threshold - arousal * 0.2))

    def select_action(
        self,
        external_candidates: List[Dict[str, Any]],
        emotion_context: Optional[Dict[str, float]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        å¤–éƒ¨å€™è£œ(Reasoningçµæœãªã©)ã¨å†…éƒ¨å€™è£œã‚’çµ±åˆã—ã€è¡Œå‹•ã‚’é¸æŠã™ã‚‹ã€‚
        """
        self.selected_action = None

        # å€™è£œã®çµ±åˆ
        internal_candidates = self._generate_internal_candidates()
        all_candidates = external_candidates + internal_candidates

        if not all_candidates:
            return None

        current_threshold = self._modulate_threshold(emotion_context)

        # å€¤ã®ãƒ†ãƒ³ã‚½ãƒ«åŒ–
        values = torch.tensor([c.get('value', 0.0) for c in all_candidates])

        # æœ€ã‚‚ä¾¡å€¤ã®é«˜ã„è¡Œå‹•ã‚’é¸æŠ (Winner-Take-All)
        best_idx = torch.argmax(values)
        best_val = values[best_idx].item()

        # é–¾å€¤åˆ¤å®š
        if best_val >= current_threshold:
            self.selected_action = all_candidates[best_idx]
            # print(f"ğŸ† è¡Œå‹•é¸æŠ: '{self.selected_action.get('action')}' (æ´»æ€§å€¤: {best_val:.2f} >= {current_threshold:.2f})")
            return self.selected_action
        else:
            # print(f"ğŸ¤” è¡Œå‹•æ£„å´ (Best: {best_val:.2f} < Threshold: {current_threshold:.2f})")
            return None
