# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/global_workspace.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Global Workspace (Consciousness Hub) v1.3 (Dim Fix)
# ä¿®æ­£å†…å®¹: 1æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ«å…¥åŠ›æ™‚ã®ã‚¹ãƒ©ã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼(IndexError)ã‚’ä¿®æ­£ã€‚

import torch
import torch.nn as nn
import torch.nn.functional as F
import logging
from typing import Dict, Any, Optional, List, Callable

logger = logging.getLogger(__name__)


class GlobalWorkspace(nn.Module):
    """
    ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆGWTï¼‰ã€‚
    è„³å†…ã®æƒ…å ±ã®ã€Œç«¶åˆã€ã¨ã€Œæ”¾é€ã€ã‚’ç®¡ç†ã™ã‚‹ã€‚
    """
    workspace_state: torch.Tensor

    def __init__(
        self,
        dim: int = 64,
        num_slots: int = 1,
        decay: float = 0.9,
        model_registry: Optional[Any] = None  # Added for DI compatibility
    ):
        super().__init__()
        self.dim = dim
        self.num_slots = num_slots
        self.decay = decay
        self.model_registry = model_registry

        # æ„è­˜ã®å†…å®¹ï¼ˆGlobal Working Memoryï¼‰
        self.register_buffer("workspace_state", torch.zeros(1, dim))

        # Attention Mechanism (Selector)
        self.selector = nn.Sequential(
            nn.Linear(dim, dim),
            nn.Tanh(),
            nn.Linear(dim, 1)
        )

        # Subscribers
        self.subscribers: List[Callable[[str, Any], None]] = []
        self.current_content: Dict[str, Any] = {}

        logger.info(f"ğŸ‘ï¸ Global Workspace (Consciousness) initialized (Dim: {dim}).")

    def subscribe(self, callback: Callable[[str, Any], None]):
        """ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ„è­˜ã®æ”¾é€ã‚’å—ä¿¡ã™ã‚‹ãŸã‚ã«ç™»éŒ²ã™ã‚‹"""
        self.subscribers.append(callback)

    def upload_to_workspace(self, source: str, data: Any, salience: float = 0.5):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã¸ã®æƒ…å ±æä¾›"""
        if salience > 0.7:
            if isinstance(data, dict) and "vector_state" in data:
                vec = data["vector_state"]
                if isinstance(vec, torch.Tensor):
                    # æ¬¡å…ƒåˆã‚ã›
                    if vec.dim() == 1:
                         vec = vec.unsqueeze(0)
                    
                    if vec.shape[-1] == self.dim:
                        self.workspace_state = vec.detach()

            self._broadcast_to_subscribers(source, data)

    def broadcast(self, inputs: List[Any], context: Optional[str] = None) -> Any:
        """Legacy Interface"""
        tensor_inputs = {}
        for i, item in enumerate(inputs):
            if isinstance(item, torch.Tensor):
                tensor_inputs[f"input_{i}"] = item
            elif isinstance(item, dict) and "features" in item:
                tensor_inputs[f"module_{i}"] = item["features"]

        if tensor_inputs:
            result = self.forward(tensor_inputs)
            if result["winner"] is not None:
                self._broadcast_to_subscribers(
                    str(result["winner"]), result["broadcast"])
            return result["broadcast"]

        return self.workspace_state

    def get_current_thought(self) -> torch.Tensor:
        return self.workspace_state

    def get_information(self) -> torch.Tensor:
        """Alias for test compatibility (test_cognitive_components.py)"""
        return self.get_current_thought()

    def get_current_content(self) -> Dict[str, Any]:
        """
        [Phase 3.1] ç¾åœ¨ã®æ„è­˜å†…å®¹ï¼ˆè¾æ›¸å½¢å¼ï¼‰ã‚’å–å¾—ã™ã‚‹ã€‚
        ExplainabilityEngineç­‰ã§ä½¿ç”¨ã€‚
        """
        return self.current_content

    def _broadcast_to_subscribers(self, source: str, content: Any):
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¿æŒ
        if isinstance(content, dict):
            self.current_content = content
        else:
            self.current_content = {"type": "raw",
                                    "data": content, "source": source}

        for callback in self.subscribers:
            try:
                callback(source, content)
            except Exception as e:
                logger.warning(f"Broadcast error: {e}")

    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        candidates = []
        names = []

        for name, tensor in inputs.items():
            flat_tensor = tensor
            
            # æ™‚é–“æ¬¡å…ƒã®é›†ç´„ (Batch, Time, Dim) -> (Batch, Dim)
            if flat_tensor.dim() > 2:
                flat_tensor = flat_tensor.mean(dim=1)
            
            # [Fix] 1æ¬¡å…ƒå…¥åŠ› (Dim,) ã®å ´åˆã€ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ã—ã¦ (1, Dim) ã«ã™ã‚‹
            if flat_tensor.dim() == 1:
                flat_tensor = flat_tensor.unsqueeze(0)

            # æ¬¡å…ƒèª¿æ•´ (Feature Dim mismatch handling)
            current_dim = flat_tensor.shape[-1]
            if current_dim != self.dim:
                if current_dim < self.dim:
                    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                    pad = self.dim - current_dim
                    flat_tensor = F.pad(flat_tensor, (0, pad))
                else:
                    # åˆ‡ã‚Šæ¨ã¦ï¼ˆã‚¹ãƒ©ã‚¤ã‚¹ï¼‰
                    # flat_tensorã¯å¿…ãš2æ¬¡å…ƒä»¥ä¸Šã«ãªã£ã¦ã„ã‚‹ãŸã‚å®‰å…¨
                    flat_tensor = flat_tensor[:, :self.dim]

            candidates.append(flat_tensor)
            names.append(name)

        if not candidates:
            return {"broadcast": self.workspace_state, "winner": None, "salience": None}

        # ã‚¹ã‚¿ãƒƒã‚¯: (NumInputs, Batch, Dim) -> (Batch*NumInputs, Dim) or similar mechanism needed?
        # ã“ã“ã§ã¯å˜ç´”åŒ–ã—ã¦ã€ã™ã¹ã¦ã®å€™è£œã‚’ãƒãƒƒãƒæ–¹å‘ã«çµåˆã—ã¦æ¯”è¼ƒã™ã‚‹ (ç«¶åˆå­¦ç¿’)
        # inputs are (Batch, Dim). Assuming Batch=1 for simplicity in demo.
        stack = torch.cat(candidates, dim=0) # (TotalBatch, Dim)
        
        scores = self.selector(stack).squeeze(-1) # (TotalBatch,)
        
        # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã®ãƒã‚¤ã‚º
        noise = torch.randn_like(scores) * 0.1
        probs = F.softmax(scores + noise, dim=0)

        winner_idx = int(torch.argmax(probs).item())
        winner_name = names[winner_idx]
        winner_content = candidates[winner_idx]

        # çŠ¶æ…‹æ›´æ–° (Exponential Moving Average)
        # winner_content shape: (1, Dim) assuming batch size 1
        if winner_content.shape[0] != self.workspace_state.shape[0]:
             # ãƒãƒƒãƒã‚µã‚¤ã‚ºä¸ä¸€è‡´æ™‚ã®å˜ç´”ãªãƒªã‚µã‚¤ã‚ºã¾ãŸã¯ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ
             if winner_content.shape[0] == 1:
                 winner_content = winner_content.expand_as(self.workspace_state)

        new_state = (1 - self.decay) * winner_content + \
            self.decay * self.workspace_state
        self.workspace_state = new_state.detach()

        return {
            "broadcast": new_state,
            "winner": winner_name,
            "salience": probs.detach()
        }