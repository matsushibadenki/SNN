# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/global_workspace.py
# Title: Global Workspace (Consciousness Stream v2)
# Description:
# - Phase 6.2å¯¾å¿œ: ã‚¯ã‚ªãƒªã‚¢ãƒ™ã‚¯ãƒˆãƒ«ã«ã‚ˆã‚‹æ„è­˜å†…å®¹ã®ä¿æŒã€‚
# - Thalamusã¸ã®ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³æ³¨æ„ä¿¡å·ã®ç”Ÿæˆã€‚

from typing import Dict, Any, List, Callable, Optional, Deque
from collections import deque
import torch
import logging

logger = logging.getLogger(__name__)

class GlobalWorkspace:
    """
    èªçŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ä¸­å¤®æƒ…å ±äº¤æ›ãƒãƒ–ã€‚
    æ„è­˜ã®ã€Œåº§ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã€ã‚¯ã‚ªãƒªã‚¢ã‚’æ”¾é€ã™ã‚‹ã€‚
    """

    def __init__(self, capacity: int = 7, model_registry: Optional[Any] = None, **kwargs):
        self.blackboard: Dict[str, Any] = {}
        self.subscribers: List[Callable[[str, Any], None]] = []
        
        # æ„è­˜ã®å†…å®¹ (Current Conscious Content)
        self.conscious_broadcast_content: Optional[Any] = None
        self.current_qualia_vector: Optional[torch.Tensor] = None
        
        # æ„è­˜ã®æµã‚Œã‚‹å±¥æ­´ (Stream of Consciousness)
        self.stream_of_consciousness: Deque[Dict[str, Any]] = deque(maxlen=capacity)

        self.model_registry = model_registry
        logger.info(f"ğŸ§  Global Workspace initialized (Stream Capacity: {capacity}).")

    def subscribe(self, callback: Callable[[str, Any], None]):
        """æ”¾é€ã®å—ä¿¡ç™»éŒ²ã€‚"""
        self.subscribers.append(callback)

    def upload_to_workspace(self, source: str, data: Any, salience: float):
        """ 
        ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æƒ…å ±ã‚’ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒœãƒˆãƒ ã‚¢ãƒƒãƒ—ï¼‰ã€‚
        """
        self.blackboard[source] = {"data": data, "salience": salience}

    def get_information(self, source: str) -> Any:
        info = self.blackboard.get(source)
        return info['data'] if info else None

    def get_context(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçŠ¶æ…‹ã‚’å–å¾—ã€‚"""
        return {
            "blackboard_snapshot": {k: v.get("data") for k, v in self.blackboard.items()},
            "current_conscious_content": self.conscious_broadcast_content,
            "has_qualia": self.current_qualia_vector is not None
        }

    def conscious_broadcast_cycle(self, qualia_vector: Optional[torch.Tensor] = None):
        """
        æ„è­˜ã®ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚µã‚¤ã‚¯ãƒ« (Ignition)ã€‚
        æœ€ã‚‚é¡•è‘—ãªæƒ…å ±ã‚’é¸æŠã—ã€ã‚¯ã‚ªãƒªã‚¢ã¨ã—ã¦çµ±åˆã—ã¦å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸æ”¾é€ã™ã‚‹ã€‚
        """
        if not self.blackboard and qualia_vector is None:
            return

        # 1. Winner-Take-All: æœ€ã‚‚é‡è¦ãªå…¥åŠ›ã‚’é¸æŠ
        winner_source = "internal"
        winner_content = None
        
        if self.blackboard:
            winner_source = max(self.blackboard.items(), key=lambda x: x[1]["salience"])[0]
            winner_content = self.blackboard[winner_source]["data"]

        # 2. çŠ¶æ…‹æ›´æ–°
        self.conscious_broadcast_content = winner_content
        self.current_qualia_vector = qualia_vector # Synthesizerã‹ã‚‰æ¥ãŸã‚¯ã‚ªãƒªã‚¢
        
        # 3. æ„è­˜ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¸ã®è¨˜éŒ²
        entry = {
            "source": winner_source, 
            "content": winner_content,
            "qualia_phi": qualia_vector.std().item() if qualia_vector is not None else 0.0
        }
        self.stream_of_consciousness.append(entry)

        # 4. ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ (Top-down transmission)
        # å…¨ã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒãƒ¼ï¼ˆå„çš®è³ªé ˜åŸŸï¼‰ã¸ä¿¡å·ã‚’é€ã‚‹
        for callback in self.subscribers:
            callback(winner_source, winner_content)

        # é»’æ¿ã®ã‚¯ãƒªã‚¢ (æ¬¡ã®ç¬é–“ã®ãŸã‚ã«)
        self.blackboard.clear()