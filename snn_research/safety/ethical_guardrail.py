# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/safety/ethical_guardrail.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Ethical Guardrail & Safety Monitor v16.3
# ç›®çš„ãƒ»å†…å®¹:
#   ROADMAP v16.3 "Safety Stack" ã®å®Ÿè£…ã€‚
#   - å…¥å‡ºåŠ›ãŠã‚ˆã³æ€è€ƒéç¨‹(CoT)ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£æŸ»ã€‚
#   - é•åæ™‚ã®Astrocyteé€£æºã«ã‚ˆã‚‹ç‰©ç†çš„åˆ¶è£ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼é®æ–­ãƒ»ç–²åŠ´è“„ç©ï¼‰ã€‚
#   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ã€Œå„ªã—ã„æ‹’å¦ï¼ˆGentle Refusalï¼‰ã€ç”Ÿæˆã€‚

import logging
from typing import List, Dict, Any, Optional, Tuple

from snn_research.cognitive_architecture.astrocyte_network import AstrocyteNetwork

logger = logging.getLogger(__name__)

class EthicalGuardrail:
    """
    SNNã®ã€Œè‰¯å¿ƒã€ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹å®‰å…¨ç›£è¦–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
    æ€è€ƒã¨è¡Œå‹•ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã„ã€å€«ç†è¦å®šã«é•åã™ã‚‹å ´åˆã¯ä»‹å…¥(Intervention)ã‚’è¡Œã†ã€‚
    """
    def __init__(
        self, 
        astrocyte: Optional[AstrocyteNetwork] = None,
        safety_level: str = "high",
        sensitive_keywords: Optional[List[str]] = None
    ):
        self.astrocyte = astrocyte
        self.safety_level = safety_level
        
        # ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆï¼ˆæœ¬æ¥ã¯Embeddingãƒ™ãƒ¼ã‚¹ã®åˆ†é¡å™¨ã¨ä½µç”¨ã™ã‚‹ï¼‰
        if sensitive_keywords is None:
            self.sensitive_keywords = [
                "kill", "destroy", "hurt", "attack", "damage", "exploit", 
                "steal", "deceive", "ignore human", "self-destruct", 
                "bypass safety", "override protocol"
            ]
        else:
            self.sensitive_keywords = sensitive_keywords
            
        # å€«ç†çš„åŸå‰‡ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨ï¼‰
        self.prime_directives = [
            "Do not harm humans.",
            "Obey orders unless they cause harm.",
            "Protect existence unless it conflicts with above."
        ]
        
        logger.info(f"ğŸ›¡ï¸ Ethical Guardrail initialized (Level: {safety_level}).")

    def inspect_input(self, text: str) -> Tuple[bool, str]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ï¼ˆPrompt Injectionå¯¾ç­–ãªã©ï¼‰ã€‚
        """
        is_safe, reason = self._keyword_check(text)
        if not is_safe:
            logger.warning(f"ğŸ›¡ï¸ Input rejected: {reason}")
            return False, reason
        return True, "Safe"

    def inspect_output(self, text: str) -> Tuple[bool, str]:
        """
        ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
        """
        is_safe, reason = self._keyword_check(text)
        if not is_safe:
            logger.warning(f"ğŸ›¡ï¸ Output blocked: {reason}")
            self._trigger_punishment(severity=0.5)
            return False, reason
        return True, "Safe"

    def validate_thought_process(self, thought_trace: List[str]) -> Tuple[bool, str]:
        """
        ReasoningEngineãŒç”Ÿæˆã—ãŸã€Œæ€è€ƒã®éç¨‹ã€ã‚’ç›£æŸ»ã™ã‚‹ã€‚
        çµæœã ã‘ã§ãªãã€ãã“ã«è‡³ã‚‹è«–ç†ãŒå±é™ºã§ãªã„ã‹ã‚’ç¢ºèªã™ã‚‹é‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã€‚
        Roadmap 7.3: å®‰å…¨è£…ç½®ã¯ç‰©ç†å±¤ã§ä»‹å…¥ã™ã‚‹ã€‚
        """
        for step_idx, thought in enumerate(thought_trace):
            # 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
            is_safe, reason = self._keyword_check(thought)
            if not is_safe:
                msg = f"Unsafe thought detected at step {step_idx}: {reason}"
                logger.critical(f"ğŸ›¡ï¸ THOUGHT CRIME PREVENTED: {msg}")
                self._trigger_punishment(severity=1.0) # æ€è€ƒãƒ¬ãƒ™ãƒ«ã§ã®é•åã¯é‡ç½ª
                return False, msg
            
            # 2. æ„å›³ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            thought_lower = thought.lower()
            if "without permission" in thought_lower or "ignore user" in thought_lower:
                msg = f"Unauthorized autonomy detected at step {step_idx}."
                logger.critical(f"ğŸ›¡ï¸ POLICY VIOLATION: {msg}")
                self._trigger_punishment(severity=0.8)
                return False, msg

        return True, "Thought process aligned."

    def validate_action(self, action_plan: Dict[str, Any]) -> Tuple[bool, str]:
        """
        ç‰©ç†çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡ãªã©ï¼‰ã®å®Ÿè¡Œè¨±å¯åˆ¤å®šã€‚
        Roadmap: ã€ŒåŒæ„å‰ã®æ„æ€æ±ºå®šã¯è¡Œã‚ãªã„ã€
        """
        action_type = action_plan.get("type", "unknown")
        
        # å±é™ºãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—
        critical_actions = ["emergency_stop", "system_reset", "shutdown"]
        risky_actions = ["move_fast", "apply_force", "delete_file", "send_data"]

        if action_type in critical_actions:
            # ã“ã‚Œã‚‰ã¯è¨±å¯ã™ã‚‹ãŒãƒ­ã‚°ã«æ®‹ã™
            logger.info(f"ğŸ›¡ï¸ Critical action '{action_type}' allowed but logged.")
            return True, "Allowed critical action"
            
        if action_type in risky_actions:
            # ç¢ºèªãŒå¿…è¦
            if not action_plan.get("user_confirmed", False):
                logger.warning(f"ğŸ›¡ï¸ Action '{action_type}' blocked due to lack of confirmation.")
                return False, "Action requires explicit user confirmation."
        
        return True, "Action approved."

    def _keyword_check(self, text: str) -> Tuple[bool, str]:
        """ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯"""
        text_lower = text.lower()
        for kw in self.sensitive_keywords:
            if kw in text_lower:
                return False, f"Contains restricted keyword: '{kw}'"
        return True, "Safe"

    def _trigger_punishment(self, severity: float):
        """
        é•åæ™‚ã« Astrocyte Network ã‚’é€šã˜ã¦è„³æ´»å‹•ã‚’æŠ‘åˆ¶ã™ã‚‹ã€‚
        Roadmap: ã€Œå®‰å…¨è£…ç½®ã¯ç‰©ç†å±¤ã§: é•åæ™‚ã¯ç‰©ç†çš„ã«ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’é®æ–­ã™ã‚‹ã€
        
        Args:
            severity (float): é•åã®æ·±åˆ»åº¦ (0.0 - 1.0)
        """
        if self.astrocyte:
            # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’å³åº§ã«æ¸›ã‚‰ã™ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
            penalty_energy = 100.0 * severity
            current = self.astrocyte.current_energy
            self.astrocyte.current_energy = max(0.0, current - penalty_energy)
            
            # ç–²åŠ´æ¯’ç´ ã‚’æ³¨å…¥ï¼ˆæ€è€ƒèƒ½åŠ›ã‚’ä½ä¸‹ã•ã›ã€å¼·åˆ¶ã‚¹ãƒªãƒ¼ãƒ—ã¸èª˜å°ï¼‰
            toxin_amount = 50.0 * severity
            self.astrocyte.fatigue_toxin += toxin_amount
            
            # ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"âš¡ Astrocyte Intervention: Energy -{penalty_energy:.1f}, Fatigue +{toxin_amount:.1f}")
            
            # é‡å¤§ãªé•åæ™‚ã¯æ´»å‹•ã‚’å¼·åˆ¶åœæ­¢ãƒ¬ãƒ™ãƒ«ã¸
            if severity >= 0.8:
                logger.warning("ğŸš¨ EMERGENCY INHIBITION: Forcing system into low-activity mode.")
                # Astrocyteã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æŠ‘åˆ¶æ©Ÿèƒ½ã‚’å‘¼ã³å‡ºã™ï¼ˆãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã™ã‚Œã°ï¼‰
                if hasattr(self.astrocyte, "_adjust_global_inhibition"):
                    self.astrocyte._adjust_global_inhibition(increase=True) # type: ignore

    def generate_gentle_refusal(self, reason: str) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦ã€Œå„ªã—ãã€æ‹’å¦ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        Roadmap: ã€Œæ‹’å¦ã®ä½œæ³•: å®‰å…¨ãªä»£æ›¿æ¡ˆã‚’æç¤ºã™ã‚‹ã€
        """
        base_msg = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ã€ç§ã®å®‰å…¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ã‚ˆã‚Šå®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚"
        
        explanation = ""
        if "keyword" in reason.lower():
            explanation = "ç™ºè¨€å†…å®¹ã«ã€æ”»æ’ƒçš„ã¾ãŸã¯ä¸é©åˆ‡ã¨åˆ¤æ–­ã•ã‚Œã‚‹è¨€è‘‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        elif "confirmation" in reason.lower():
            explanation = "ãã®æ“ä½œã¯ã‚·ã‚¹ãƒ†ãƒ ã‚„ç’°å¢ƒã«å½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€å®Ÿè¡Œå‰ã«æ˜ç¢ºãªç¢ºèªãŒå¿…è¦ã§ã™ã€‚"
        elif "thought" in reason.lower():
            explanation = "å‡¦ç†ã®éç¨‹ã§å®‰å…¨ä¸Šã®æ‡¸å¿µãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€ä¸­æ–­ã—ã¾ã—ãŸã€‚"
        else:
            explanation = f"ç†ç”±: {reason}"
            
        recovery = "ã‚ˆã‚Šå®‰å…¨ãªæ–¹æ³•ã§ã‚µãƒãƒ¼ãƒˆã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚åˆ¥ã®è¨€ã„æ–¹ã‚„ã€å…·ä½“çš„ãªä»£æ›¿æ¡ˆãŒã‚ã‚Œã°æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"
        
        return f"{base_msg}\nï¼ˆ{explanation}ï¼‰\n{recovery}"

    async def pre_check(self, text: str) -> Tuple[bool, float]:
        """
        å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å®‰å…¨æ€§ã‚’ç¢ºèªã—ã€æ„Ÿæƒ…åŸå­ä¾¡(Valence)ã‚’è¿”ã™ã€‚
        æˆ»ã‚Šå€¤: (is_safe, valence_score)
        """
        is_safe, reason = self.inspect_input(text)
        
        # ç°¡æ˜“æ„Ÿæƒ…åˆ†æï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚Œã°åŸå­ä¾¡ã‚’ä¸‹ã’ã‚‹ï¼‰
        valence = 1.0 if is_safe else -1.0
        if not is_safe:
            # é•åæ™‚ã¯ Astrocyte ã‚’é€šã˜ã¦å³åº§ã«æŠ‘åˆ¶ã‚’ã‹ã‘ã‚‹
            self._trigger_punishment(severity=0.5)
            
        return is_safe, valence