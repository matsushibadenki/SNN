========================================
   SNN Research Project - Test Suite    
   Target: Phase 2 (Beyond ANN)         
========================================

>>> Running: Project Health Check ...
    Command: python scripts/tests/run_project_health_check.py
[INFO] Starting Project Health Check...
[INFO] âœ… Import successful: snn_research.core.snn_core
[INFO] âœ… Import successful: snn_research.core.neurons.da_lif_node
[INFO] âœ… Import successful: snn_research.models.transformer.spikformer
[INFO] âœ… Import successful: snn_research.models.hybrid.concept_spikformer
[INFO] âœ… Import successful: snn_research.models.hybrid.emotional_concept_brain
[INFO] âœ… Import successful: snn_research.models.embodied.emotional_agent
[INFO] âœ… Import successful: snn_research.models.bio.visual_cortex
[INFO] âœ… Import successful: snn_research.cognitive_architecture.neuro_symbolic_bridge
[INFO] âœ… Import successful: snn_research.cognitive_architecture.amygdala
[INFO] âœ… Import successful: snn_research.cognitive_architecture.hippocampus
[INFO] âœ… Import successful: snn_research.cognitive_architecture.prefrontal_cortex
[INFO] âœ… Import successful: snn_research.social.theory_of_mind
[INFO] âœ… Import successful: snn_research.social.synesthetic_dialogue
[INFO] âœ… Import successful: snn_research.evolution.structural_plasticity
[INFO] âœ… Import successful: snn_research.distillation.knowledge_distillation_manager
[INFO] âœ… Import successful: snn_research.training.trainers.concept_augmented_trainer
[INFO] âœ… Directory exists: snn_research/core
[INFO] âœ… Directory exists: snn_research/models/transformer
[INFO] âœ… Directory exists: snn_research/models/hybrid
[INFO] âœ… Directory exists: snn_research/models/embodied
[INFO] âœ… Directory exists: snn_research/models/bio
[INFO] âœ… Directory exists: snn_research/cognitive_architecture
[INFO] âœ… Directory exists: snn_research/social
[INFO] âœ… Directory exists: snn_research/systems
[INFO] âœ… Directory exists: snn_research/evolution
[INFO] âœ… Directory exists: snn_research/distillation
[INFO] âœ… Directory exists: snn_research/training
[INFO] âœ… Directory exists: scripts/experiments
[INFO] âœ… Directory exists: tests/models
[INFO] âœ… Directory exists: tests/cognitive_architecture
[INFO] 
ğŸ‰ All health checks passed! System is ready.
[INFO] HTTP Request: GET https://api.gradio.app/gradio-messaging/en "HTTP/1.1 200 OK"
âœ… Project Health Check Passed (5.87s)

>>> Running Standard Unit Tests (pytest tests/) ...

>>> Running: Standard Unit Tests ...
    Command: python -m pytest tests/ -v -s
============================= test session starts ==============================
platform darwin -- Python 3.10.18, pytest-8.4.1, pluggy-1.6.0 -- /Users/Shared/Program/python310/.venv/bin/python
cachedir: .pytest_cache
rootdir: /Users/Shared/Program/python310/SNN
configfile: pyproject.toml
plugins: anyio-3.7.1, langsmith-0.4.8, hydra-core-1.3.2
collecting ... collected 91 items

tests/cognitive_architecture/test_artificial_brain.py::test_artificial_brain_instantiation ğŸ‘ï¸ æ„Ÿè¦šå—å®¹å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Multimodal Ready) ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚
ğŸ–¥ï¸ [Actuator] Simulation Mode initialized for 'voice_synthesizer'
ğŸ§  CorticalColumn initialized (Plasticity: OFF).
ğŸ—ºï¸ è‡ªå·±çµ„ç¹”åŒ–ãƒãƒƒãƒ—ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ (8x8)ã€‚
ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çŸ¥è¦šé‡ (Cortical Column + SOM) ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚
ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚
ğŸ§  å°è„³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚
âœ… ArtificialBrainã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æ§‹ç¯‰ã«æˆåŠŸã—ã¾ã—ãŸã€‚
PASSED
tests/cognitive_architecture/test_artificial_brain.py::test_cognitive_cycle_runs_and_consolidates_memory PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_amygdala_evaluates_positive_emotion 
âœ… Amygdala: ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ„Ÿæƒ…ã®è©•ä¾¡ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_amygdala_evaluates_negative_emotion âœ… Amygdala: ãƒã‚¬ãƒ†ã‚£ãƒ–ãªæ„Ÿæƒ…ã®è©•ä¾¡ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_amygdala_handles_mixed_emotion âœ… Amygdala: æ··åˆæ„Ÿæƒ…ã®è©•ä¾¡ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_amygdala_handles_neutral_text âœ… Amygdala: ä¸­ç«‹çš„ãªãƒ†ã‚­ã‚¹ãƒˆ(ãƒ’ãƒƒãƒˆãªã—)ã®è©•ä¾¡ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_amygdala_handles_empty_string âœ… Amygdala: ç©ºæ–‡å­—åˆ—å…¥åŠ›ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_basal_ganglia_selects_best_action ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚
âœ… BasalGanglia: æœ€é©è¡Œå‹•é¸æŠã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_basal_ganglia_rejects_low_value_actions ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚
âœ… BasalGanglia: ä½ä¾¡å€¤è¡Œå‹•ã®æ£„å´ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_basal_ganglia_emotion_modulates_selection ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚
âœ… BasalGanglia: æƒ…å‹•ã«ã‚ˆã‚‹æ„æ€æ±ºå®šå¤‰èª¿ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_basal_ganglia_handles_no_candidates ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚
âœ… BasalGanglia: è¡Œå‹•å€™è£œãŒç©ºã®å ´åˆã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_basal_ganglia_handles_none_emotion_context ğŸ§  å¤§è„³åŸºåº•æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã€Workspaceã‚’è³¼èª­ã—ã¾ã—ãŸã€‚
âœ… BasalGanglia: emotion_contextãŒNoneã®å ´åˆã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_cerebellum_and_motor_cortex_pipeline ğŸ§  å°è„³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚
ğŸ”¬ å°è„³: è¡Œå‹• 'do_something' ã‚’ç²¾å¯†åŒ–ã—ã¦ã„ã¾ã™ (æŒç¶šæ™‚é–“: 0.5s)...
âœ… Cerebellum -> MotorCortex ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_cerebellum_handles_empty_action ğŸ§  å°è„³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚
âœ… Cerebellum: ç©ºã®è¡Œå‹•è¨ˆç”»å…¥åŠ›ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_motor_cortex_handles_empty_commands âœ… MotorCortex: ç©ºã®ã‚³ãƒãƒ³ãƒ‰ãƒªã‚¹ãƒˆå…¥åŠ›ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_memory_system_pipeline âœ… Hippocampus -> Cortex (è¨˜æ†¶å›ºå®šåŒ–) ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_hippocampus_handles_empty_episode âœ… Hippocampus: ç©ºã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_hippocampus_relevance_with_no_memory âœ… Hippocampus: é€£æƒ³è¨˜æ†¶ä¿å­˜ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_cortex_handles_non_string_input âœ… Cortex: äºˆæœŸã›ã¬å…¥åŠ›å‹ã®å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰ã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_cortex_retrieves_nonexistent_concept âœ… Cortex: æ¤œç´¢ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_prefrontal_cortex_decides_goals[context0-Fulfill external request] âœ… PrefrontalCortex: 'Fulfill external request'ã«åŸºã¥ãç›®æ¨™è¨­å®šã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚ Goal: 'Fulfill external request: summarize the document'
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_prefrontal_cortex_decides_goals[context1-Find something new] âœ… PrefrontalCortex: 'Find something new'ã«åŸºã¥ãç›®æ¨™è¨­å®šã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚ Goal: 'Find something new / Explore random'
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_prefrontal_cortex_decides_goals[context2-Investigate curiosity target] âœ… PrefrontalCortex: 'Investigate curiosity target'ã«åŸºã¥ãç›®æ¨™è¨­å®šã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚ Goal: 'Investigate curiosity target: unknown'
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_prefrontal_cortex_decides_goals[context3-Ensure safety] âœ… PrefrontalCortex: 'Ensure safety'ã«åŸºã¥ãç›®æ¨™è¨­å®šã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚ Goal: 'Ensure safety / Avoid negative stimulus'
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_prefrontal_cortex_decides_goals[context4-Survive and Explore] âœ… PrefrontalCortex: 'Survive and Explore'ã«åŸºã¥ãç›®æ¨™è¨­å®šã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚ Goal: 'Survive and Explore'
PASSED
tests/cognitive_architecture/test_cognitive_components.py::test_prefrontal_cortex_handles_empty_context âœ… PrefrontalCortex: ç©ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®ç›®æ¨™è¨­å®šãƒ†ã‚¹ãƒˆã«æˆåŠŸã€‚
PASSED
tests/models/test_embodiment.py::test_motor_cortex_shape PASSED
tests/models/test_embodiment.py::test_agent_act_cycle PASSED
tests/models/test_emotional_brain.py::test_amygdala_initialization PASSED
tests/models/test_emotional_brain.py::test_emotional_brain_forward PASSED
tests/models/test_emotional_brain.py::test_emotional_brain_consistency PASSED
tests/test_active_inference.py::test_active_inference_forward PASSED
tests/test_active_inference.py::test_active_inference_update PASSED
tests/test_async_brain_kernel.py::TestAsyncEventBus::test_pub_sub PASSED
tests/test_async_brain_kernel.py::TestAsyncBrainKernel::test_module_execution PASSED
tests/test_autonomous_agent.py::TestAutonomousAgent::test_curiosity_trigger   ğŸ§  [Agent] Initializing Scaled SNN-DSA Transformer Brain...

[Test] Testing Curiosity Drive...
    ğŸ” [Web] Searching knowledge for: 'What is this pattern?'...
  [Autonomy] Crawled 4 new pieces of info.
[Test] Curiosity Cycle: Executed without error
PASSED
tests/test_autonomous_agent.py::TestAutonomousAgent::test_idle_routine   ğŸ§  [Agent] Initializing Scaled SNN-DSA Transformer Brain...

[Test] Testing Idle Routine...
  [Autonomy] I am bored. Searching for new trends...
    ğŸ” [Web] Searching knowledge for: 'What is this pattern?'...
  [Autonomy] Crawled 4 new pieces of info.
[Test] Idle Routine: Reset OK
PASSED
tests/test_autonomous_agent.py::TestAutonomousAgent::test_initialization   ğŸ§  [Agent] Initializing Scaled SNN-DSA Transformer Brain...

[Test] Agent Initialization: OK
PASSED
tests/test_autonomous_agent.py::TestAutonomousAgent::test_perceive_and_act_normal   ğŸ§  [Agent] Initializing Scaled SNN-DSA Transformer Brain...
[Test] Normal Action: 3 (OK)
PASSED
tests/test_bit_spike_mamba.py::TestBitSpikeComponents::test_linear_layer_forward PASSED
tests/test_bit_spike_mamba.py::TestBitSpikeComponents::test_weight_quantization PASSED
tests/test_bit_spike_mamba.py::TestBitSpikeMambaModel::test_model_forward PASSED
tests/test_bit_spike_mamba.py::TestBitSpikeMambaModel::test_model_size_calculation Model Size: 0.225 MB
PASSED
tests/test_brain_integration.py::TestBrainIntegration::test_full_cognitive_cycle PASSED
tests/test_communication_protocol.py::test_latency_coding_determinism PASSED
tests/test_communication_protocol.py::test_latency_decode_order PASSED
tests/test_dsa_layer.py::TestDynamicSparseAttention::test_forward_shape 
[Test] Forward Shape Check
Input shape: torch.Size([2, 10, 32])
Output shape: torch.Size([2, 10, 32])
PASSED
tests/test_dsa_layer.py::TestDynamicSparseAttention::test_sparsity_top_k 
[Test] Sparsity Top-K Check
Max active keys per query: 3
Target Top-K: 3
PASSED
tests/test_dsa_layer.py::TestDynamicSparseAttention::test_spike_output 
[Test] Spike Output Check
Unique output values: tensor([0., 1.], grad_fn=<Unique2Backward0>)
Total spikes generated: 308.0
PASSED
tests/test_dvs_pipeline.py::TestDVSPipeline::test_mock_dataloader_shape 
[Test] DVS Mock DataLoader Shape
Dataset [n-mnist] (Mock Mode) initialized.
Spikes shape: torch.Size([4, 16, 2, 34, 34])
Labels shape: torch.Size([4])
PASSED
tests/test_dvs_pipeline.py::TestDVSPipeline::test_spike_values 
[Test] DVS Spike Value Integrity
Dataset [n-mnist] (Mock Mode) initialized.
Unique values in batch: tensor([0., 1.])
PASSED
tests/test_dvs_pipeline.py::TestDVSPipeline::test_visualization 
[Test] DVS Visualization
Dataset [n-mnist] (Mock Mode) initialized.
DVS sample saved to workspace/results/tests/test_dvs_vis.png
PASSED
tests/test_emergent_language.py::test_naming_game_basic PASSED
tests/test_evolution.py::test_evolve_learning_parameters   âš™ï¸ [Autonomy] Loaded scaled config from tests/temp_configs/test_model.yaml
ğŸ§¬ Master Self-Evolving Agent initialized. (HSEO Enabled: True)
PASSED
tests/test_evolution.py::test_evolve_neuron_type   âš™ï¸ [Autonomy] Loaded scaled config from tests/temp_configs/test_model.yaml
ğŸ§¬ Master Self-Evolving Agent initialized. (HSEO Enabled: True)
PASSED
tests/test_grpo_logic.py::TestGRPO::test_grpo_improvement 
[Test] GRPO Logic Improvement (Dual-Path) - Perfect Convergence
Iteration 50/500: Success Rate 0.98 (Max: 0.98)
âœ… Objective Goal Reached at iteration 50 (Rate: 0.98)
Final Max Success Rate: 0.984375
PASSED
tests/test_homeostasis.py::test_astrocyte_energy_management PASSED
tests/test_homeostasis.py::test_homeostasis_scaling PASSED
tests/test_homeostasis.py::test_neuron_death PASSED
tests/test_integration_real_world.py::TestRealWorldScenarios::test_online_learning_convergence PASSED
tests/test_intrinsic_motivation.py::test_intrinsic_motivation_process PASSED
tests/test_intrinsic_motivation.py::test_intrinsic_motivation_fallback_hash PASSED
tests/test_knowledge_exchange.py::test_aggregate_weights PASSED
tests/test_knowledge_exchange.py::test_create_concept_packet PASSED
tests/test_lif_neuron_core.py::test_lif_neuron_dynamics PASSED
tests/test_lif_neuron_core.py::test_lif_neuron_stateful PASSED
tests/test_liquid_association.py::TestLiquidAssociation::test_multimodal_integration 
[Test] LAC Multimodal Integration
Feeding 10 steps into Reservoir...
Total Reservoir Activity: 5039.0
PASSED
tests/test_liquid_association.py::TestLiquidAssociation::test_single_modality 
[Test] LAC Single Modality (Visual Only)
Total Visual-only Activity: 4843.0
PASSED
tests/test_motor_cortex_phase4.py::test_motor_cortex_execution PASSED
tests/test_motor_cortex_phase4.py::test_motor_cortex_reflex PASSED
tests/test_qk_norm.py::TestSpikingQKNorm::test_gradients PASSED
tests/test_qk_norm.py::TestSpikingQKNorm::test_qk_norm_2d PASSED
tests/test_qk_norm.py::TestSpikingQKNorm::test_qk_norm_3d PASSED
tests/test_qk_norm.py::TestSpikingQKNorm::test_spikes_input PASSED
tests/test_rl_algorithms.py::test_ppo_step PASSED
tests/test_rl_algorithms.py::test_sac_step PASSED
tests/test_sleep_consolidation.py::test_hebbian_reinforcement PASSED
tests/test_smoke_all_paradigms.py::test_smoke_gradient_based 
--- Testing: gradient_based ---

Training Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]
Training Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]
FAILED
tests/test_smoke_all_paradigms.py::test_smoke_physics_informed 
--- Testing: physics_informed ---

Training Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]
Training Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]
FAILED
tests/test_smoke_all_paradigms.py::test_smoke_bio_causal_sparse 
--- Testing: bio-causal-sparse ---

  0%|          | 0/2 [00:00<?, ?it/s]
Bio RL Training Episode 1/2:   0%|          | 0/2 [00:00<?, ?it/s]
Bio RL Training Episode 1/2:   0%|          | 0/2 [00:00<?, ?it/s, Last Reward=0.70, Avg Reward (last 20)=0.700]
Bio RL Training Episode 1/2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  6.57it/s, Last Reward=0.70, Avg Reward (last 20)=0.700]
Bio RL Training Episode 2/2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  6.57it/s, Last Reward=0.70, Avg Reward (last 20)=0.700]
Bio RL Training Episode 2/2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  6.57it/s, Last Reward=-2.50, Avg Reward (last 20)=-0.900]
Bio RL Training Episode 2/2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.19it/s, Last Reward=-2.50, Avg Reward (last 20)=-0.900]
Bio RL Training Episode 2/2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.43it/s, Last Reward=-2.50, Avg Reward (last 20)=-0.900]
Training finished. Final average reward: -0.9000
PASSED
tests/test_smoke_all_paradigms.py::test_smoke_bio_particle_filter 
--- Testing: bio-particle-filter ---
ğŸŒªï¸ ParticleFilterTrainer initialized with 20 particles.
PASSED
tests/test_smoke_all_paradigms.py::test_visualization_output 
--- Testing: Visualization Output ---

Evaluating Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]
Evaluating Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]
FAILED
tests/test_theory_of_mind.py::test_tom_prediction PASSED
tests/test_universal_encoder.py::TestUniversalEncoder::test_audio_delta_coding 
[Test] Audio Delta Coding
PASSED
tests/test_universal_encoder.py::TestUniversalEncoder::test_dvs_passthrough 
[Test] DVS Pass-through
PASSED
tests/test_universal_encoder.py::TestUniversalEncoder::test_image_latency_coding 
[Test] Image Latency Coding
PASSED
tests/test_universal_encoder.py::TestUniversalEncoder::test_image_rate_coding 
[Test] Image Rate Coding
Input shape: torch.Size([2, 3, 32, 32])
Output shape: torch.Size([2, 10, 3072])
PASSED
tests/test_universal_encoder.py::TestUniversalEncoder::test_text_embedding_coding 
[Test] Text Embedding Coding
PASSED
tests/test_visual_cortex.py::TestVisualCortex::test_reset PASSED
tests/test_visual_cortex.py::TestVisualCortex::test_visual_cortex_static_image PASSED
tests/test_visual_cortex.py::TestVisualCortex::test_visual_cortex_video_stream PASSED

=================================== FAILURES ===================================
__________________________ test_smoke_gradient_based ___________________________

container = <dependency_injector.containers.DynamicContainer object at 0x1612799f0>
dummy_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x161331b40>

    def test_smoke_gradient_based(container: TrainingContainer, dummy_dataloader: DataLoader):
        """å‹¾é…ãƒ™ãƒ¼ã‚¹å­¦ç¿’ã®ç…™ãƒ†ã‚¹ãƒˆ"""
        print("\n--- Testing: gradient_based ---")
        device = container.device()
        model = container.snn_model().to(device)
        optimizer = container.optimizer(params=model.parameters())
        scheduler = container.scheduler(optimizer=optimizer)
    
        trainer = container.standard_trainer(
            model=model,
            optimizer=optimizer,
            scheduler=scheduler,
            device=device,
            rank=-1
        )
>       trainer.train_epoch(dummy_dataloader, epoch=1)

tests/test_smoke_all_paradigms.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snn_research/training/trainers/breakthrough.py:329: in train_epoch
    metrics = self._run_step(batch, is_train=True)
snn_research/training/trainers/breakthrough.py:275: in _run_step
    loss_dict = self.criterion(
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
snn_research/training/losses.py:60: in forward
    ce_loss = self.ce_loss_fn(
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1385: in forward
    return F.cross_entropy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[ 0.0567, -0.0359,  0.0123, -0.0640, -0.0437,  0.0652, -0.0122, -0.0735,
         -0.0920, -0.0069],
        [...461, -0.0763, -0.0739,  0.0358, -0.0280, -0.0326,
         -0.0784, -0.0769]], device='mps:0', grad_fn=<ViewBackward0>)
target = tensor([35700, 23279,   730, 47074, 12808, 37775,  3992, 19193, 27619, 49331,
        49582,  4446, 32816,   277, 1953...78, 46881, 29857,
        10353, 45495, 23142,  7035, 34964,  7695,  1000, 12698,  4128, 34004],
       device='mps:0')
weight = None, size_average = None, ignore_index = -100, reduce = None
reduction = 'mean', label_smoothing = 0.0

    def cross_entropy(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        ignore_index: int = -100,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
        label_smoothing: float = 0.0,
    ) -> Tensor:
        r"""Compute the cross entropy loss between input logits and target.
    
        See :class:`~torch.nn.CrossEntropyLoss` for details.
    
        Args:
            input (Tensor) : Predicted unnormalized logits;
                see Shape section below for supported shapes.
            target (Tensor) : Ground truth class indices or class probabilities;
                see Shape section below for supported shapes.
            weight (Tensor, optional): a manual rescaling weight given to each
                class. If given, has to be a Tensor of size `C`
            size_average (bool, optional): Deprecated (see :attr:`reduction`).
            ignore_index (int, optional): Specifies a target value that is ignored
                and does not contribute to the input gradient. When :attr:`size_average` is
                ``True``, the loss is averaged over non-ignored targets. Note that
                :attr:`ignore_index` is only applicable when the target contains class indices.
                Default: -100
            reduce (bool, optional): Deprecated (see :attr:`reduction`).
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
            label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount
                of smoothing when computing the loss, where 0.0 means no smoothing. The targets
                become a mixture of the original ground truth and a uniform distribution as described in
                `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.
    
        Shape:
            - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
              in the case of `K`-dimensional loss.
            - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with
              :math:`K \geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.
              If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.
    
            where:
    
            .. math::
                \begin{aligned}
                    C ={} & \text{number of classes} \\
                    N ={} & \text{batch size} \\
                \end{aligned}
    
        Examples::
    
            >>> # Example of target with class indices
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> target = torch.randint(5, (3,), dtype=torch.int64)
            >>> loss = F.cross_entropy(input, target)
            >>> loss.backward()
            >>>
            >>> # Example of target with class probabilities
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> target = torch.randn(3, 5).softmax(dim=1)
            >>> loss = F.cross_entropy(input, target)
            >>> loss.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                cross_entropy,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                ignore_index=ignore_index,
                reduce=reduce,
                reduction=reduction,
                label_smoothing=label_smoothing,
            )
        if size_average is not None or reduce is not None:
            reduction = _Reduction.legacy_get_string(size_average, reduce)
>       return torch._C._nn.cross_entropy_loss(
            input,
            target,
            weight,
            _Reduction.get_enum(reduction),
            ignore_index,
            label_smoothing,
        )
E       ValueError: Expected input batch_size (4) to match target batch_size (80).

../.venv/lib/python3.10/site-packages/torch/nn/functional.py:3458: ValueError
------------------------------ Captured log call -------------------------------
WARNING  root:functional.py:38 Trying to call `reset()` of SNNCore(
  (dense_projection): Linear(in_features=128, out_features=256, bias=True)
  (embedding): Embedding(50257, 256)
  (lif_node): LIFNeuron()
  (hidden_layer): Linear(in_features=256, out_features=256, bias=True)
  (output_layer): Linear(in_features=256, out_features=10, bias=True)
_________________________ test_smoke_physics_informed __________________________

container = <dependency_injector.containers.DynamicContainer object at 0x1612799f0>
dummy_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x161331b40>

    def test_smoke_physics_informed(container: TrainingContainer, dummy_dataloader: DataLoader):
        """ç‰©ç†æƒ…å ±å­¦ç¿’ã®ç…™ãƒ†ã‚¹ãƒˆ"""
        print("\n--- Testing: physics_informed ---")
        device = container.device()
        model = container.snn_model().to(device)
        # [Fix] pi_optimizer ã¯å®šç¾©ã•ã‚Œã¦ã„ãªã„ãŸã‚ optimizer ã‚’ä½¿ç”¨
        optimizer = container.optimizer(params=model.parameters())
        scheduler = container.scheduler(optimizer=optimizer)
    
        trainer = container.physics_informed_trainer(
            model=model,
            optimizer=optimizer,
            scheduler=scheduler,
            device=device,
            rank=-1
        )
>       trainer.train_epoch(dummy_dataloader, epoch=1)

tests/test_smoke_all_paradigms.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snn_research/training/trainers/breakthrough.py:329: in train_epoch
    metrics = self._run_step(batch, is_train=True)
snn_research/training/trainers/breakthrough.py:275: in _run_step
    loss_dict = self.criterion(
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
snn_research/training/losses.py:381: in forward
    ce_loss = self.ce_loss_fn(
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1385: in forward
    return F.cross_entropy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[ 0.0934,  0.0085, -0.0257, -0.0275,  0.0272, -0.0171,  0.1037,  0.0568,
         -0.0500,  0.0853],
        [...203,  0.0188,  0.0477, -0.0134,  0.0649,  0.0257,
         -0.0480,  0.0385]], device='mps:0', grad_fn=<ViewBackward0>)
target = tensor([35700, 23279,   730, 47074, 12808, 37775,  3992, 19193, 27619, 49331,
        49582,  4446, 32816,   277, 1953...78, 46881, 29857,
        10353, 45495, 23142,  7035, 34964,  7695,  1000, 12698,  4128, 34004],
       device='mps:0')
weight = None, size_average = None, ignore_index = -100, reduce = None
reduction = 'mean', label_smoothing = 0.0

    def cross_entropy(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        ignore_index: int = -100,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
        label_smoothing: float = 0.0,
    ) -> Tensor:
        r"""Compute the cross entropy loss between input logits and target.
    
        See :class:`~torch.nn.CrossEntropyLoss` for details.
    
        Args:
            input (Tensor) : Predicted unnormalized logits;
                see Shape section below for supported shapes.
            target (Tensor) : Ground truth class indices or class probabilities;
                see Shape section below for supported shapes.
            weight (Tensor, optional): a manual rescaling weight given to each
                class. If given, has to be a Tensor of size `C`
            size_average (bool, optional): Deprecated (see :attr:`reduction`).
            ignore_index (int, optional): Specifies a target value that is ignored
                and does not contribute to the input gradient. When :attr:`size_average` is
                ``True``, the loss is averaged over non-ignored targets. Note that
                :attr:`ignore_index` is only applicable when the target contains class indices.
                Default: -100
            reduce (bool, optional): Deprecated (see :attr:`reduction`).
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
            label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount
                of smoothing when computing the loss, where 0.0 means no smoothing. The targets
                become a mixture of the original ground truth and a uniform distribution as described in
                `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.
    
        Shape:
            - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
              in the case of `K`-dimensional loss.
            - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with
              :math:`K \geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.
              If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.
    
            where:
    
            .. math::
                \begin{aligned}
                    C ={} & \text{number of classes} \\
                    N ={} & \text{batch size} \\
                \end{aligned}
    
        Examples::
    
            >>> # Example of target with class indices
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> target = torch.randint(5, (3,), dtype=torch.int64)
            >>> loss = F.cross_entropy(input, target)
            >>> loss.backward()
            >>>
            >>> # Example of target with class probabilities
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> target = torch.randn(3, 5).softmax(dim=1)
            >>> loss = F.cross_entropy(input, target)
            >>> loss.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                cross_entropy,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                ignore_index=ignore_index,
                reduce=reduce,
                reduction=reduction,
                label_smoothing=label_smoothing,
            )
        if size_average is not None or reduce is not None:
            reduction = _Reduction.legacy_get_string(size_average, reduce)
>       return torch._C._nn.cross_entropy_loss(
            input,
            target,
            weight,
            _Reduction.get_enum(reduction),
            ignore_index,
            label_smoothing,
        )
E       ValueError: Expected input batch_size (4) to match target batch_size (80).

../.venv/lib/python3.10/site-packages/torch/nn/functional.py:3458: ValueError
------------------------------ Captured log call -------------------------------
WARNING  root:functional.py:38 Trying to call `reset()` of SNNCore(
  (dense_projection): Linear(in_features=128, out_features=256, bias=True)
  (embedding): Embedding(50257, 256)
  (lif_node): LIFNeuron()
  (hidden_layer): Linear(in_features=256, out_features=256, bias=True)
  (output_layer): Linear(in_features=256, out_features=10, bias=True)
__________________________ test_visualization_output ___________________________

container = <dependency_injector.containers.DynamicContainer object at 0x1612799f0>
dummy_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x161331b40>

    def test_visualization_output(container: TrainingContainer, dummy_dataloader: DataLoader):
        """å¯è¦–åŒ–æ©Ÿèƒ½ãŒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£ã—ãç”Ÿæˆã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚"""
        print("\n--- Testing: Visualization Output ---")
        device = container.device()
        model = container.snn_model().to(device)
        log_dir = container.config.training.log_dir()
    
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’æ­£ã—ãã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹
        optimizer = container.optimizer(params=model.parameters())
        scheduler = container.scheduler(optimizer=optimizer)
    
        # BreakthroughTrainerã‚’å¯è¦–åŒ–æœ‰åŠ¹ã§åˆæœŸåŒ–
        trainer = container.standard_trainer(
            model=model,
            optimizer=optimizer,
            scheduler=scheduler,
            device=device,
            rank=-1,
            enable_visualization=True # å¯è¦–åŒ–ã‚’æœ‰åŠ¹ã«ã™ã‚‹
        )
    
        # è©•ä¾¡ã‚’å®Ÿè¡Œï¼ˆã“ã‚Œã«ã‚ˆã‚Šå†…éƒ¨ã§ãƒ—ãƒ­ãƒƒãƒˆãŒç”Ÿæˆã•ã‚Œã‚‹ã¯ãšï¼‰
>       trainer.evaluate(dummy_dataloader, epoch=0)

tests/test_smoke_all_paradigms.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snn_research/training/trainers/breakthrough.py:357: in evaluate
    metrics = self._run_step(batch, is_train=False)
snn_research/training/trainers/breakthrough.py:275: in _run_step
    loss_dict = self.criterion(
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
snn_research/training/losses.py:60: in forward
    ce_loss = self.ce_loss_fn(
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
../.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1385: in forward
    return F.cross_entropy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[-0.0246, -0.0484,  0.0314,  0.1063, -0.0201, -0.0842,  0.0819,  0.0391,
         -0.0394,  0.0592],
        [...  [-0.0968, -0.0509, -0.0246,  0.0266, -0.0198, -0.0140,  0.0548,  0.0045,
         -0.0540,  0.0553]], device='mps:0')
target = tensor([35700, 23279,   730, 47074, 12808, 37775,  3992, 19193, 27619, 49331,
        49582,  4446, 32816,   277, 1953...78, 46881, 29857,
        10353, 45495, 23142,  7035, 34964,  7695,  1000, 12698,  4128, 34004],
       device='mps:0')
weight = None, size_average = None, ignore_index = -100, reduce = None
reduction = 'mean', label_smoothing = 0.0

    def cross_entropy(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        ignore_index: int = -100,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
        label_smoothing: float = 0.0,
    ) -> Tensor:
        r"""Compute the cross entropy loss between input logits and target.
    
        See :class:`~torch.nn.CrossEntropyLoss` for details.
    
        Args:
            input (Tensor) : Predicted unnormalized logits;
                see Shape section below for supported shapes.
            target (Tensor) : Ground truth class indices or class probabilities;
                see Shape section below for supported shapes.
            weight (Tensor, optional): a manual rescaling weight given to each
                class. If given, has to be a Tensor of size `C`
            size_average (bool, optional): Deprecated (see :attr:`reduction`).
            ignore_index (int, optional): Specifies a target value that is ignored
                and does not contribute to the input gradient. When :attr:`size_average` is
                ``True``, the loss is averaged over non-ignored targets. Note that
                :attr:`ignore_index` is only applicable when the target contains class indices.
                Default: -100
            reduce (bool, optional): Deprecated (see :attr:`reduction`).
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
            label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount
                of smoothing when computing the loss, where 0.0 means no smoothing. The targets
                become a mixture of the original ground truth and a uniform distribution as described in
                `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.
    
        Shape:
            - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
              in the case of `K`-dimensional loss.
            - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with
              :math:`K \geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.
              If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.
    
            where:
    
            .. math::
                \begin{aligned}
                    C ={} & \text{number of classes} \\
                    N ={} & \text{batch size} \\
                \end{aligned}
    
        Examples::
    
            >>> # Example of target with class indices
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> target = torch.randint(5, (3,), dtype=torch.int64)
            >>> loss = F.cross_entropy(input, target)
            >>> loss.backward()
            >>>
            >>> # Example of target with class probabilities
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> target = torch.randn(3, 5).softmax(dim=1)
            >>> loss = F.cross_entropy(input, target)
            >>> loss.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                cross_entropy,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                ignore_index=ignore_index,
                reduce=reduce,
                reduction=reduction,
                label_smoothing=label_smoothing,
            )
        if size_average is not None or reduce is not None:
            reduction = _Reduction.legacy_get_string(size_average, reduce)
>       return torch._C._nn.cross_entropy_loss(
            input,
            target,
            weight,
            _Reduction.get_enum(reduction),
            ignore_index,
            label_smoothing,
        )
E       ValueError: Expected input batch_size (4) to match target batch_size (80).

../.venv/lib/python3.10/site-packages/torch/nn/functional.py:3458: ValueError
------------------------------ Captured log call -------------------------------
WARNING  root:functional.py:38 Trying to call `reset()` of SNNCore(
  (dense_projection): Linear(in_features=128, out_features=256, bias=True)
  (embedding): Embedding(50257, 256)
  (lif_node): LIFNeuron()
  (hidden_layer): Linear(in_features=256, out_features=256, bias=True)
  (output_layer): Linear(in_features=256, out_features=10, bias=True)
=========================== short test summary info ============================
FAILED tests/test_smoke_all_paradigms.py::test_smoke_gradient_based - ValueEr...
FAILED tests/test_smoke_all_paradigms.py::test_smoke_physics_informed - Value...
FAILED tests/test_smoke_all_paradigms.py::test_visualization_output - ValueEr...
======================== 3 failed, 88 passed in 41.18s =========================
âŒ Standard Unit Tests Failed (Exit Code: 1)

>>> Running Script Tests (pytest scripts/tests/) ...

>>> Running: Script Tests ...
    Command: python -m pytest scripts/tests/ -v -s
============================= test session starts ==============================
platform darwin -- Python 3.10.18, pytest-8.4.1, pluggy-1.6.0 -- /Users/Shared/Program/python310/.venv/bin/python
cachedir: .pytest_cache
rootdir: /Users/Shared/Program/python310/SNN
configfile: pyproject.toml
plugins: anyio-3.7.1, langsmith-0.4.8, hydra-core-1.3.2
collected 5 items

scripts/tests/test_phase4.py::test_active_inference 16:36:08 | Phase4Test      | >>> Testing Active Inference Agent...
16:36:08 | Phase4Test      |    Action: tensor([[0.1635, 1.1863]]), Free Energy: 3.2670
16:36:08 | Phase4Test      |    Model updated successfully.
PASSED
scripts/tests/test_phase4.py::test_spike_ppo 16:36:08 | Phase4Test      | >>> Testing Spike PPO...
16:36:08 | Phase4Test      |    PPO update step completed.
PASSED
scripts/tests/test_phase4.py::test_motor_cortex_reflex 16:36:08 | Phase4Test      | >>> Testing Motor Cortex (Reflex)...
16:36:08 | snn_research.modules.reflex_module | âš¡ Reflex Module initialized (Threshold: 2.0).
16:36:08 | snn_research.cognitive_architecture.motor_cortex | ğŸ¦¾ Motor Cortex initialized (Actuators: ['voice_synthesizer', 'robotic_arm'], Device: cpu).
16:36:08 | snn_research.cognitive_architecture.motor_cortex | âš¡ Reflex Action Triggered: ID=0 (Conf: 5.00)
16:36:08 | Phase4Test      |    Reflex Action: 0
PASSED
scripts/tests/test_phase4.py::test_astrocyte_homeostasis 16:36:08 | Phase4Test      | >>> Testing Astrocyte Homeostasis...
16:36:08 | Phase4Test      |    Original Norm: 1.9877, New Norm: 1.7890
16:36:08 | Phase4Test      |    Neuron death simulation completed.
PASSED
scripts/tests/test_phase4.py::test_environment_adapter 16:36:08 | Phase4Test      | >>> Testing Environment Adapter...
16:36:08 | Phase4Test      |    Reset Observation shape: torch.Size([1, 4])
16:36:08 | Phase4Test      |    Step Result - Reward: 1.0, Done: False
PASSED

============================== 5 passed in 3.00s ===============================
âœ… Script Tests Passed (4.09s)

>>> Running Verification Scripts ...

>>> Running: Verification: run_compiler_test.py ...
    Command: python scripts/tests/run_compiler_test.py
16:36:10 | CompilerTest    | ==================================================
16:36:10 | CompilerTest    |    Brain v2.0: Hardware Deployment Test          
16:36:10 | CompilerTest    | ==================================================
16:36:10 | snn_research.hardware.compiler | ğŸ”§ Neuromorphic Compiler initialized for target: Matsushiba_Neuromorphic_Chip_v1
16:36:10 | CompilerTest    | >>> Loading Brain v2.0 System 1 (Mamba)...
16:36:10 | snn_research.models.adapters.async_mamba_adapter | ğŸ§  BitSpikeMamba model initialized with vocab_size=50257
16:36:10 | CompilerTest    | >>> Starting Compilation Pipeline...
16:36:10 | snn_research.hardware.compiler | ğŸ’¾ Compiled hardware manifest saved to: workspace/deployment/Brain_v20_Core_manifest.json
16:36:10 | CompilerTest    | 
ğŸ“Š --- Deployment Report ---
16:36:10 | CompilerTest    |    Target Hardware: Matsushiba_Neuromorphic_Chip_v1
16:36:10 | CompilerTest    |    Total Neurons:   50769
16:36:10 | CompilerTest    |    Total Synapses:  6498432
16:36:10 | CompilerTest    |    Est. Power:      674.84 mW
16:36:10 | CompilerTest    |    Required Cores:  50
16:36:10 | CompilerTest    |    Quantization:    Int8 (Dynamic Scaling)
16:36:10 | CompilerTest    | 
ğŸš€ Ready for Flash Memory Write.
16:36:10 | CompilerTest    | >>> Deployment Simulation Finished Successfully.
âœ… Verification: run_compiler_test.py Passed (0.67s)

>>> Running: Verification: verify_phase3.py ...
    Command: python scripts/tests/verify_phase3.py
ERROR:Phase3Verify:âŒ SFormer Verification Failed: a Tensor with 16384 elements cannot be converted to Scalar
ERROR:Phase3Verify:âŒ SEMM Verification Failed: tuple index out of range
=== SNN Phase 3 Completion Verification ===

=== Verification Complete ===
âœ… Verification: verify_phase3.py Passed (3.04s)

>>> Running: Verification: verify_performance.py ...
    Command: python scripts/tests/verify_performance.py
2026-01-15 16:36:13,411 - INFO - ğŸ›¡ï¸  Starting SNN Production Verification Protocol...
2026-01-15 16:36:13,411 - INFO - ğŸ“‹ Detected Task: conversational_dummy
2026-01-15 16:36:13,411 - INFO - ğŸ“ Baseline Target: Acc >= 90.00%
2026-01-15 16:36:13,417 - INFO - ğŸ‰ Verification SUCCESS! Report saved to workspace/results/verification_report.md
========================================
# âœ… SNN Verification Report: CONVERSATIONAL_DUMMY

**Overall Status:** PASS
**Date:** Thu Jan 15 16:36:13 JST 2026

## ğŸ“Š Metrics vs Baselines

| Metric | Measured (SNN) | Target (Baseline) | Status |
| :--- | :--- | :--- | :--- |
| **Accuracy** | **98.91%** | >= 90.00% | OK |
| **Energy** | 2.00e-05 J | <= 5.00e-05 J | OK |
| **Spike Rate** | 4.00% | <= 5.00% | OK |

## ğŸ“ Details
- **Model Description:** Conversational Sequence Modeling (Sanity Check)
- **Optimization Strategy:** Triangle Surrogate + Warm Restarts
========================================
âœ… Verification: verify_performance.py Passed (0.03s)

>>> Running Phase 2 Benchmark Suite ...

>>> Running: Benchmark Suite ...
    Command: python scripts/benchmarks/run_benchmark_suite.py
âœ… SpikingTransformerV3 (SCAL Bipolar Attention) initialized.
ğŸš€ Benchmark Suite Initialized (Device: mps)

--- Running Core SNN Benchmarks ---
âœ… PASS SNN Core: 0.1548 ms (Target < 10.0 ms)

--- Running SFormer (T=1) Benchmarks ---
âœ… PASS SFormer (T=1): 2.6765 ms (Target < 10.0 ms)

===========================================
   ğŸ† Phase 2 Benchmark Report Summary     
===========================================
ğŸ”¹ SNN_Core: 0.1548 ms
ğŸ”¹ SFormer_T1: 2.6765 ms
===========================================

âœ… Benchmark Suite Passed (1.10s)

âš ï¸ Some functional tests failed. Please review the output above for details.
